{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#gwaslab","title":"GWASLab","text":"<ul> <li>A handy Python toolkit for handling GWAS summary statistics (sumstats).</li> <li>Each process is modularized and can be customized to your needs.</li> <li>Sumstats-specific manipulations are designed as methods of a Python object, <code>gwaslab.Sumstats</code>.</li> </ul> <p>Please check GWASLab documentation at https://cloufield.github.io/gwaslab/ Note: GWASLab is being updated very frequently for now. I will release the first stable version soon! Please stay tuned.</p>"},{"location":"#install","title":"Install","text":"<pre><code>pip install gwaslab==3.4.35\n</code></pre> <pre><code>import gwaslab as gl\n# load plink2 output\nmysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", fmt=\"plink2\")\n\n# load sumstats with auto mode (auto-detecting common headers) \n# assuming ALT/A1 is EA, and frq is EAF\nmysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", fmt=\"auto\")\n\n# or you can specify the columns:\nmysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNP\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             ea=\"ALT\",\n             nea=\"REF\",\n             neaf=\"Frq\",\n             beta=\"BETA\",\n             se=\"SE\",\n             p=\"P\",\n             direction=\"Dir\",\n             n=\"N\",\n             build=\"19\")\n\n# manhattan and qq plot\nmysumstats.plot_mqq()\n...\n</code></pre>"},{"location":"#functions","title":"Functions","text":""},{"location":"#loading-and-formatting","title":"Loading and Formatting","text":"<ul> <li>Loading sumstats by simply specifying the software name or format name, or specifying each column name.</li> <li>Converting GWAS sumstats to specific formats:</li> <li>LDSC / MAGMA / METAL / PLINK / SAIGE / REGENIE / MR-MEGA / GWAS-SSF / FUMA / GWAS-VCF / BED... </li> <li>check available formats</li> <li>Optional filtering of variants in commonly used genomic regions: Hapmap3 SNPs / High-LD regions / MHC region </li> </ul>"},{"location":"#standardization-normalization","title":"Standardization &amp; Normalization","text":"<ul> <li>Variant ID standardization</li> <li>CHR and POS notation standardization</li> <li>Variant POS and allele normalization</li> <li>Genome build : Inference and Liftover </li> </ul>"},{"location":"#quality-control-value-conversion-filtering","title":"Quality control, Value conversion &amp; Filtering","text":"<ul> <li>Statistics sanity check</li> <li>Extreme value removal</li> <li>Equivalent statistics conversion<ul> <li>BETA/SE , OR/OR_95L/OR_95U</li> <li>P, Z, CHISQ, MLOG10P</li> </ul> </li> <li>Customizable value filtering</li> </ul>"},{"location":"#harmonization","title":"Harmonization","text":"<ul> <li>rsID assignment based on CHR, POS, and REF/ALT</li> <li>CHR POS assignment based on rsID using a reference text file</li> <li>Palindromic SNPs and indels strand inference using a reference VCF</li> <li>Check allele frequency discrepancy using a reference VCF</li> <li>Reference allele alignment using a reference genome sequence FASTA file</li> </ul>"},{"location":"#visualization","title":"Visualization","text":"<ul> <li>Mqq plot: Manhattan plot, QQ plot or MQQ plot (with a bunch of customizable features including auto-annotate nearest gene names)</li> <li>Miami plot: mirrored Manhattan plot</li> <li>Brisbane plot:  GWAS hits density plot</li> <li>Regional plot: GWAS regional plot</li> <li>Genetic correlation heatmap: ldsc-rg genetic correlation matrix</li> <li>Scatter plot: variant effect size comparison</li> <li>Scatter plot: allele frequency comparison </li> <li>Scatter plot: trumpet plot (plot of MAF and effect size with power lines)</li> </ul>"},{"location":"#visualization-examples","title":"Visualization Examples","text":""},{"location":"#other-utilities","title":"Other Utilities","text":"<ul> <li>Read ldsc h2 or rg outputs directly as DataFrames (auto-parsing).</li> <li>Extract lead variants given a sliding window size.</li> <li>Extract novel loci given a list of known lead variants / or known loci obtained from GWAS Catalog.</li> <li>Logging: keep a complete record of manipulations applied to the sumstats.</li> <li>Sumstats summary: give you a quick overview of the sumstats. </li> <li>...</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<p>environment.yml</p> <pre><code>name: gwaslab\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - python=3.8.16=h7a1cb2a_3\n  - jupyter==1.0.0\n  - pip==23.1.2\n  - pip:\n      - adjusttext==0.8\n      - biopython==1.81\n      - gwaslab==3.4.16\n      - liftover==1.1.16\n      - matplotlib==3.7.1\n      - numpy==1.24.2\n      - pandas==1.4.4\n      - scikit-allel==1.3.5\n      - scikit-learn==1.2.2\n      - scipy==1.10.1\n      - seaborn==0.11.2\n      - statsmodels==0.13\n      - adjustText==0.8\n      - pysam==0.19\n      - pyensembl==2.2.3\n</code></pre>"},{"location":"#how-to-cite","title":"How to cite","text":"<ul> <li>GWASLab preprint: He, Y., Koido, M., Shimmori, Y., Kamatani, Y. (2023). GWASLab: a Python package for processing and visualizing GWAS summary statistics. Preprint at Jxiv, 2023-5. https://doi.org/10.51094/jxiv.370</li> </ul>"},{"location":"#sample-data","title":"Sample Data","text":"<ul> <li>Sample GWAS data used in GWASLab is obtained from: http://jenger.riken.jp/ (Suzuki, Ken, et al. \"Identification of 28 new susceptibility loci for type 2 diabetes in the Japanese population.\" Nature genetics 51.3 (2019): 379-386.).</li> </ul>"},{"location":"#contacts","title":"Contacts","text":"<ul> <li>Github: https://github.com/Cloufield/gwaslab</li> <li>Blog (in Chinese): https://gwaslab.com/</li> <li>Email: gwaslab@gmail.com</li> <li>Stats: https://pypistats.org/packages/gwaslab</li> </ul>"},{"location":"AlleleFrequency/","title":"Allele Frequency Comparison","text":"<p>Scatter &amp; Distribution plot : allele frequency comparison</p> <p>Available from v3.4.15</p> <pre><code>#check the difference between the EAF in the sumstats and the allele frequency in VCF files\nsumstats.check_af()\n\n#allele frequnecy correlation plot\nsumstats.plot_daf()\n</code></pre> <p>You need to run 'check_af()' first before plotting. For check_af(), see here.</p> <p>Options for <code>plot_daf</code>: <code>threshold</code>: <code>float</code>, the threshold used to determine outliers.</p> <p>Example</p> <p><pre><code>mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNP\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             ea=\"ALT\",\n             nea=\"REF\",\n             neaf=\"Frq\",\n             beta=\"BETA\",\n             se=\"SE\",\n             p=\"P\",\n             direction=\"Dir\",\n             n=\"N\",nrows=10000)\n\n# harmonize\nmysumstats.harmonize(basic_check = True, \n                     ref_seq=gl.get_path(\"ucsc_genome_hg19\"))\n</code></pre> </p> <p><pre><code># check the difference in allele frequency with reference vcf\nmysumstats.check_af(ref_infer=gl.get_path(\"1kg_eas_hg19\"), \n                    ref_alt_freq=\"AF\",\n                    n_cores=2)\n</code></pre> </p> <p><pre><code>plot and get the outliers\noutliers = mysumstats.plot_daf(threshold=0.12, \n                                save=\"af_correlation.png\",\n                                save_args={\"dpi\":300})\n</code></pre> </p> <p><pre><code>outliers[1]\n</code></pre> </p>"},{"location":"AssignCHRPOS/","title":"Assigning CHR/POS","text":"<p>GWASLab can update CHR/POS using a pre-processed SNPID-rsID table to assign CHR and POS based on rsID. Currently, only variants in 1KG phase3v5 are supported.  </p>"},{"location":"AssignCHRPOS/#1-reference-data","title":"1. Reference data","text":"<p>GWASLab provides a download function <code>gl.download_ref()</code> and two curated tables which contains ~80M 1KG variants:</p> <ul> <li><code>hg19</code> : <code>gl.download_ref(\"1kg_dbsnp151_hg19_auto\")</code></li> <li><code>hg38</code> : <code>gl.download_ref(\"1kg_dbsnp151_hg38_auto\")</code></li> </ul> <p>Reference data</p> <p>1kg_dbsnp151_hg19_auto</p> <pre><code>~/.gwaslab$ zcat 1kg_dbsnp151_hg19_auto.txt.gz |head\nSNPID   rsID    CHR     POS     NEA     EA\n1:10177:A:AC    rs367896724     1       10177   A       AC\n1:10235:T:TA    rs540431307     1       10235   T       TA\n1:10352:T:TA    rs555500075     1       10352   T       TA\n1:10505:A:T     rs548419688     1       10505   A       T\n1:10511:G:A     rs534229142     1       10511   G       A\n1:10539:C:A     rs537182016     1       10539   C       A\n1:10542:C:T     rs572818783     1       10542   C       T\n1:10579:C:A     rs538322974     1       10579   C       A\n1:10616:CCGCCGTTGCAAAGGCGCGCCG:C        rs376342519     1       10616   CCGCCGTTGCAAAGGCGCGCCG  C\n</code></pre>"},{"location":"AssignCHRPOS/#2-usage","title":"2. Usage","text":"<pre><code># if not downloaded yet :\n# gl.download_ref(\"1kg_dbsnp151_hg19_auto\")\n\n# assign chr and pos using rsID\nmysumstats.rsid_to_chrpos( path = gl.get_path(\"1kg_dbsnp151_hg19_auto\"))\n</code></pre>"},{"location":"AssignCHRPOS/#3-example","title":"3. Example","text":"<p>Assign CHR and POS using rsID</p> <pre><code>mysumstats.data\n\nEA  NEA EAF BETA    SE  P   N   DIRECTION   STATUS  rsID\n0   G   A   0.9960  -0.0737 0.1394  0.59700 166718  -?+-    9960099 rs565766235\n1   G   A   0.0040  0.0737  0.1394  0.59730 166718  +?-+    9960099 rs534711480\n2   C   T   0.0051  0.0490  0.1231  0.69080 166718  +?-+    9960099 rs540210562\n3   TAA T   0.8374  0.0213  0.0199  0.28460 166718  -?++    9960399 rs529266287\n4   T   A   0.8593  0.0172  0.0156  0.27050 166718  -?++    9960099 rs28544273\n... ... ... ... ... ... ... ... ... ... ...\n9995    C   T   0.1292  -0.0350 0.0191  0.06686 191764  ----    9960099 rs55938238\n9996    C   T   0.4886  -0.0014 0.0094  0.88070 191764  -0+-    9960099 rs7520225\n9997    C   T   0.9476  -0.0061 0.0216  0.77790 191764  ---+    9960099 rs151238770\n9998    C   CT  0.9418  -0.0047 0.0199  0.81500 191764  ---+    9960399 rs137909285\n9999    G   A   0.9828  -0.0084 0.0433  0.84620 191764  +--+    9960099 rs77575110\n\n\nmysumstats.rsid_to_chrpos(path=gl.get_path(\"1kg_dbsnp151_hg19_auto\"))\n\nFri Jan 27 00:06:24 2023 Start to update chromosome and position information based on rsID...\nFri Jan 27 00:06:24 2023  -Current Dataframe shape : 10000  x  10\nFri Jan 27 00:06:24 2023  -rsID dictionary file: /home/he/.gwaslab/1kg_dbsnp151_hg19_auto.txt.gz\nFri Jan 27 00:06:24 2023  -Setting block size:  10000000\nFri Jan 27 00:06:24 2023  -Loading block: 0   1   2   3   4   5   6   7   \nFri Jan 27 00:11:44 2023  -Updating CHR and POS finished.Start to re-fixing CHR and POS... \nFri Jan 27 00:11:44 2023 Start to fix chromosome notation...\nFri Jan 27 00:11:44 2023  -Current Dataframe shape : 10000  x  12\nFri Jan 27 00:11:45 2023  -Variants with standardized chromosome notation: 9942\nFri Jan 27 00:11:45 2023  -Variants with fixable chromosome notations: 0\nFri Jan 27 00:11:45 2023  -Variants with NA chromosome notations: 58\nFri Jan 27 00:11:45 2023  -No unrecognized chromosome notations...\nFri Jan 27 00:11:46 2023 Finished fixing chromosome notation successfully!\nFri Jan 27 00:11:46 2023 Start to fix basepair positions...\nFri Jan 27 00:11:46 2023  -Current Dataframe shape : 10000  x  12\nFri Jan 27 00:11:46 2023  -Converting to Int64 data type ...\nFri Jan 27 00:11:46 2023  -Position upper_bound is: 250,000,000\nFri Jan 27 00:11:46 2023  -Remove outliers: 0\nFri Jan 27 00:11:46 2023  -Converted all position to datatype Int64.\nFri Jan 27 00:11:46 2023 Finished fixing basepair position successfully!\n\nmysumstats.data\n\nrsID    EA  NEA EAF BETA    SE  P   N   DIRECTION   STATUS  CHR POS\n0   rs565766235 G   A   0.9960  -0.0737 0.1394  0.59700 166718  -?+-    9960099 1   725932\n1   rs534711480 G   A   0.0040  0.0737  0.1394  0.59730 166718  +?-+    9960099 1   725933\n2   rs540210562 C   T   0.0051  0.0490  0.1231  0.69080 166718  +?-+    9960099 1   737801\n3   rs529266287 TAA T   0.8374  0.0213  0.0199  0.28460 166718  -?++    9960399 1   749963\n4   rs28544273  T   A   0.8593  0.0172  0.0156  0.27050 166718  -?++    9960099 1   751343\n... ... ... ... ... ... ... ... ... ... ... ... ...\n9995    rs55938238  C   T   0.1292  -0.0350 0.0191  0.06686 191764  ----    9960099 1   3142135\n9996    rs7520225   C   T   0.4886  -0.0014 0.0094  0.88070 191764  -0+-    9960099 1   3142137\n9997    rs151238770 C   T   0.9476  -0.0061 0.0216  0.77790 191764  ---+    9960099 1   3142161\n9998    rs137909285 C   CT  0.9418  -0.0047 0.0199  0.81500 191764  ---+    9960399 1   3142212\n9999    rs77575110  G   A   0.9828  -0.0084 0.0433  0.84620 191764  +--+    9960099 1   3142762\n</code></pre>"},{"location":"AssignCHRPOS/#4-dbsnp-reference-file-rsid_to_chrpos2","title":"4. dbSNP reference file / .rsid_to_chrpos2()","text":"<p>Available since v3.4.31</p> <p><code>.rsid_to_chrpos2()</code> is a function to assign CHR and POS based on rsID using a HDF5 file derived from dbSNP reference VCF files.</p> <p>First, download reference VCF file from dbSNP ftp site.</p> <pre><code># For example, dbSNP v155 hg19\nGCF_000001405.25.gz (24G)\nGCF_000001405.25.gz.tbi (2.9M)\n</code></pre> <p>Process the vcf file and convert it to HDF5 file using <code>.process_ref_vcf()</code>. This step may take up to one or two hours.</p> Option DataType Description Default <code>vcf</code> <code>string</code> the path to dbSNP VCF file - <code>directory</code> <code>string</code> the directory where you want output the converted HDF5 file <code>./</code> <pre><code>directory=\"/home/yunye/work/gwaslab/examples/vcf_hd5/\"\nvcf = \"/home/yunye/CommonData/Reference/ncbi_dbsnp/ncbi_dbsnp/db155/GCF_000001405.25.gz\"\n\ngl.process_ref_vcf(vcf=vcf,\n                   directory=directory,\n                   chr_dict=gl.get_NC_to_number(build=\"19\"))\n\nFri Nov 10 11:27:59 2023 Start processing VCF files:\nFri Nov 10 11:27:59 2023  -Reference VCF path:/home/yunye/CommonData/Reference/ncbi_dbsnp/ncbi_dbsnp/db155/GCF_000001405.25.gz\nFri Nov 10 11:27:59 2023  -Output group size:20000000\nFri Nov 10 11:27:59 2023  -Compression level:9\nFri Nov 10 11:27:59 2023  -Loading chunksize:20000000\nFri Nov 10 11:27:59 2023  -HDF5 Output path: /home/yunye/work/gwaslab/examples/vcf_hd5/rsID_CHR_POS_groups_20000000.h5\nFri Nov 10 11:27:59 2023  -Log output path: /home/yunye/work/gwaslab/examples/vcf_hd5/rsID_CHR_POS_groups_20000000.log\nFri Nov 10 11:27:59 2023  -Processing chunk: 0 1 2 3 4 ...\n</code></pre> <p>Assign CHR POS using the HDF5 file. </p> <p><code>.rsid_to_chrpos2()</code></p> Option DataType Description Default <code>path</code> <code>string</code> the path to the HDF5 file - <code>n_cores</code> <code>int</code> number of threads to use <code>./</code> <code>build</code> <code>string</code> genome build version for CHR and POS <code>\"99\"</code> <pre><code>...\nmysumstats.rsid_to_chrpos2(path=\"/home/yunye/work/gwaslab/examples/vcf_hd5/rsID_CHR_POS_groups_20000000.h5\")\n\nFri Nov 10 17:30:44 2023 Start to assign CHR and POS using rsIDs... \nFri Nov 10 17:30:44 2023  -Source hdf5 file:  ./vcf_hd5/rsID_CHR_POS_groups_20000000.hd5\nFri Nov 10 17:30:44 2023  -Cores to use :  4\nFri Nov 10 17:30:44 2023  -Blocksize (make sure it is the same as hdf5 file ):  20000000\nFri Nov 10 17:30:44 2023  -Non-Valid rsIDs:  58\nFri Nov 10 17:30:44 2023  -Duplicated rsIDs except for the first occurrence:  0\nFri Nov 10 17:30:44 2023  -Valid rsIDs:  9942\nFri Nov 10 17:30:44 2023  -Initiating CHR ... \nFri Nov 10 17:30:44 2023  -Initiating POS ... \nFri Nov 10 17:30:44 2023  -Divided into groups:  41\nFri Nov 10 17:30:44 2023   - {0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 18, 19, 26, 27, 28, 37, 38, 39, 43, 44, 48, 49, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74}\nFri Nov 10 17:30:46 2023  -Number of groups in HDF5:  92\nFri Nov 10 17:30:46 2023  -Max index of groups in HDF5:  105\nFri Nov 10 17:32:44 2023  -Merging group data... \nFri Nov 10 17:32:44 2023  -Append data... \nFri Nov 10 17:32:44 2023 Start to fix chromosome notation...\nFri Nov 10 17:32:44 2023  -Current Dataframe shape : 10000  x  13\nFri Nov 10 17:32:44 2023  -Checking CHR data type...\nFri Nov 10 17:32:44 2023  -Variants with standardized chromosome notation: 9705\nFri Nov 10 17:32:44 2023  -Variants with fixable chromosome notations: 0\nFri Nov 10 17:32:44 2023  -Variants with NA chromosome notations: 295\nFri Nov 10 17:32:44 2023  -No unrecognized chromosome notations...\nFri Nov 10 17:32:44 2023  -Sanity check for CHR...\nFri Nov 10 17:32:44 2023  -Removed 0 variants with CHR &lt; 1...\nFri Nov 10 17:32:44 2023 Finished fixing chromosome notation successfully!\nFri Nov 10 17:32:44 2023 Start to fix basepair positions...\nFri Nov 10 17:32:44 2023  -Current Dataframe shape : 10000  x  13\nFri Nov 10 17:32:44 2023  -Converting to Int64 data type ...\nFri Nov 10 17:32:44 2023  -Position upper_bound is: 250,000,000\nFri Nov 10 17:32:44 2023  -Remove outliers: 0\nFri Nov 10 17:32:44 2023  -Converted all position to datatype Int64.\nFri Nov 10 17:32:44 2023 Finished fixing basepair position successfully!\nFri Nov 10 17:32:44 2023 Finished assigning CHR and POS using rsIDs.\n</code></pre>"},{"location":"AssignrsID/","title":"Assigning rsID","text":"<p>GWASLab uses a two-step strategy (both steps are optional).</p> <ul> <li>For quick annotation, GWASLab iterates over a SNPID-rsID table and assigns rsID by joining on SNPID (CHR:POS:REF:ALT) with sumstats. GWASLab provides a curated table  (1KG autosome variants). </li> <li>For full annotation, GWASLab will query a large reference VCF file (dbSNP for example, &gt;20GB ) by CHR, POS, NEA, EA. It will assign the ID in VCF file to sumstats if the CHR, POS and EN/NEA match.</li> </ul>"},{"location":"AssignrsID/#1-reference-data","title":"1. Reference data","text":""},{"location":"AssignrsID/#11-snpid-rsid-table","title":"1.1 SNPID-rsID table","text":"<p>GWASLab provides a download function <code>gl.download_ref()</code> and two curated tables which contains ~80M 1KG variants:</p> <ul> <li><code>hg19</code> : <code>gl.download_ref(\"1kg_dbsnp151_hg19_auto\")</code></li> <li><code>hg38</code> : <code>gl.download_ref(\"1kg_dbsnp151_hg38_auto\")</code></li> </ul>"},{"location":"AssignrsID/#12-vcf-file","title":"1.2 VCF file","text":"<p>You can download this from dbSNP:</p> <p><code>hg19</code></p> <ul> <li><code>vcf</code>:https://ftp.ncbi.nih.gov/snp/latest_release/VCF/GCF_000001405.25.gz</li> <li><code>tbi</code>:https://ftp.ncbi.nih.gov/snp/latest_release/VCF/GCF_000001405.25.gz.tbi</li> </ul> <p><code>hg38</code></p> <ul> <li><code>vcf</code>:https://ftp.ncbi.nih.gov/snp/latest_release/VCF/GCF_000001405.39.gz</li> <li><code>tbi</code>:https://ftp.ncbi.nih.gov/snp/latest_release/VCF/GCF_000001405.39.gz.tbi</li> </ul> <p>1kg_dbsnp151_hg19_auto</p> <pre><code>~/.gwaslab$ zcat 1kg_dbsnp151_hg19_auto.txt.gz |head\nSNPID   rsID    CHR     POS     NEA     EA\n1:10177:A:AC    rs367896724     1       10177   A       AC\n1:10235:T:TA    rs540431307     1       10235   T       TA\n1:10352:T:TA    rs555500075     1       10352   T       TA\n1:10505:A:T     rs548419688     1       10505   A       T\n1:10511:G:A     rs534229142     1       10511   G       A\n1:10539:C:A     rs537182016     1       10539   C       A\n1:10542:C:T     rs572818783     1       10542   C       T\n1:10579:C:A     rs538322974     1       10579   C       A\n1:10616:CCGCCGTTGCAAAGGCGCGCCG:C        rs376342519     1       10616   CCGCCGTTGCAAAGGCGCGCCG  C\n</code></pre> <p>VCF file form dbSNP</p> <pre><code> zcat GCF_000001405.25.vcf.gz | head -100 | tail -10\nNC_000001.10    10059   rs1570391745    C       G       .       .       RS=1570391745;dbSNPBuildID=154;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=SNV;R5;GNO;FREQ=KOREAN:0.9997,0.0003425|dbGaP_PopFreq:1,0\nNC_000001.10    10060   rs1639544146    C       CT      .       .       RS=1639544146;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=INDEL;R5;GNO;FREQ=dbGaP_PopFreq:1,0\nNC_000001.10    10060   rs1639544159    CT      C       .       .       RS=1639544159;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=DEL;R5;GNO;FREQ=dbGaP_PopFreq:1,0\nNC_000001.10    10063   rs1010989343    A       C,G     .       .       RS=1010989343;dbSNPBuildID=150;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=SNV;R5;GNO;FREQ=KOREAN:0.9928,0.004112,0.003084|Siberian:0.5,0.5,.|dbGaP_PopFreq:1,.,0\nNC_000001.10    10067   rs1489251879    T       TAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCC      .       .       RS=1489251879;dbSNPBuildID=151;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=INDEL;R5;GNO;FREQ=GnomAD:1,1.789e-05\nNC_000001.10    10067   rs1639545042    T       C       .       .       RS=1639545042;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=SNV;R5;GNO;FREQ=dbGaP_PopFreq:1,0\nNC_000001.10    10067   rs1639545104    TA      T       .       .       RS=1639545104;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=INDEL;R5;GNO;FREQ=dbGaP_PopFreq:1,0\nNC_000001.10    10068   rs1639545079    A       T       .       .       RS=1639545079;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=SNV;R5;GNO;FREQ=dbGaP_PopFreq:1,0\nNC_000001.10    10069   rs1570391755    A       C,G     .       .       RS=1570391755;dbSNPBuildID=154;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=SNV;R5;GNO;FREQ=KOREAN:0.9966,.,0.003425|dbGaP_PopFreq:1,0,0\nNC_000001.10    10069   rs1639545200    A       AC      .       .       RS=1639545200;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=INDEL;R5;GNO;FREQ=dbGaP_PopFreq:1,0\n</code></pre>"},{"location":"AssignrsID/#2-usage","title":"2. Usage","text":"<pre><code>mysumstats.basic_check()\nmysumstats.assign_rsid( \n                        ref_rsid_tsv = gl.get_path(\"1kg_dbsnp151_hg19_auto\"),\n                        ref_rsid_vcf = \"/home/yunye/mydata/d_disk/dbsnp/GCF_000001405.25.vcf.gz\",\n                        chr_dict = gl.get_number_to_NC(build=\"19\"),\n                        n_cores = 2)\n</code></pre> <p>Info</p> <p>Please always run <code>.basic_check()</code> first. This will convert the data to right data type in most cases, and standardize and normalize the sumstats.</p>"},{"location":"AssignrsID/#3-options","title":"3. Options","text":"<code>.assign_rsid()</code> options DataType Description Default <code>ref_rsid_tsv</code> <code>string</code> tsv file path for annotation of commonly used variants using SNPID (like 1:725932:G:A) as key. - <code>ref_rsid_vcf</code> <code>string</code> vcf file path for annotation of other variants. .tbi file is also needed. - <code>chr_dict</code> <code>dict</code> a dictionary for converting 1-25 to CHR in the vcf files. For example, the notation in dbSNP vcf file is based on RefSeq (like NC_000001.10). <code>gwaslab</code> provides built-in conversion dictionaries.   <code>gl.get_number_to_NC(build=\"19\")</code> and <code>gl.get_number_to_NC(build=\"19\")</code> - <code>n_cores</code> <code>int</code> number of cores to use. <code>1</code> <p>Conversion for RefSeq sequence</p> <pre><code>gl.get_number_to_NC(build=\"19\")\n{1: 'NC_000001.10',2: 'NC_000002.11',3: 'NC_000003.11', 4: 'NC_000004.11', 5: 'NC_000005.9', 6: 'NC_000006.11', 7: 'NC_000007.13', 8: 'NC_000008.10', 9: 'NC_000009.11', 10: 'NC_000010.10', 11: 'NC_000011.9', 12: 'NC_000012.11', 13: 'NC_000013.10', 14: 'NC_000014.8', 15: 'NC_000015.9', 16: 'NC_000016.9', 17: 'NC_000017.10', 18: 'NC_000018.9', 19: 'NC_000019.9', 20: 'NC_000020.10', 21: 'NC_000021.8', 22: 'NC_000022.10', 23: 'NC_000023.10', 24: 'NC_000024.9', 25: 'NC_012920.1'}\n\ngl.get_number_to_NC(build=\"19\")\n{1: 'NC_000001.11',2: 'NC_000002.12',3: 'NC_000003.12',4: 'NC_000004.12',5: 'NC_000005.10',6: 'NC_000006.12',7: 'NC_000007.14',8: 'NC_000008.11',9: 'NC_000009.12',10: 'NC_000010.11',11: 'NC_000011.10',12: 'NC_000012.12',13: 'NC_000013.11',14: 'NC_000014.9',15: 'NC_000015.10',16: 'NC_000016.10',17: 'NC_000017.11',18: 'NC_000018.10',19: 'NC_000019.10',20: 'NC_000020.11',21: 'NC_000021.9',22: 'NC_000022.11',23: 'NC_000023.11',24: 'NC_000024.1',25: 'NC_012920.1'}\n</code></pre>"},{"location":"AssignrsID/#4-example","title":"4. Example","text":"<p>Example</p> <pre><code># download ref SNPID-rsID table first\ngl.download_ref(\"1kg_dbsnp151_hg19_auto\") \n\n# if you want to annotate as much as possible. Please download the very large dbSNP vcf file.\n\nmysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNP\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             ea=\"ALT\",\n             nea=\"REF\",\n             neaf=\"Frq\",\n             beta=\"BETA\",\n             se=\"SE\",\n             p=\"P\",\n             direction=\"Dir\",\n             n=\"N\",\n             nrows=10000)\n\n# run basic_check first\nmysumstats.basic_check() \n</code></pre> <p></p> <pre><code># if you SNPID is like 1:725932_G_A , you can use fix_id to fix the separator.\nmysumstats.fix_id(fixsep=True)\n</code></pre> <p></p> <pre><code># rsID annotation\nmysumstats.assign_rsid( n_cores = 2,\n                        ref_rsid_tsv = gl.get_path(\"1kg_dbsnp151_hg19_auto\"),\n                        ref_rsid_vcf =\"/home/yunye/mydata/d_disk/dbsnp/GCF_000001405.25.vcf.gz\",\n                        chr_dict = gl.get_number_to_NC(build=\"19\"))\n</code></pre> <pre><code>Wed Jan 11 20:05:38 2023 Start to annotate rsID based on chromosome and position information...\nWed Jan 11 20:05:38 2023  -Current Dataframe shape : 10000  x  12\nWed Jan 11 20:05:38 2023  -SNPID-rsID text file: /home/yunye/.gwaslab/1kg_dbsnp151_hg19_auto.txt.gz\nWed Jan 11 20:05:38 2023  -10000 rsID could be possibly fixed...\nWed Jan 11 20:05:38 2023  -Setting block size:  5000000\nWed Jan 11 20:05:38 2023  -Loading block: 0   1   2   3   4   5   6   7   8   9   10   11   12   13   14   15   \nWed Jan 11 20:10:16 2023  -rsID Annotation for 58 need to be fixed!\nWed Jan 11 20:10:16 2023  -Annotated 9942 rsID successfully!\nWed Jan 11 20:10:16 2023 Start to assign rsID using vcf...\nWed Jan 11 20:10:16 2023  -Current Dataframe shape : 10000  x  13\nWed Jan 11 20:10:16 2023  -CPU Cores to use : 2\nWed Jan 11 20:10:16 2023  -Reference VCF file: /home/yunye/mydata/d_disk/dbsnp/GCF_000001405.25.vcf.gz\nWed Jan 11 20:10:16 2023  -Assigning rsID based on chr:pos and ref:alt/alt:ref...\nWed Jan 11 20:10:17 2023  -rsID Annotation for 1 need to be fixed!\nWed Jan 11 20:10:17 2023  -Annotated 57 rsID successfully!\n</code></pre> <p>As you can see, SNPID-rsID (<code>1kg_dbsnp151_hg19_auto</code>) annotated 9942 rsID and the large reference VCF file (from dbSNP) annotated additonal 57 rare rsID.</p> <p></p>"},{"location":"BrisbanePlot/","title":"Brisbane plot","text":""},{"location":"BrisbanePlot/#1-brisbane-plot-gwas-signal-density-plot","title":"1. Brisbane plot : GWAS signal density plot","text":"<p>GWASLab can create the Brisbane plot (GWAS signal density plot). Brisbane plot is a scatter plot that shows the signal density (number of variants within the 500 Kb flanking region of the reference variant) for each variant, which is very useful for presenting the independent signals obtained from large-scale GWAS of complex traits. The signals are usually determined by other statistical methods such as conditional analysis. </p>"},{"location":"BrisbanePlot/#11-usage","title":"1.1 Usage","text":"<pre><code>mysumstats.plot_mqq(mode=\"b\")\n</code></pre> <p>Note</p> <p>To create Brisbane plot using this function, you just need to load the sumstats of indenpedent signals. If you load the entire datasets, the plot will simply reflect the marker density for your sumstats. To investigate indenpedent signals, please use other tools such as GCTA-COJO. GWASLab only calculates the density of all variants in the gl.Sumstats Object.</p>"},{"location":"BrisbanePlot/#12-options","title":"1.2 Options","text":"Option DataType Description Default <code>mode</code> <code>b</code> specify Brisbane plot mode - <code>bwindowsizekb</code> <code>int</code> windowsize in kb (flanking region length on one side) <code>100</code>"},{"location":"BrisbanePlot/#13-example","title":"1.3 Example","text":"<p>Brisbane plot</p> <p>Data was obtained from : Yengo, L., Vedantam, S., Marouli, E., Sidorenko, J., Bartell, E., Sakaue, S., ... &amp; Lee, J. Y. (2022). A saturated map of common genetic variants associated with human height. Nature, 1-16.</p> <pre><code>mysumstats = gl.Sumstats(\"height_lead.tsv\",\n             snpid=\"SNP\",\n             chrom=\"Chr\",\n             pos=\"BP_HG19\",\n             p=\"P-value\")\n\nmysumstats.plot_mqq(mode=\"b\",anno=\"GENENAME\",\n                  build=\"19\",anno_fixed_arm_length=2,\n                  anno_args={\"rotation\":90},\n                  marker_size=(30,30),sig_line_color=\"red\")\n</code></pre> <p></p>"},{"location":"BrisbanePlot/#2-calculate-the-density-for-sumstats","title":"2. Calculate the density for sumstats","text":"<pre><code>mysumstats.get_density(windowsizekb=100)\n</code></pre> <p>Or you can use <code>.get_density()</code> to just calculate the density.</p> Option DataType Description Default <code>windowsizekb</code> <code>int</code> window size for calculation of signal density. <code>DENSITY</code> <code>100</code> <p>Calculate signal density</p> <pre><code>mysumstats.get_density(windowsizekb=100)\n\nmysumstats.data\n    SNPID   CHR POS P   STATUS  DENSITY\n0   rs2710888   1   959842  2.190000e-57    9999999 1\n1   rs3934834   1   1005806 2.440000e-29    9999999 1\n2   rs182532    1   1287040 1.250000e-18    9999999 1\n3   rs17160669  1   1305561 1.480000e-28    9999999 1\n4   rs9660106   1   1797947 1.860000e-12    9999999 0\n... ... ... ... ... ... ...\n12106   rs9628283   22  50540766    5.130000e-15    9999999 1\n12107   rs28642259  22  50785718    1.140000e-13    9999999 1\n12108   rs11555194  22  50876662    2.000000e-15    9999999 2\n12109   rs762669    22  50943423    3.000000e-30    9999999 1\n12110   rs9628185   22  51109992    5.430000e-12    9999999 0\n</code></pre>"},{"location":"BrisbanePlot/#reference","title":"Reference","text":"<p>Citation for Brisbane plot</p> <p>Yengo, L., Vedantam, S., Marouli, E., Sidorenko, J., Bartell, E., Sakaue, S., ... &amp; Lee, J. Y. (2022). A saturated map of common genetic variants associated with human height. Nature, 1-16.</p>"},{"location":"Clumping/","title":"Clumping in GWASLab by calling PLINK2","text":"<p>GWASLab provides a clumping function using PLINK2.  You can get clumping results without worrying about the file format.  </p>"},{"location":"Clumping/#clumping","title":"Clumping","text":"<p>You need to install PLINK2 first and add to your environment.</p> <pre><code>clump(  vcf=None, \n        bfile=None,\n        scaled=False, \n        out=\"clumping_plink2\", \n        overwrite=False, \n        n_cores=2, \n        chrom=None, \n        clump_p1=5e-8, \n        clump_p2=5e-8, \n        clump_r2=0.2, \n        clump_kb=250,\n        log=Log())\n</code></pre> Option DataType Description Default <code>vcf</code> <code>string</code> path to reference VCF file (it will be converted to plink binary format). You need to specify either <code>vcf</code> or <code>bfile</code> - <code>bfile</code> <code>string</code> path to PLINK bfile. You need to specify either <code>vcf</code> or <code>bfile</code> - <code>scaled</code> <code>boolean</code> If tru, use MLOG10P instead of P <code>False</code> <code>out</code> <code>string</code> output file prefix <code>clumping_plink2</code> <code>overwrite</code> <code>boolean</code> if True, overwrite the existing bfile when vcf path is provided <code>False</code> <code>n_cores</code> <code>int</code> number of cores to use 2 <code>clump_p1</code> <code>float</code> clump_p1 5e-8 <code>clump_p2</code> <code>float</code> clump_p2 5e-8 <code>clump_r2</code> <code>float</code> clump_r2 0.2 <code>clump_kb</code> <code>float</code> clump_kb 250 <p>Plink2 script</p> <pre><code># using P\nplink2 \\\n    --bfile {}\\\n    --chr {} \\\n    --clump {} \\\n    --clump-field P \\\n    --clump-snp-field SNPID \\\n    --clump-p1 {} \\\n    --clump-p2 {} \\\n    --clump-r2 {} \\\n    --clump-kb {} \\\n    --threads {} \\\n    --out {}\n</code></pre> <pre><code># using MLOG10P\nplink2 \\\n    --bfile {}\\\n    --chr {} \\\n    --clump {} \\\n    --clump-field P \\\n    --clump-snp-field SNPID \\\n    --clump-p1 {} \\\n    --clump-p2 {} \\\n    --clump-r2 {} \\\n    --clump-kb {} \\\n    --threads {} \\\n    --out {}\n</code></pre>"},{"location":"Clumping/#example","title":"Example","text":"<p>Example</p> <pre><code>clumps = mysumstats.clump(vcf= \"/home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\")\n</code></pre>"},{"location":"CommonData/","title":"Commonly used data in GWASLab","text":"<p>GWASLab integrates a few pre-defined datasets for quick conversion and access, which are used in the functions of GWASLab.</p>"},{"location":"CommonData/#chromosme-notation-conversion-dictionary","title":"Chromosme notation conversion dictionary","text":""},{"location":"CommonData/#full-chromosome-list","title":"Full chromosome list","text":"<p><code>gl.get_chr_list()</code>: Get a full list of chromosomes (string datatype):</p> <pre><code>gl.get_chr_list()\n\n['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','X','Y','M','MT']\n\n\ngl.get_chr_list(n=2)\n\n['1', '2', 'X', 'Y', 'M', 'MT']\n</code></pre>"},{"location":"CommonData/#chr-nc-conversion","title":"CHR - NC conversion","text":"<p><code>gl.get_chr_to_NC(build)</code></p> <pre><code>gl.get_chr_to_NC(build=\"19\")\n\n{'1': 'NC_000001.10', '2': 'NC_000002.11', '3': 'NC_000003.11', '4': 'NC_000004.11', '5': 'NC_000005.9', '6': 'NC_000006.11', '7': 'NC_000007.13', '8': 'NC_000008.10', '9': 'NC_000009.11', '10': 'NC_000010.10', '11': 'NC_000011.9', '12': 'NC_000012.11', '13': 'NC_000013.10', '14': 'NC_000014.8', '15': 'NC_000015.9', '16': 'NC_000016.9', '17': 'NC_000017.10', '18': 'NC_000018.9', '19': 'NC_000019.9', '20': 'NC_000020.10', '21': 'NC_000021.8', '22': 'NC_000022.10', 'X': 'NC_000023.10', 'Y': 'NC_000024.9', 'MT': 'NC_012920.1'}\n</code></pre> <p><code>gl.get_number_to_NC(build)</code></p> <pre><code>gl.get_number_to_NC(build=\"19\")\n\n{1: 'NC_000001.10', 2: 'NC_000002.11', 3: 'NC_000003.11', 4: 'NC_000004.11', 5: 'NC_000005.9', 6: 'NC_000006.11', 7: 'NC_000007.13', 8: 'NC_000008.10', 9: 'NC_000009.11', 10: 'NC_000010.10', 11: 'NC_000011.9', 12: 'NC_000012.11', 13: 'NC_000013.10', 14: 'NC_000014.8', 15: 'NC_000015.9', 16: 'NC_000016.9', 17: 'NC_000017.10', 18: 'NC_000018.9', 19: 'NC_000019.9', 20: 'NC_000020.10', 21: 'NC_000021.8', 22: 'NC_000022.10', 23: 'NC_000023.10', 24: 'NC_000024.9', 25: 'NC_012920.1'}\n</code></pre> <p><code>gl.get_NC_to_chr(build)</code></p> <pre><code>gl.get_NC_to_chr(build=\"19\")\n\n{'NC_000001.10': '1', 'NC_000002.11': '2', 'NC_000003.11': '3', 'NC_000004.11': '4', 'NC_000005.9': '5', 'NC_000006.11': '6', 'NC_000007.13': '7', 'NC_000008.10': '8', 'NC_000009.11': '9', 'NC_000010.10': '10', 'NC_000011.9': '11', 'NC_000012.11': '12', 'NC_000013.10': '13', 'NC_000014.8': '14', 'NC_000015.9': '15', 'NC_000016.9': '16', 'NC_000017.10': '17', 'NC_000018.9': '18', 'NC_000019.9': '19', 'NC_000020.10': '20', 'NC_000021.8': '21', 'NC_000022.10': '22', 'NC_000023.10': 'X', 'NC_000024.9': 'Y', 'NC_012920.1': 'MT'}\n</code></pre> <p><code>gl.get_NC_to_number(build)</code></p> <pre><code>gl.get_NC_to_number(build=\"19\")\n\n{'NC_000001.10': 1, 'NC_000002.11': 2, 'NC_000003.11': 3, 'NC_000004.11': 4, 'NC_000005.9': 5, 'NC_000006.11': 6, 'NC_000007.13': 7, 'NC_000008.10': 8, 'NC_000009.11': 9, 'NC_000010.10': 10, 'NC_000011.9': 11, 'NC_000012.11': 12, 'NC_000013.10': 13, 'NC_000014.8': 14, 'NC_000015.9': 15, 'NC_000016.9': 16, 'NC_000017.10': 17, 'NC_000018.9': 18, 'NC_000019.9': 19, 'NC_000020.10': 20, 'NC_000021.8': 21, 'NC_000022.10': 22, 'NC_000023.10': 23, 'NC_000024.9': 24, 'NC_012920.1': 25}\n</code></pre>"},{"location":"CommonData/#chr-datatype-conversion-string-int","title":"CHR Datatype conversion (string &lt;-&gt; int)","text":"<p><code>gl.get_chr_to_number()</code>: <code>string</code> to <code>int</code></p> <p><code>gl.get_number_to_chr()</code>: <code>int</code> to <code>string</code></p>"},{"location":"CommonData/#high-ld-region-bed","title":"High-LD region bed","text":"<p><code>gl.get_high_ld(build)</code>: get the path for the BED file of high-LD regions</p> <pre><code>gl.get_high_ld(\"19\")\n\n'/home/yunye/anaconda3/envs/gwaslab/lib/python3.8/site-packages/gwaslab/data/high_ld/high_ld_hla_hg19.bed.gz'\n</code></pre>"},{"location":"CommonData/#sumstats-format-list","title":"Sumstats Format list","text":"<p><code>gl.get_format_dict(fmt)</code>: check the details of a format.</p> <pre><code>gl.get_format_dict(fmt=\"gwaslab\")\n\n({'format_name': 'ldsc',\n  'format_source': 'https://github.com/bulik/ldsc/wiki/Summary-Statistics-File-Format',\n  'format_source2': 'https://github.com/bulik/ldsc/blob/master/munge_sumstats.py',\n  'format_version': 20150306},\n {'SNP': 'rsID',\n  'A2': 'NEA',\n  'A1': 'EA',\n  'Frq': 'EAF',\n  'N': 'N',\n  'Beta': 'BETA',\n  'P': 'P',\n  'Z': 'Z',\n  'INFO': 'INFO',\n  'OR': 'OR',\n  'CHR': 'CHR',\n  'POS': 'POS'})\n</code></pre> <p><code>gl.get_formats_list()</code>: show all available format GWASLab supports.</p> <pre><code>['auto',\n 'bolt_lmm',\n 'fastgwa',\n 'gwascatalog',\n 'gwascatalog_hm',\n 'gwaslab',\n 'ldsc',\n 'metal',\n 'mrmega',\n 'mtag',\n 'pgscatalog',\n 'pgscatalog_hm',\n 'pheweb',\n 'plink',\n 'plink2',\n 'regenie',\n 'saige',\n 'ssf',\n 'template',\n 'vcf']\n</code></pre>"},{"location":"Conversion/","title":"Statistics conversion","text":"<p>GWASLab can convert equvalent statistics, including:</p> Target stats Original stats Implementation MLOG10P P <code>sumstats[\"MLOG10P\"] = -np.log10(sumstats[\"P\"])</code> P MLOG10P <code>sumstats[\"P\"] = np.power(10,-sumstats[\"MLOG10P\"])</code> P Z <code>sumstats[\"P\"] = ss.norm.sf(np.abs(sumstats[\"Z\"])) * 2</code> P CHISQ <code>sumstats[\"P\"] = ss.chi2.sf(sumstats[\"CHISQ\"], 1)</code> OROR_95LOR_95U BETASE <code>sumstats[\"OR\"]   = np.exp(sumstats[\"BETA\"])</code>,  <code>sumstats[\"OR_95L\"] = np.exp(sumstats[\"BETA\"]-ss.norm.ppf(0.975)*sumstats[\"SE\"])</code>,  <code>sumstats[\"OR_95U\"] = np.exp(sumstats[\"BETA\"]+ss.norm.ppf(0.975)*sumstats[\"SE\"])</code> BETA  SE OR OR_95LOR_95U <code>sumstats[\"BETA\"]  = np.log(sumstats[\"OR\"])</code>,  <code>sumstats[\"SE\"]=(np.log(sumstats[\"OR\"]) - np.log(sumstats[\"OR_95L\"]))/ss.norm.ppf(0.975)</code>,  <code>sumstats[\"SE\"]=(np.log(sumstats[\"OR_95U\"]) - np.log(sumstats[\"OR\"]))/ss.norm.ppf(0.975)</code> Z BETA/SE <code>sumstats[\"Z\"] = sumstats[\"BETA\"]/sumstats[\"SE\"]</code> CHISQ P <code>sumstats[\"CHISQ\"] = ss.chi2.isf(sumstats[\"P\"], 1)</code> CHISQ Z <code>sumstats[\"CHISQ\"] = (sumstats[\"Z\"])**2</code> MAF EAF <code>sumstats[\"MAF\"] =  sumstats[\"EAF\"].apply(lambda x: min(x,1-x) if pd.notnull(x) else np.nan)</code> <p>Extreme P values</p> <p>For extreme P, <code>extreme=True</code> can be added to overcome the limitation of extreme P values (P&lt;1e-308). MLOG10P will be calculated using the methods described here:</p> <p><code>mysumstats.fill_data(to_fill=[\"MLOG10P\"], extreme=True)</code></p> <p></p> <p>Z socres (or BETA and SE) will be used to calculate MLOG10P, two additional columns <code>P_MANTISSA</code> and <code>P_EXPONENT</code> will be added to present p values. </p> <p>Note</p> <p>The conversion is implemented using scipy and numpy.</p> <ul> <li>ss : <code>import scipy.stats as ss</code></li> <li>np : <code>import numpy as np</code></li> </ul> <p>See examples here.</p>"},{"location":"Conversion/#fill_data","title":"fill_data()","text":"<pre><code>mysumstats.fill_data( \n    to_fill=[],\n    df=None,\n    overwrite=False,\n    only_sig=False\n    )\n</code></pre>"},{"location":"Conversion/#options","title":"Options","text":"<ul> <li><code>to_fill</code>: the columns to fill. [\"OR\",\"OR_95L\",\"OR_95U\",\"BETA\",\"SE\",\"P\",\"MLOG10P\",\"Z\",\"CHISQ\"]</li> <li><code>df</code> : columns name for degree of freedom</li> <li><code>overwrite</code>: if overwrite when the specified column existed</li> <li><code>only_sig</code> : fill the data only for significant variants</li> </ul>"},{"location":"Conversion/#priority","title":"Priority","text":"<ul> <li>For P : using MLOG10P, Z, CHISQ </li> <li>For MLOG10P : using P, MLOG10P, Z, CHISQ </li> <li>For BETA/SE : using OR/OR_95L/OR_95U</li> <li>For OR/OR_95L/OR_95U : using BETA/SE</li> <li>For Z : using BETA/SE</li> <li>For CHISQ : using  Z, P</li> </ul>"},{"location":"Conversion/#example","title":"Example","text":"<p>Example</p> <pre><code># raw data\n#SNPID  CHR POS EA  NEA EAF BETA    SE  P   STATUS\n#1:725932_G_A   1   725932  G   A   0.9960  -0.0737 0.1394  0.5970  9999999\n#1:725933_A_G   1   725933  G   A   0.0040  0.0737  0.1394  0.5973  9999999\n#1:737801_T_C   1   737801  C   T   0.0051  0.0490  0.1231  0.6908  9999999\n\n# let's fill \"MLOG10P\",\"Z\",\"OR\",\"OR_95L\",\"OR_95U\"\n# gwaslab will automatically search for equivalent statistics\n\nmysumstats.fill_data(to_fill=[\"MLOG10P\",\"Z\",\"OR\",\"OR_95L\",\"OR_95U\"])\n\nWed Oct 19 10:13:30 2022 Start filling data using existing columns...\nWed Oct 19 10:13:30 2022  -Raw input columns:  ['SNPID', 'CHR', 'POS', 'EA', 'NEA', 'EAF', 'BETA', 'SE', 'P', 'STATUS']\nWed Oct 19 10:13:30 2022  -Overwrite mode:  False\nWed Oct 19 10:13:30 2022   - Skipping columns:  []\nWed Oct 19 10:13:30 2022 Filling columns:  ['MLOG10P', 'OR', 'OR_95L', 'OR_95U']\nWed Oct 19 10:13:30 2022   - Filling OR using BETA column...\nWed Oct 19 10:13:31 2022   - Filling OR_95L/OR_95U using BETA/SE columns...\nWed Oct 19 10:13:32 2022   - Filling MLOG10P using P column...\nWed Oct 19 10:13:38 2022 Finished filling data using existing columns.\n</code></pre>"},{"location":"Download/","title":"Download reference data","text":""},{"location":"Download/#downloading-and-file-management-system","title":"Downloading and file management system","text":"Functions Options Datatype Description <code>gl.check_available_ref()</code> list available reference datasets GWASLab can use <code>gl.check_downloaded_ref()</code> list downloaded reference dataset <code>gl.download_ref(keyword)</code> keyword <code>string</code> download the reference dataset <code>gl.remove_file(keyword)</code> keyword <code>string</code> remove the downloaded dataset <code>gl.get_path(keyword)</code> keyword <code>string</code> get the path to the refernce dataset <p>You can download the following files using GWASLab with the keywords:</p> <p>Processed datasets are currently hosted on Dropbox which may not be accessible for users in certain regions.</p> <p>Datasets you need to download explicitly if needed.</p> Keyword Description Note '1kg_eas_hg19','1kg_eas_hg19_tbi' Autosomes; 1KGp3v5 low-coverage EAS VCF and index (hg19) Processed, Dropbox '1kg_eur_hg19','1kg_eur_hg19_tbi' Autosomes; 1KGp3v5 low-coverage EUR VCF and index (hg19) Processed, Dropbox '1kg_amr_hg19','1kg_amr_hg19_tbi' Autosomes; 1KGp3v5 low-coverage AMR VCF and index (hg19) Processed, Dropbox '1kg_afr_hg19','1kg_afr_hg19_tbi' Autosomes; 1KGp3v5 low-coverage AFR VCF and index (hg19) Processed, Dropbox '1kg_sas_hg19','1kg_sas_hg19_tbi' Autosomes; 1KGp3v5 low-coverage SAS VCF and index (hg19) Processed, Dropbox '1kg_pan_hg19','1kg_pan_hg19_tbi' Autosomes; 1KGp3v5 low-coverage VCF and index (hg19); all ancestries Processed, Dropbox '1kg_eas_hg38','1kg_eas_hg38_tbi' Autosomes; 1KGp3v5 30x EAS VCF and index (hg38) Processed, Dropbox '1kg_eur_hg38','1kg_eur_hg38_tbi' Autosomes; 1KGp3v5 30x EUR VCF and index (hg38) Processed, Dropbox '1kg_afr_hg38','1kg_eas_hg38_tbi' Autosomes; 1KGp3v5 30x AFR VCF and index (hg38) Processed, Dropbox '1kg_amr_hg38','1kg_eur_hg38_tbi' Autosomes; 1KGp3v5 30x AMR VCF and index (hg38) Processed, Dropbox '1kg_sas_hg38','1kg_sas_hg38_tbi' Autosomes; 1KGp3v5 30x SAS VCF and index (hg38) Processed, Dropbox '1kg_pan_hg38','1kg_pan_hg38_tbi' Autosomes; 1KGp3v5 30x VCF and index (hg38); all ancestries Processed, Dropbox '1kg_eas_x_hg19','1kg_eas_x_hg19_tbi' ChrX; 1KGp3v5 low-coverage EAS VCF and index (hg19) Processed, Dropbox '1kg_eur_x_hg19','1kg_eur_x_hg19_tbi' ChrX; 1KGp3v5 low-coverage EUR VCF and index (hg19) Processed, Dropbox '1kg_amr_x_hg19','1kg_amr_x_hg19_tbi' ChrX; 1KGp3v5 low-coverage AMR VCF and index (hg19) Processed, Dropbox '1kg_afr_x_hg19','1kg_afr_x_hg19_tbi' ChrX; 1KGp3v5 low-coverage AFR VCF and index (hg19) Processed, Dropbox '1kg_sas_x_hg19','1kg_sas_x_hg19_tbi' ChrX; 1KGp3v5 low-coverage SAS VCF and index (hg19) Processed, Dropbox '1kg_pan_x_hg19','1kg_pan_x_hg19_tbi' ChrX; 1KGp3v5 low-coverage VCF and index (hg19); all ancestries Processed, Dropbox '1kg_eas_x_hg38','1kg_eas_x_hg38_tbi' ChrX; 1KGp3v5 30x EAS VCF and index (hg38) Processed, Dropbox '1kg_eur_x_hg38','1kg_eur_x_hg38_tbi' ChrX; 1KGp3v5 30x EUR VCF and index (hg38) Processed, Dropbox '1kg_afr_x_hg38','1kg_eas_x_hg38_tbi' ChrX; 1KGp3v5 30x AFR VCF and index (hg38) Processed, Dropbox '1kg_amr_x_hg38','1kg_eur_x_hg38_tbi' ChrX; 1KGp3v5 30x AMR VCF and index (hg38) Processed, Dropbox '1kg_sas_x_hg38','1kg_sas_x_hg38_tbi' ChrX; 1KGp3v5 30x SAS VCF and index (hg38) Processed, Dropbox '1kg_pan_x_hg38','1kg_pan_x_hg38_tbi' ChrX; 1KGp3v5 30x VCF and index (hg38); all ancestries Processed, Dropbox 'dbsnp_v151_hg19' dbSNP151 (hg19, !!very large) Original source 'dbsnp_v151_hg38' dbSNP151 (hg38, !!very large) Original source 'dbsnp_v156_hg19' dbSNP151 (hg19, !!very large) Original source 'dbsnp_v156_hg38' dbSNP151 (hg38, !!very large) Original source 'ucsc_genome_hg19' UCSC human reference genome (hg19) Original source 'ucsc_genome_hg38' UCSC human reference genome (hg38) Original source '1kg_dbsnp151_hg19_auto' Autosomes; 1KGp3v5 variants SNPID-rsID conversion table (hg19) Processed, Dropbox '1kg_dbsnp151_hg38_auto' Autosomes; 1KGp3v5 variants SNPID-rsID conversion table (hg38) Processed, Dropbox '1kg_dbsnp151_hg19_x' ChrX; 1KGp3v5 variants SNPID-rsID conversion table (hg19) Processed, Dropbox '1kg_dbsnp151_hg38_x' ChrX; 1KGp3v5 variants SNPID-rsID conversion table (hg38) Processed, Dropbox <p>tbi index file will be automatically downloaded when you download VCF files</p> <p>Download and check the local path of <code>1kg_eas_hg19</code></p> <pre><code>gl.download_ref(\"1kg_eas_hg19\")\n\ngl.get_path(\"1kg_eas_hg19\")\n'/Users/he/work/gwaslab/src/gwaslab/data/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz'\n</code></pre> <p>Other reference datasets GWASLab uses to create regional plot and annotate variants (GWASLab will automatically download and process these files when needed): </p> Keyword Description Note 'recombination_hg19' Recombination rate reference files from Hapmap Project (hg19) Processed, Dropbox 'recombination_hg38' Recombination rate reference files from Hapmap Project (hg38) Processed, Dropbox 'ensembl_hg19_gtf' GTF file for genes from Ensembl (hg19) Original source 'ensembl_hg38_gtf' GTF file for genes from Ensembl (hg38) Original source 'refseq_hg19_gtf' GTF file for genes from Refseq (hg19) Original source 'refseq_hg38_gtf' GTF file for genes from Refseq (hg19) Original source"},{"location":"Download/#configurations","title":"Configurations","text":"<p>GWASLab uses 3 files and a default path for reference management:</p> <ul> <li><code>config</code> : a dictionary of <code>keyword</code>:<code>local path</code> for local file management.</li> <li><code>reference</code> : a dictionary of <code>keyword</code>:<code>url</code> for automatically downloading reference files.</li> <li><code>formatbook</code> : a dictionary used for format header conversions. </li> <li><code>data_directory</code>: the path for downloaded reference file. default: (<code>~/.gwaslab</code>)</li> </ul> <p>You can use <code>gl.options.paths</code> to check the paths of the three files.</p> <pre><code>gl.options.paths\n{'config': '/Users/he/work/gwaslab/src/gwaslab/data/config.json',\n 'reference': '/Users/he/work/gwaslab/src/gwaslab/data/reference.json',\n 'formatbook': '/Users/he/work/gwaslab/src/gwaslab/data/formatbook.json',\n 'data_directory': '/Users/he/.gwaslab/'}\n</code></pre> <p>Sometimes you might need to use your own files, which can be done using <code>gl.options.set_option(key, newpath)</code> (simply run this after loadnig the gwaslab package):</p> <pre><code># change the path for formatbook\n\ngl.options.set_option(\"formatbook\",\"/newpath/formatbook.json\")\ngl.options.paths\n{'config': '/Users/he/work/gwaslab/src/gwaslab/data/config.json',\n 'reference': '/Users/he/work/gwaslab/src/gwaslab/data/reference.json',\n 'formatbook': '/newpath/formatbook.json',\n 'data_directory': '/Users/he/.gwaslab/'}\n</code></pre>"},{"location":"EffectSize/","title":"Comparing effect sizes","text":""},{"location":"EffectSize/#scatter-plot-effect-size-comparison","title":"Scatter plot : effect size comparison","text":"<p>upgrated since v3.4.17</p> <p><code>gl.compare_effect()</code> will plot effect size comparison plot using two sets of sumstats. Alleles will be aligned to effect alleles in sumstats1.</p> <pre><code>gl.compare_effect (path1,\n                   path2,\n                   cols_name_list_1=None, effect_cols_list_1=None,\n                   cols_name_list_2=None, effect_cols_list_2=None,\n                   eaf=[],\n                   maf_level=None,\n                   label=None,\n                   snplist=None,\n                   mode=\"beta\",\n                   anno=False,\n                   anno_het=False,\n                   anno_min=0,\n                   anno_min1=0,\n                   anno_min2=0,\n                   anno_diff=0,\n                   scaled=False,\n                   scaled1=False,\n                   scaled2=False,\n                   wc_correction=False, \n                   null_beta=0,\n                   is_q=False,\n                   include_all=True,\n                   q_level=0.05,\n                   sig_level=5e-8,\n                   drop=False,\n                   wc_sig_level=5e-8,\n                   # reg\n                   reg_box=None,\n                   is_reg=True,\n                   fdr=False,\n                   allele_match=False,\n                   r_se=False,\n                   is_45_helper_line=True,\n                   legend_mode=\"full\",\n                   legend_title=r'$ P &lt; 5 x 10^{-8}$ in:',\n                   legend_title2=r'Heterogeneity test:',\n                   legend_pos='upper left',\n                   scatterargs=None,\n                   plt_args=None,\n                   xylabel_prefix=\"Per-allele effect size in \",\n                   helper_line_args=None,\n                   fontargs=None,\n                   errargs=None,\n                   legend_args=None,\n                   sep=[\"\\t\",\"\\t\"],\n                   log = Log(),\n                   save=False,\n                   save_args=None,\n                   verbose=False)\n</code></pre>"},{"location":"EffectSize/#options","title":"Options","text":""},{"location":"EffectSize/#path-and-column","title":"Path and column","text":"<ul> <li><code>path1</code> and <code>path2</code> : the paths to the sumstats. Can also be <code>gl.Sumstats</code> Object or <code>pd.DataFrame</code> (from v3.4.17). If <code>gl.Sumstats</code> Objects are provided, there is no need to set cols_name_list and effect_cols_list.</li> <li><code>cols_name_list_1</code> and <code>cols_name_list_2</code> : list of column names for variants basic information</li> <li><code>effect_cols_list_1</code> and <code>effect_cols_list_2</code> : list of column names for effect size-related columns</li> <li><code>mode</code> : use beta or OR </li> <li><code>cols_name_list_x</code> and <code>effect_cols_list_x</code> examples:<ul> <li><code>[snpid,p,ea,nea]</code>        ,<code>[effect,se]</code></li> <li><code>[snpid,p,ea,nea,chr,pos]</code>,<code>[effect,se]</code></li> <li><code>[snpid,p,ea,nea,chr,pos]</code>,<code>[OR,OR_l,OR_h]</code></li> </ul> </li> </ul> Option Type Description Default <code>path1</code> <code>string</code>,<code>gl.Sumstats</code>, or <code>pd.DataFrame</code> path to the sumstats file, or gwaslab Sumstats object or pandas Dataframe None <code>path2</code> <code>string</code>,<code>gl.Sumstats</code>, or <code>pd.DataFrame</code> path to the sumstats file, or gwaslab Sumstats object or pandas Dataframe None <code>cols_name_list_1</code> <code>list</code> \"[snpid,p,ea,nea]\" or \"[snpid,p,ea,nea,chr,pos]\" None <code>cols_name_list_2</code> <code>list</code> \"[snpid,p,ea,nea]\" or \"[snpid,p,ea,nea,chr,pos]\" None <code>effect_cols_list_1</code> <code>list</code> \"[effect,se]\" or \"[OR,OR_95l,OR_95h]\" None <code>effect_cols_list_2</code> <code>list</code> \"[effect,se]\" or \"[OR,OR_95l,OR_95h]\" None <code>mode</code> <code>beta</code> or <code>OR</code> plot beta or OR <code>beta</code> <p>Note</p> <p>from v3.4.17, you need to specify the parameters using keywords instead of using them as positional arguments for <code>cols_name_list_1</code> and <code>cols_name_list_2</code>, <code>effect_cols_list_1</code> and <code>effect_cols_list_1</code> .</p>"},{"location":"EffectSize/#save-figures","title":"Save figures","text":"Option Type Description Default <code>save</code> <code>string</code> path to the saved file <code>./Sumstats1_Sumstats2_effect_comparison_plot.png</code> <code>save_args</code> <code>dict</code> parametrs for plt.savefig() <code>{\"dpi\":300,\"facecolor\":\"white\"}</code>"},{"location":"EffectSize/#snplist","title":"Snplist","text":"Option Type Description Default <code>snplist</code> <code>list</code> optional, specify the variants you want to compare. If None, GWASLab will automatically extract lead variants from both sumstats. None"},{"location":"EffectSize/#filter-by-maf","title":"Filter by maf:","text":"Option Type Description Default <code>eaf</code> <code>list</code> optional, a list column names for effect allele frequency, in the order of [sumstats1_eaf, sumstats2_eaf]. It is required when you need to filter by maf using <code>maf_level</code>. <code>None</code> <code>maf_level</code> <code>float</code> the maf filter for variants. Vairants with maf &lt; maf_level will be removed from comparison. <code>None</code>"},{"location":"EffectSize/#label","title":"Label","text":"Option Type Description Default <code>label</code> <code>list</code> a list of labels for the legend , in the order of [\"Sumstats_1\",\"Sumstats_2\",\"Both\",\"None\"] <code>[\"Sumstats_1\",\"Sumstats_2\",\"Both\",\"None\"]</code> <code>sig_level</code> <code>float</code> the significance level for auto-extracting lead variants. If <code>snplist</code> is provided, the auto-extraction will be skipped. <code>5e-8</code> <code>legend_title</code> <code>string</code> legend title <code>'$ P &lt; 5 x 10^{-8}$ in:'</code> <code>legend_pos</code> <code>string</code> legend position <code>upper left</code> <code>xylabel_prefix</code> <code>string</code> - <code>\"Per-allele effect size in \"</code>"},{"location":"EffectSize/#annotation","title":"Annotation","text":"Option Type Description Default <code>is_reg</code> <code>boolean</code> if true, draw regression line. <code>True</code> <code>is_45_helper_line</code> <code>boolean</code> if true, draw 45 degree line. <code>True</code> <code>anno</code> <code>boolean</code> if true, annotate the variants with ID. <code>False</code> <code>anno_diff</code> <code>float</code> threshold of effect size difference for annotation. <code>0</code> <code>anno_min1</code> <code>float</code> threshold of sumstats1 minimum absolute effect size for annotation. <code>0</code> <code>anno_min2</code> <code>float</code> threshold of sumstats2 minimum absolute effect size for annotation. <code>0</code>"},{"location":"EffectSize/#heterogeneity-test","title":"Heterogeneity test","text":"Option Type Description Default <code>is_q</code> <code>boolean</code> if true, apply the heterogeneity tests by Cochran's Q test. <code>True</code> <code>q_level</code> <code>float</code> the significance threshold for Cochran's Q test (raw p value). <code>0.05</code> <code>anno_het</code> annotate only variants with Phet &lt; <code>q_level</code> <code>False</code>"},{"location":"EffectSize/#r-se","title":"R SE","text":"Option Type Description Default <code>r_se</code> <code>boolean</code> If True, SE for r will be estimated using the jackknife method. (Note: available from v3.4.17) <code>False</code> \\[ s.e.(\\hat{r}_{jack}) = \\sqrt{ {{n-1}\\over{n}} \\sum_{i=1}^n(\\hat{r_i} -\\bar{r}_{jack} )^2 } \\]"},{"location":"EffectSize/#_1","title":"Effect Size Comparison","text":""},{"location":"EffectSize/#example","title":"Example:","text":"<p>Use gl.Sumstats object</p> <p><pre><code>gl1 = gl.Sumstats(\"bbj_bmi_female.txt.gz\",fmt=\"gwaslab\",snpid=\"SNP\",ea=\"REF\",nea=\"ALT\",sep=\"\\t\")\ngl2 = gl.Sumstats(\"bbj_bmi_male.txt.gz\",fmt=\"gwaslab\",snpid=\"SNP\",ea=\"REF\",nea=\"ALT\",sep=\"\\t\")\n\n# auto extract lead SNPs and compare the effect sizes\na = gl.compare_effect(path1= gl1,\n                      path2= gl2\n)\n</code></pre> </p> <p>Use pandas DataFrame</p> <pre><code>pd1 = pd.read_table(\"bbj_bmi_female.txt.gz\",sep=\"\\t\")\npd2 = pd.read_table(\"bbj_bmi_male.txt.gz\",sep=\"\\t\")\n\n# cols_name_list should be SNPID, P, Effect Allele, Non-Effect allele, Chromosome and Position\n# effect_cols_list should be BETA,SE\n\na = gl.compare_effect(path1 = pd1,\n                    cols_name_list_1 = [\"SNP\",\"P\",\"REF\",\"ALT\",\"CHR\",\"POS\"],effect_cols_list_1= [\"BETA\",\"SE\"],\n                    path2 = pd2,\n                    cols_name_list_2 = [\"SNP\",\"P\",\"REF\",\"ALT\",\"CHR\",\"POS\"],effect_cols_list_2= [\"BETA\",\"SE\"]\n                    )\n</code></pre> <p>Heterogeneity test</p> <p><pre><code>pd1 = pd.read_table(\"bbj_bmi_female.txt.gz\",sep=\"\\t\")\npd2 = pd.read_table(\"bbj_bmi_male.txt.gz\",sep=\"\\t\")\n\n# cols_name_list should be SNPID, P, Effect Allele, Non-Effect allele, Chromosome and Position\n# effect_cols_list should be BETA,SE\n# is_q : if true, apply the heterogeneity tests by Cochran's Q test.\n# q_level` : `float`, the significance threshold for Cochran's Q test (raw p value).\n\na = gl.compare_effect(path1 = pd1,\n                      cols_name_list_1 = [\"SNP\",\"P\",\"REF\",\"ALT\",\"CHR\",\"POS\"],effect_cols_list_1= [\"BETA\",\"SE\"],\n                      path2 = pd2,\n                      cols_name_list_2 = [\"SNP\",\"P\",\"REF\",\"ALT\",\"CHR\",\"POS\"],effect_cols_list_2= [\"BETA\",\"SE\"],\n                      is_q=True,\n                      q_level=0.05,\n                      legend_mode=\"full\"\n                      )\n</code></pre> </p> <p>Annotation</p> <p><pre><code>a = gl.compare_effect(path1=\"bbj_bmi_female.txt.gz\",\n                  cols_name_list_1=[\"SNP\",\"P\",\"REF\",\"ALT\",\"CHR\",\"POS\"],effect_cols_list_1=[\"BETA\",\"SE\"],\n                  path2=\"bbj_bmi_male.txt.gz\",\n                  cols_name_list_2=[\"SNP\",\"P\",\"REF\",\"ALT\",\"CHR\",\"POS\"],effect_cols_list_2=[\"BETA\",\"SE\"],\n                  label=[\"Female\",\"Male\",\"Both\",\"None\"],\n                  xylabel_prefix=\"Per-allele effect size for \",\n                  r_se=True, \n                  is_q=True, \n                  anno=True, \n                  anno_het=True, # only annotate variants with significant heterogeneity\n                  anno_diff=0.015,    # only annotate variants with a difference in effect size &gt; 0.015\n                  sig_level=5e-8,\n                  legend_title=r'$ P &lt; 5 x 10^{-8}$ in:',\n                  verbose=True)\n</code></pre> </p> <p>Male-specific and female-specific BMI Sumstats from JENGER</p> <pre><code>!wget -O bbj_bmi_male.txt.gz http://jenger.riken.jp/2analysisresult_qtl_download/\n!wget -O bbj_bmi_female.txt.gz http://jenger.riken.jp/4analysisresult_qtl_download/\n\nHeaders of the files : # SNP    CHR POS REF ALT Frq Rsq BETA    SE  P\n</code></pre> <p><pre><code># GWASLab will automatically extract significant variants from both sumstats. \na = gl.compare_effect(path1=\"bbj_bmi_female.txt.gz\",\n                  cols_name_list_1=[\"SNP\",\"P\",\"REF\",\"ALT\",\"CHR\",\"POS\"],effect_cols_list_1=[\"BETA\",\"SE\"],\n                  path2=\"bbj_bmi_male.txt.gz\",\n                  cols_name_list_2=[\"SNP\",\"P\",\"REF\",\"ALT\",\"CHR\",\"POS\"],effect_cols_list_2=[\"BETA\",\"SE\"],\n                  label=[\"Female\",\"Male\",\"Both\",\"None\"],\n                  xylabel_prefix=\"Per-allele effect size for \",\n                  anno=True,\n                  anno_het=True,\n                  anno_diff=0.015,\n                  sig_level=5e-8,\n                  legend_title=r'$ P &lt; 5 x 10^{-8}$ in:',\n                  verbose=True,\n                  save = \"myplot.png\",\n                  save_args= {\"dpi\":300,\"facecolor\":\"white\"}\n)\n</code></pre> </p> <p>Reference: Akiyama, M., Okada, Y., Kanai, M., Takahashi, A., Momozawa, Y., Ikeda, M., ... &amp; Kamatani, Y. (2017). Genome-wide association study identifies 112 new loci for body mass index in the Japanese population. Nature genetics, 49(10), 1458-1467.</p>"},{"location":"ExtractLead/","title":"Extract lead variants","text":"<p>GWASLab can extract the lead variants based on P values or MLOG10P values from identified significant loci using a sliding window, and return the result as a pandas.DataFrame or gl.Sumstats Object.</p>"},{"location":"ExtractLead/#1-get_lead","title":"1. get_lead()","text":"<pre><code>mysumstats.get_lead(\n           scaled=False,\n           windowsizekb=500,\n           sig_level=5e-8,\n           anno=False,\n           build=\"19\",\n           source=\"ensembl\",\n           verbose=True,\n           gls=False)\n</code></pre>"},{"location":"ExtractLead/#2-options","title":"2. Options","text":"<code>.get_lead()</code> options DataType Description Default <code>scaled</code> <code>boolean</code> If True, use MLOG10P for extraction instead of P values <code>False</code> <code>windowsizekb</code> <code>int</code> Specify the sliding window size in kb <code>500</code> <code>sig_level</code> <code>float</code> Specify the P value threshold <code>5e-8</code> <code>anno</code> <code>boolean</code> If True, annotate the lead variants with nearest gene names. <code>False</code> <code>source</code> <code>ensembl</code> or <code>refseq</code> When <code>anno=True</code>, annotate variants using gtf files from <code>ensembl</code> or <code>refseq</code> <code>ensembl</code> <code>build</code> <code>\"19\"</code> or <code>\"38\"</code> genome build version \"19\" or \"38\". <code>\"19\"</code> <code>verbose</code> <code>boolean</code> If True, print logs <code>True</code> <code>gls</code> <code>boolean</code> If True, return a new gl.Sumstats Object instead of pandas DataFrame <code>False</code> <p>Note</p> <p><code>.get_lead()</code> simply extract the lead variants of each significant loci. It is different from clumping.</p> <p>Note</p> <p>Please trying running <code>.basic_check()</code> to standardize the sumstats if there are any errors.</p> <p>Quote</p> <p>GWASLab basically adopted the definition for novel loci from Global Biobank Meta-analysis Initiative flagship paper. </p> <p>\"We defined genome-wide significant loci by iteratively spanning the \u00b1500 kb region around the most significant variant and merging overlapping regions until no genome-wide significant variants were detected within \u00b11 Mb.\" </p> <p>(Details are described in Zhou, W., Kanai, M., Wu, K. H. H., Rasheed, H., Tsuo, K., Hirbo, J. B., ... &amp; Study, C. O. H. (2022). Global Biobank Meta-analysis Initiative: Powering genetic discovery across human disease. Cell Genomics, 2(10), 100192. )</p> <p>GWASlab currently iteratively extends \u00b1 <code>windowsizekb</code> kb region around the most significant variant and merges overlapping regions until no genome-wide significant variants were detected within \u00b1 <code>windowsizekb</code>. (slightly different from the GBMI paper. When <code>windowsizekb=1000</code>, it is equvalent to GBMI's definition.)</p>"},{"location":"ExtractLead/#3-example","title":"3. Example","text":"<p>Example</p> <p>Sample sumstats: IS from pheweb.jp https://pheweb.jp/pheno/IS <pre><code>mysumstats = gl.Sumstats(\"./hum0197.v3.BBJ.IS.v1/GWASsummary_IS_Japanese_SakaueKanai2020.auto.txt.gz\",  fmt=\"saige\")\nmysumstats.get_lead()\n</code></pre> </p>"},{"location":"ExtractNovel/","title":"Checking if lead variants are novel or not","text":"<p>GWASLab can check if the lead variants of your summary statistics overlap with reported variants or not based on the physical distance.</p>"},{"location":"ExtractNovel/#1-get_novel","title":"1. get_novel()","text":"<pre><code>sumstats.get_novel(\n                    known,\n                    efo,\n                    only_novel=False,\n                    windowsizekb_for_novel=1000,\n                    windowsizekb=500,\n                    sig_level=5e-8,\n                    output_known=False)\n</code></pre> <p>GWASLab checks overlap with a local files of variants or records in GWASCatalog.</p> <p>Required (either):</p> <ul> <li><code>known</code> : <code>string</code>, path to local file of reported variants</li> </ul> <p>or </p> <ul> <li><code>efo</code> : <code>string</code>, efo id for the target trait, which is used for querying the GWASCatalog.</li> </ul>"},{"location":"ExtractNovel/#2-options","title":"2. Options:","text":"<code>.get_lead()</code> options DataType Description Default <code>windowsizekb</code> <code>int</code> Specify the sliding window size in kb <code>500</code> <code>sig_level</code> <code>float</code> Specify the P value threshold <code>5e-8</code> <code>windowsizekb_for_novel</code> <code>int</code> windowsize for determining if lead variants overlap with reported variants in GWASCatalog <code>1000</code> <code>only_novel</code> <code>boolean</code> output only novel variants <code>False</code> <code>output_known</code> <code>boolean</code> additionally output the reported variants <code>False</code> <code>verbose</code> <code>boolean</code> If True, print logs <code>True</code> <p>EFO ID</p> <p>You can find the efo id by simply searching in GWASCatalog. For example, the EFO ID for T2D can be obtained like:</p> <p></p>"},{"location":"ExtractNovel/#3-example-checking-with-gwascatalog-api","title":"3. Example: Checking with GWAScatalog API","text":"<p>Only works when your sumstats are based on GRCh38</p> <p>Only associations with the EFO trait will be obtained. This does not inlcude associations with child traits.</p> <p>Querying the GWAS Catalog</p> <pre><code># sample data\nReference : Suzuki, K., Akiyama, M., Ishigaki, K., Kanai, M., Hosoe, J., Shojima, N., ... &amp; Kadowaki, T. (2019). Identification of 28 new     susceptibility loci for type 2 diabetes in the Japanese population. Nature genetics, 51(3), 379-386.\n!wget -O t2d_bbj.txt.gz http://jenger.riken.jp/14/\n\n# load data and run a basic check\nmysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNP\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             se=\"SE\",\n             p=\"P\")\nmysumstats.basic_check()\n\n# liftover to grch38 (original sumstats are based on grch37)\nmysumstats.liftover(from_build=\"19\",to_build=\"38\")\n\n# run get_novel with efo id for type 2 diabetes mellitus\nmysumstats.get_novel(efo=\"MONDO_0005148\")\n\nFri Feb  3 12:11:44 2023 Start to check if lead variants are known...\nFri Feb  3 12:11:44 2023 Start to extract lead variants...\nFri Feb  3 12:11:44 2023  -Processing 1035234 variants...\nFri Feb  3 12:11:44 2023  -Significance threshold : 5e-08\nFri Feb  3 12:11:44 2023  -Sliding window size: 500  kb\nFri Feb  3 12:11:44 2023  -Found 9458 significant variants in total...\nFri Feb  3 12:11:45 2023  -Identified 89 lead variants!\nFri Feb  3 12:11:45 2023 Finished extracting lead variants successfully!\nFri Feb  3 12:11:45 2023 Start to retrieve data from GWASCatalog...\nFri Feb  3 12:11:45 2023  -Requesting (GET) trait information through the GWASCatalog API...\nFri Feb  3 12:11:45 2023  -EFO trait api: https://www.ebi.ac.uk/gwas/rest/api/efoTraits/MONDO_0005148\nFri Feb  3 12:11:46 2023  -Trait Name: type 2 diabetes mellitus\nFri Feb  3 12:11:46 2023  -Trait URL: http://purl.obolibrary.org/obo/MONDO_0005148\nFri Feb  3 12:11:46 2023  -Requesting (GET) GWAS associations through the GWASCatalog API...\nFri Feb  3 12:11:46 2023  -associationsByTraitSummary API: https://www.ebi.ac.uk/gwas/rest/api/efoTraits/MONDO_0005148/associations?    projection=associationByEfoTrait\nFri Feb  3 12:11:46 2023  -Note: this step might take a while...\nFri Feb  3 12:18:55 2023  -Status code 200 OK: Retrieved data from GWASCatalog successffully ...\nFri Feb  3 12:18:55 2023  -Loading json ...\nFri Feb  3 12:18:58 2023  -Parsing json ...\nFri Feb  3 12:18:58 2023  -Number of reported associations for MONDO_0005148 in GWASCatalog: 5345\nFri Feb  3 12:18:58 2023  -Loading retrieved data into gwaslab Sumstats object ...\nFri Feb  3 12:18:58 2023 GWASLab version 3.3.24 https://cloufield.github.io/gwaslab/\nFri Feb  3 12:18:58 2023 (C) 2022-2023, Yunye He, Kamatani Lab, MIT License, gwaslab@gmail.com\nFri Feb  3 12:18:58 2023   - format_name  : gwaslab\nFri Feb  3 12:18:58 2023   - format_source  : https://cloufield.github.io/gwaslab/\nFri Feb  3 12:18:58 2023   - format_version  : 20220729_v3\nFri Feb  3 12:19:00 2023 Finished retrieving data from GWASCatalog...\nFri Feb  3 12:19:00 2023  -Retrieved 4036 associations from GWAS catalog.\nFri Feb  3 12:19:00 2023  -Lead variants in known loci: 4036\nFri Feb  3 12:19:00 2023  -Checking the minimum distance between identified lead variants and provided known variants...\nFri Feb  3 12:19:00 2023  -Identified  89  known vairants in current sumstats...\nFri Feb  3 12:19:00 2023  -Identified  0  novel vairants in current sumstats...\nFri Feb  3 12:19:00 2023 Finished checking known or novel successfully!\n\nSNPID   CHR POS SE  P   MLOG10P STATUS  DISTANCE_TO_KNOWN   KNOWN_ID    KNOWN_PUBMED_ID KNOWN_AUTHOR    NOVEL   LOCATION_OF_KNOWN\n0   1:22068326_A_G  1   21741833    0.0103  1.629000e-09    8.788079    3860999 0   rs1825307   30718926    Suzuki K    False   Same\n1   1:51103268_T_C  1   50637596    0.0120  2.519000e-11    10.598772   3860999 0   rs12031188  30718926    Suzuki K    False   Same\n2   1:154309595_TA_T    1   154337119   0.0166  3.289000e-08    7.482936    3860999 1   rs68062313  30718926    Suzuki K    False       Upstream\n3   2:640986_CACAT_C    2   640986  0.0150  2.665000e-10    9.574303    3860999 1   rs72156956  30718926    Suzuki K    False   Upstream\n4   2:27734972_G_A  2   27512105    0.0088  3.897000e-15    14.409270   3860999 0   rs6547692   30718926    Suzuki K    False   Same\n... ... ... ... ... ... ... ... ... ... ... ... ... ...\n84  X:21569920_A_G  23  21551802    0.0076  2.616000e-08    7.582362    3860999 0   rs6633421   30718926    Suzuki K    False   Same\n85  X:48724648_CAA_C    23  48866248    0.0103  4.576000e-09    8.339514    3860999 1   rs782100977 30718926    Suzuki K    False       Upstream\n86  X:57170781_A_AT 23  57144348    0.0076  4.583000e-09    8.338850    3860999 1   rs144226500 30718926    Suzuki K    False   Upstream\n87  X:117915163_T_TA    23  118781200   0.0071  9.818000e-15    14.007977   3860999 1   rs11390176  30718926    Suzuki K    False       Upstream\n88  X:152908887_G_A 23  153643433   0.0077  9.197000e-58    57.036354   3860999 0   rs1894299   30718926    Suzuki K    False   Same\n</code></pre> <p>All of the lead variants are reported which is expected of course. </p> <p>Currently, there is a one-basepair difference in positions for indels. Please pay attention to the positions. ( It will be fixed later)</p> <p>Warning</p> <p>GWAS Catalog API is unstable sometimes.</p>"},{"location":"ExtractNovel/#4-example-checking-with-local-files","title":"4. Example: Checking with local files","text":"<p>Example</p> <p>Suppose we have a list of reported variants like:</p> <pre><code>cat ./toy_data/known_loci.txt\nCHR POS\n1 154309595\n1 51103268\n</code></pre> <pre><code>mysumstats.get_novel(known=\"./toy_data/known_loci.txt\")\n\nFri Feb  3 11:44:12 2023 Start to check if lead variants are known...\nFri Feb  3 11:44:12 2023 Start to extract lead variants...\nFri Feb  3 11:44:12 2023  -Processing 1035804 variants...\nFri Feb  3 11:44:12 2023  -Significance threshold : 5e-08\nFri Feb  3 11:44:12 2023  -Sliding window size: 500  kb\nFri Feb  3 11:44:12 2023  -Found 9461 significant variants in total...\nFri Feb  3 11:44:13 2023  -Identified 89 lead variants!\nFri Feb  3 11:44:13 2023 Finished extracting lead variants successfully!\nFri Feb  3 11:44:13 2023  -Lead variants in known loci: 2\nFri Feb  3 11:44:13 2023  -Checking the minimum distance between identified lead variants and provided known variants...\nFri Feb  3 11:44:13 2023  -Identified  2  known vairants in current sumstats...\nFri Feb  3 11:44:13 2023  -Identified  87  novel vairants in current sumstats...\nFri Feb  3 11:44:13 2023 Finished checking known or novel successfully!\n\nSNPID   CHR POS SE  P   MLOG10P STATUS  DISTANCE_TO_KNOWN   KNOWN_ID    NOVEL   LOCATION_OF_KNOWN\n0   1:22068326_A_G  1   22068326    0.0103  1.629000e-09    8.788079    9960999 29034942    1:51103268  True    Upstream\n1   1:51103268_T_C  1   51103268    0.0120  2.519000e-11    10.598772   9960999 0   1:51103268  False   Same\n2   1:154309595_TA_T    1   154309595   0.0166  3.289000e-08    7.482936    9960999 0   1:154309595 False   Same\n3   2:640986_CACAT_C    2   640986  0.0150  2.665000e-10    9.574303    9960999 &lt;NA&gt;    &lt;NA&gt;    True    NoneOnThisChr\n4   2:27734972_G_A  2   27734972    0.0088  3.897000e-15    14.409270   9960999 &lt;NA&gt;    &lt;NA&gt;    True    NoneOnThisChr\n... ... ... ... ... ... ... ... ... ... ... ...\n84  X:21569920_A_G  23  21569920    0.0076  2.616000e-08    7.582362    9960999 &lt;NA&gt;    &lt;NA&gt;    True    NoneOnThisChr\n85  X:48724648_CAA_C    23  48724648    0.0103  4.576000e-09    8.339514    9960999 &lt;NA&gt;    &lt;NA&gt;    True    NoneOnThisChr\n86  X:57170781_A_AT 23  57170781    0.0076  4.583000e-09    8.338850    9960999 &lt;NA&gt;    &lt;NA&gt;    True    NoneOnThisChr\n87  X:117915163_T_TA    23  117915163   0.0071  9.818000e-15    14.007977   9960999 &lt;NA&gt;    &lt;NA&gt;    True    NoneOnThisChr\n88  X:152908887_G_A 23  152908887   0.0077  9.197000e-58    57.036354   9960999 &lt;NA&gt;    &lt;NA&gt;    True    NoneOnThisChr\n</code></pre>"},{"location":"ExtractNovel/#reference","title":"Reference","text":"<ul> <li>Buniello, A., MacArthur, J. A. L., Cerezo, M., Harris, L. W., Hayhurst, J., Malangone, C., ... &amp; Parkinson, H. (2019). The NHGRI-EBI GWAS Catalog of published genome-wide association studies, targeted arrays and summary statistics 2019. Nucleic acids research, 47(D1), D1005-D1012.</li> </ul>"},{"location":"ForestPlot/","title":"Coming soon","text":""},{"location":"Format/","title":"Output sumstats in certain formats","text":"<p>GWASLab provides a flexible formatting and saving function.</p>"},{"location":"Format/#1-usage","title":"1. Usage","text":"<pre><code>.to_format(\n          path=\"./sumstats\",\n          fmt=\"ldsc\",   \n          ...\n          )\n</code></pre>"},{"location":"Format/#2-options","title":"2. Options","text":"<code>.to_format()</code> options DataType Description Default <code>path</code> <code>string</code> the path for the output file; only prefix is needed. <code>\"./sumstats\"</code> <code>fmt</code> <code>string</code> output format for sumstats. Currently support <code>plink</code> ,<code>plink2</code>, <code>ldsc</code>, <code>saige</code>, <code>fastgwa</code>, <code>regenie</code> and so forth. For details , please check  https://github.com/Cloufield/formatbook. <code>\"gwaslab\"</code> <code>cols</code> <code>list</code> list of additional columns to linclude in the output <code>None</code> <code>extract</code> <code>list</code> a list of variant SNPIDs to include. <code>None</code> <code>exclude</code> <code>list</code> a list of variant SNPIDs to exclude. <code>None</code> <code>id_use</code> <code>SNPID</code> or <code>rsID</code> specify which ID to use when excluding or extracting variants. <code>rsID</code> <code>hapmap3</code> <code>boolean</code> If True, only output Hapmap3 SNPs. <code>False</code> <code>exclude_hla</code> <code>boolean</code> if True, exclude variants in the MHC region from the output. <code>False</code> <code>hla_range</code> <code>tuple</code> a tuple of 2 numbers (MBp) indicating the start and the end position of the HLA region. <code>(25,34)</code> <code>build</code> <code>string</code> reference genome build. <code>\"19\"</code> <code>xymt_number</code> <code>boolean</code> if True, output sex chromosomes as X/Y/MT \"False\" <code>xymt</code> <code>list</code> 3-element list of sex chromosome notations to indicate how to convert integers to sex chromosome <code>[\"X\",\"Y\",\"MT\"]</code> <code>chr_prefix</code> <code>string</code> Add a prefix to chromosomes. For example, 6 -&gt; Chr6. <code>\"\"</code> <code>bgzip</code> <code>boolean</code> If True, bgzip the output file. Only works for bed and vcf format. - <code>tabix</code> <code>boolean</code> If True, use tabix to index the bgzipped output file. Only works for bed and vcf format. - <code>tabix_indexargs</code> <code>dict</code> extra parameters for pysam.tabix_index() <code>{}</code> <code>md5sum</code> <code>boolean</code> If True, calculate and output the file MD5 hashes <code>False</code> <code>to_csvargs</code> <code>dict</code> extra parameters for pd.to_csv() <code>None</code> <code>float_formats</code> <code>dict</code> a dictionary to specify the float format for each column. <code>None</code> <code>verbose</code> <code>boolean</code> If True, print logs. <code>True</code> <code>output_log</code> <code>boolean</code> If True, save the log to a file. <code>True</code> <code>ssfmeta</code> <code>boolean</code> If True, output a gwas-ssf-style meta file. <code>False</code>"},{"location":"Format/#3-format-dictionary","title":"3. Format dictionary","text":"<p>Using <code>float_formats</code>, you can specify the formats for numbers.</p> <p>Default formats for floating-point numbers</p> <pre><code>{'EAF': '{:.4g}', 'BETA': '{:.4f}', 'Z': '{:.4f}','CHISQ': '{:.4f}','SE': '{:.4f}','OR': '{:.4f}','OR_95U': '{:.4f}','OR_95L': '{:.4f}','INFO': '{:.4f}','P': '{:.4e}','MLOG10P': '{:.4f}','DAF': '{:.4f}'}\n</code></pre>"},{"location":"Format/#4-examples","title":"4. Examples","text":""},{"location":"Format/#41-common-tabular-formats","title":"4.1 Common tabular formats","text":"<p>GWASLab support commonly used tabular formats, which are listed in a companion repository <code>formatbook</code>.</p> <p>formatbook</p> <p>for more details, please check formatbook ssf: GWAS-SSF format gwascatalog : GWAS Catalog format pgscatalog : PGS Catalog format plink: PLINK output format plink2: PLINK2 output format saige: SAIGE output format regenie: output format fastgwa: output format metal: output format mrmega: output format fuma: input format ldsc: input format locuszoom: input format vcf: gwas-vcf format bolt_lmm : output format</p> <p>output metal format</p> <pre><code>import gwaslab as gl\n# load your raw sumstats\nmysumstats = gl.Sumstats(...)\n# basic QC\nmysumstats.basic_check()\n# output metal format\nmysumstats.to_format(\"./test\",fmt=\"metal\")\n\nTue Sep 13 18:00:41 2022 Start to format the output sumstats in:  metal  format\nTue Sep 13 18:00:41 2022  -Formatting statistics ...\nTue Sep 13 18:00:41 2022  - Float statistics formats:\nTue Sep 13 18:00:41 2022   - Columns: ['EAF', 'BETA', 'SE', 'P']\nTue Sep 13 18:00:41 2022   - Output formats: ['{:.4g}', '{:.4f}', '{:.4f}', '{:.4e}']\nTue Sep 13 18:00:41 2022  - Start outputting sumstats in metal format...\nTue Sep 13 18:00:41 2022  -metal format will be loaded...\nTue Sep 13 18:00:41 2022  -metal format meta info:\nTue Sep 13 18:00:41 2022   - format_name  :  metal\nTue Sep 13 18:00:41 2022   - format_source  :  https://genome.sph.umich.edu/wiki/METAL_Documentation\nTue Sep 13 18:00:41 2022   - format_version  :  20220726\nTue Sep 13 18:00:41 2022  -gwaslab to metal format dictionary:\nTue Sep 13 18:00:41 2022   - gwaslab keys: ['SNPID', 'EA', 'NEA', 'EAF', 'BETA', 'SE', 'P', 'DIRECTION']\nTue Sep 13 18:00:41 2022   - metal values: ['MarkerName', 'Allele1', 'Allele2', 'Freq1', 'Effect', 'StdErr', 'P-value', 'Direction']\nTue Sep 13 18:00:41 2022  -Output columns: Index(['MarkerName', 'Allele1', 'Allele2', 'Freq1', 'Effect', 'StdErr',\n       'P-value'],\n      dtype='object')\nTue Sep 13 18:00:41 2022  -Output path: ./test.metal.tsv.gz\nTue Sep 13 18:00:41 2022  -Saving log file: ./test.metal.log\nTue Sep 13 18:00:41 2022 Finished outputting successfully!\n</code></pre>"},{"location":"Format/#42-ldsc-format","title":"4.2 LDSC format","text":"<p>LDSC format; extract hapmap3 SNPs and exclude SNPs in HLA region</p> <pre><code>## format the sumstats to ldsc format\n## extract only hapmap3 SNPs\n## exclude SNPs in HLA region\nmysumstats.to_format(\"./test\",fmt=\"ldsc\", hapmap3=True, exclude_hla=False, build=\"19\")\n</code></pre>"},{"location":"Format/#43-gwas-vcf-format","title":"4.3 GWAS VCF format","text":"<p>GWAS-VCF format</p> <pre><code># output vcf file, and then bgzip and index the file.\nmysumstats.to_format(\"./test\",fmt=\"vcf\",bgzip=True,tabix=True)\n</code></pre>"},{"location":"Format/#44-gwas-ssf-format","title":"4.4 GWAS-SSF format","text":"<p>GWAS-ssf format</p> <pre><code># output  GWAS-ssf format\nmysumstats.to_format(\"./test\",fmt=\"ssf\")\n</code></pre>"},{"location":"Format/#45-bed-format","title":"4.5 BED format","text":"<p>BED-like format for variant information</p> <pre><code># output 1-based bed-like files for vep\nmysumstats.to_format(\"./test\",fmt=\"vep\",xymt_number=True,chr_prefix=\"Chr\")\n\n# output 0-based bed-like file, and then bgzip and index the file.\nmysumstats.to_format(\"./test\",fmt=\"bed\",bgzip=True,tabix=True)\n</code></pre>"},{"location":"Gallery/","title":"GWASLab Gallery","text":""},{"location":"Gallery/#manhattan-and-q-q-plot","title":"Manhattan and Q-Q plot","text":""},{"location":"Gallery/#regional-plot","title":"Regional plot","text":""},{"location":"Gallery/#brisbane-plot","title":"Brisbane plot","text":""},{"location":"Gallery/#miami-plot","title":"Miami plot","text":""},{"location":"Gallery/#effect-size-comparison-scatter-plot","title":"Effect size comparison scatter plot","text":""},{"location":"Gallery/#genetic-correlation-heatmap","title":"Genetic correlation heatmap","text":""},{"location":"Gallery/#allele-frequency-comparison-scatter-plot","title":"Allele frequency comparison scatter plot","text":""},{"location":"GeneticCorrelation/","title":"Genetic correlation loading and plotting","text":""},{"location":"GeneticCorrelation/#heatmap-genetic-correlation-matrix","title":"Heatmap: Genetic correlation matrix","text":"<p>Available since v3.4.15</p> <pre><code>gl.plot_rg(ldsc)\n</code></pre> <p>Simple plot</p> <pre><code># load ldsc log files\nldsc_log_file_list = [\"ldscrg.log\"] \n\nldsc = gl.read_ldsc(ldsc_log_file_list, mode=\"rg\")\n\ngl.plot_rg( ldsc )\n</code></pre> <p></p> <p>Options:</p> <ul> <li><code>ldscrg</code> : <code>DataFrame</code>, results from ldsc-rg. 4 columns are required, <code>p1</code>,<code>p2</code>,<code>p</code>,<code>rg</code>.</li> <li><code>p1</code>: <code>string</code>, column name for trait1, defaul: <code>p1</code></li> <li><code>p2</code>: <code>string</code>, column name for trait2 defaul: <code>p2</code></li> <li><code>rg</code>: <code>string</code>, column name for rg defaul: <code>rg</code></li> <li><code>p</code>: <code>string</code>, column name for p defaul: <code>p</code></li> <li><code>sig_levels</code>: <code>list</code>, default: <code>[0.05]</code></li> <li><code>panno</code>: <code>boolean</code>, default: <code>True</code></li> <li><code>corrections</code>: <code>list</code>,<code>non</code> no correction, <code>fdr</code> FDR, <code>bon</code> bonferroni , default: <code>[\"non\",\"fdr\",\"bom\"]</code></li> <li><code>panno_texts</code>: <code>list</code>, text to annotate significant correlations, match the number of <code>corrections</code> times the number of <code>sig_levels</code>, default: <code>[\"*\",\"**\",\"***\"]</code></li> <li><code>sort_key</code>: <code>function</code>, sort the columns , default: <code>None</code></li> <li><code>equal_aspect</code>: <code>`, defaul:</code>True`</li> <li><code>fontsize</code>: <code>`, defaul:</code>10`</li> <li><code>save</code>: <code>string</code> or <code>boolean</code>, defaul: <code>None</code></li> <li><code>save_args</code>: <code>dict</code>, defaul: <code>None</code></li> <li><code>full_cell</code>: <code>tuple</code>, threshold for full cell, default: <code>(\"fdr\",0.05)</code></li> <li><code>yticklabel_args</code>: <code>dict</code>, default: <code>{\"fontsize\":10}</code></li> <li><code>xticklabel_args</code>: <code>dict</code>, default: <code>{\"rotation\":45,\"horizontalalignment\":\"left\", \"verticalalignment\":\"bottom\",\"fontsize\":10}</code></li> <li><code>colorbar_args</code> :  <code>dict</code> , default:<code>{\"shrink\":0.82}</code></li> <li><code>cmap</code>: <code>cmap</code>, default:<code>matplotlib.cm.get_cmap('RdBu')</code></li> </ul> <p>Customized plot</p> <pre><code># or load from tabular files\nldsc = pd.read_csv(\"toy_data/input_rg.txt\",sep=\"\\t\")\nldsc\n#prepare the final dataset\ntrait =  pd.read_csv(\"toy_data/trait_list.txt\",sep=\"\\t\")\ntrait[\"order\"] = range(len(trait))\norder = trait[\"TRAIT\"].values\ntrait_set1 = trait.loc[trait[\"order\"]&gt;=59,\"TRAIT\"].values\ntrait_set2 = trait.loc[trait[\"order\"]&lt;59,\"TRAIT\"].values\nldsc = ldsc.loc[((ldsc[\"p1\"].isin(trait_set1))&amp;(ldsc[\"p2\"].isin(trait_set2))) | ((ldsc[\"p1\"].isin(trait_set2))&amp;(ldsc[\"p2\"].isin(trait_set1))),:]\nmap_dic={order[i]:i+1 for i in range(len(order))}\nkey=lambda x:x.map(map_dic)\n\n# plot\ndf = gl.plot_rg( ldsc,\n            sig_levels=[0.05],\n            corrections =[\"non\"],\n            p=\"q\",\n            p1=\"p2\",\n            p2=\"p1\",\n            full_cell=(\"non\",0.05),\n            panno_texts=[\"*\"],\n            fig_args={\"figsize\":(15,15),\"dpi\":300},\n            colorbar_args={\"shrink\":0.4},\n            panno_args={\"size\":12,\"c\":\"black\"},fdr_method=\"i\",\n            fontsize=8,\n            sort_key=key\n            )\n</code></pre> <p></p> <p>sample data source: https://github.com/mkanai/ldsc-corrplot-rg , Kanai, M., Akiyama, M., Takahashi, A., Matoba, N., Momozawa, Y., Ikeda, M., ... &amp; Kamatani, Y. (2018). Genetic analysis of quantitative traits in the     Japanese population links cell types to complex human diseases. Nature genetics, 50(3), 390-400.</p>"},{"location":"Harmonization/","title":"Harmonization","text":"<p>GWASLab provides reference-dependent harmonization functions.</p>"},{"location":"Harmonization/#1-methods-summary","title":"1. Methods summary","text":"Sumstats Methods Options Description <code>.check_ref()</code> <code>ref_path</code>, <code>chr_dict=get_chr_to_number()</code> Check alignment with a reference sequence <code>.assign_rsid()</code> <code>ref_rsid_tsv</code>, <code>ref_rsid_vcf</code>, <code>n_cores=1</code>, <code>chunksize=5000000</code>, <code>chr_dict=get_number_to_chr()</code>, <code>overwrite=\"empty\"</code> Annotate rsid using a reference vcf file <code>.infer_strand()</code> <code>ref_infer</code>,<code>ref_alt_freq=None</code>,<code>maf_threshold=0.40</code>,<code>remove_snp=\"\"</code>,<code>mode=\"pi\"</code>,<code>n_cores=1</code>,<code>remove_indel=\"\"</code> Infer the strand of a variant using reference vcf file with EAF in INFO <code>.check_daf()</code> <code>ref_infer</code>,<code>ref_alt_freq=None</code>,<code>maf_threshold=0.40</code>,<code>n_cores=1</code> Calculate difference in allele frequencies <code>.flip_allele_stats()</code> After alignment and inferring, flip the alleles to harmonise the variants. <code>.harmonize()</code> <code>basic_check=True</code>,  <code>ref_seq=None</code>,<code>ref_rsid_tsv=None</code>,<code>ref_rsid_vcf=None</code>,<code>ref_infer=None</code>,<code>ref_alt_freq=None</code>,<code>maf_threshold=0.40</code>,<code>n_cores=1</code>,<code>remove=False</code>,<code>checkref_args={}</code>,<code>removedup_args={}</code>,<code>assignrsid_args={}</code>,<code>inferstrand_args={}</code>,<code>flipallelestats_args={}</code>,<code>fixid_args={}</code>,<code>fixchr_agrs={}</code>,<code>fixpos_args={}</code>,<code>fixallele_args={}</code>,<code>sanitycheckstats_args={}</code>,<code>normalizeallele_args={}</code> all-in-one function for harmonization"},{"location":"Harmonization/#2-align-nea-with-ref-in-the-reference-genome","title":"2. Align NEA with REF in the reference genome","text":"<p><code>.check_ref()</code>:  Check if NEA is aligned with the reference sequence. After checking, the tracking status code will be changed accordingly. </p> <p>Example</p> <pre><code>mysumstats.check_ref(ref_path=\"ref_genome.fa\")\nmysumstats.flip_allele_stats()\n</code></pre> <p>Note</p> <p><code>check_ref()</code> only change the status code. Use flip function <code>.flip_allele_stats()</code> to flip the allele-specific stats.</p>"},{"location":"Harmonization/#3-assign-rsid-according-to-chr-pos-refalt","title":"3. Assign rsID according to CHR, POS, REF/ALT","text":"<p><code>.assign_rsid()</code> : Annotated variants with rsID using a reference tsv file (1KG variants) and reference vcf file (tabix indexed, entire dbSNP).</p> <p>Example</p> <pre><code>mysumstats.assign_rsid(ref_rsid_tsv, ref_rsid_vcf, n_cores=1)\n</code></pre> <ul> <li>For tsv file, variants will be matched using SNPID (CHR:POS:NEA:EA) for quick assigning.</li> <li>For VCF file, GWASLab will first extract all variants in the reference file with matching CHR and POS. And then compare EA/NEA in sumstats with REF/ALT in reference vcf. When matching, it will annotate the variant in sumstats with the matching rsID in reference vcf.  </li> </ul>"},{"location":"Harmonization/#4-check-palindromic-snps-or-indistinguishable-indels","title":"4. Check palindromic SNPs or indistinguishable Indels","text":"<p><code>.infer_strand()</code>:</p> <ul> <li>Infer the strand for palindromic SNPs (AT, or CG), the default threshold is 0.40. </li> <li>Checking the alignment status of indels with the REF allele in a reference vcf file.</li> </ul> <p>Example</p> <pre><code>mysumstats.infer_strand()\nmysumstats.flip_allele_stats()\n</code></pre> <p>Note</p> <p><code>infer_strand()</code> only change the status code. Use filp function <code>.flip_allele_stats()</code> to filp the allele-specific stats.</p>"},{"location":"Harmonization/#5-check-the-difference-in-allele-frequency","title":"5. Check the difference in allele frequency","text":"<p><code>.check_daf()</code> : check the allele frequency discrepancy with a reference vcf. Please make sure your sumstats are already harmonized, and the variants in reference VCF are also aligned. gwaslab will retrieve information only for matched variants (CHR, POS, EA-ALT, and NEA-REF).</p> <p><code>ref_infer</code>: reference VCF file path. <code>ref_alt_freq</code>:  allele frequency for ALT in the INFO field of reference VCF file. <code>n_cores</code>: number of cores to use.</p> <p>Example</p> <pre><code>mysumstats.check_af(ref_infer=gl.get_path(\"1kg_eas_hg19\"), \n                    ref_alt_freq=\"AF\",\n                    n_cores=2)\n</code></pre> <p>DAF : Difference between Effect allele frequency and Reference ALT frequency EAF: Effect allele frequency RAF: Reference ALT allele frequency</p> <p>You may want to check the allele frequency discrepancy with a reference VCF. Just specify the path and the right allele frequency for your target ancestry in INFO field.</p>"},{"location":"Harmonization/#6-allele-frequency-correlation-plot","title":"6. Allele frequency correlation plot","text":"<p>GWASlab will simply calculate DAF = AF-EAF - AF-ALT , and store the results in DAF column. DAF can then be used for plotting (<code>.plot_daf()</code>) or filter variants.</p> <p>Example</p> <pre><code>mysumstats.plot_daf(threshold=0.12)\n</code></pre> <p></p>"},{"location":"Harmonization/#7-flipping-based-on-status-code","title":"7. Flipping based on status code","text":"<p><code>.flip_allele_stats()</code> :  Flip allele-specific statistics to harmonize the variants based on the tracking status code. </p> <p>Example</p> <pre><code>mysumstats.check_ref(ref_path=\"ref_genome.fa\")\nmysumstats.flip_allele_stats()\n\nmysumstats.infer_strand()\nmysumstats.flip_allele_stats()\n</code></pre>"},{"location":"Harmonization/#8-assign-chr-and-pos-according-to-rsid-and-reference-data","title":"8. Assign CHR and POS according to rsID and reference data","text":"<pre><code>mysumstats.rsid_to_chrpos()  \n</code></pre>"},{"location":"HeritabilityConversion/","title":"Heritability conversion","text":"<p>GWASLab can convert Observed-scale heritability to Liability-scale heritability. </p> <p>Quote</p> <p>Conversion formula (Equation 23 from Lee. 2011): $$ h^2_{liability-scale} = h^2_{observed-scale} * {{K(1-K)}\\over{Z^2}} *  {{K(1-K)}\\over{P(1-P)}} $$</p> <ul> <li>\\(K\\) : Population disease prevalence.</li> <li>\\(P\\) : Sample disease prevalence.</li> <li>\\(Z\\) : The height of the standard normal probability density function at threshold T. <code>scipy.stats.norm.pdf(T, loc=0, scale=1)</code>.</li> <li>\\(T\\) : The threshold. <code>scipy.stats.norm.ppf(1 - K, loc=0, scale=1)</code> or <code>scipy.stats.norm.isf(K)</code>.</li> </ul> <p>Reference: Estimating Missing Heritability for Disease from Genome-wide Association Studies https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059431/</p>"},{"location":"HeritabilityConversion/#usage","title":"Usage","text":"<pre><code>gl.h2_obs_to_liab(h2_obs, P, K, se_obs=None)\n</code></pre>"},{"location":"HeritabilityConversion/#parameters","title":"Parameters","text":"<ul> <li><code>h2_obs</code> : float. Heritability on the observed scale in an ascertained sample. </li> <li><code>P</code> : float in (0,1). Prevalence of the phenotype in the sample. </li> <li><code>K</code> : float in (0,1) . Prevalence of the phenotype in the population. </li> <li><code>se_obs</code> : float. se of h2_obs.</li> </ul> <p>Quote</p> <p>Codes were adopted from LDSC. </p> <p>Reference : Bulik-Sullivan, B. K., Loh, P. R., Finucane, H. K., Ripke, S., Yang, J., Patterson, N., ... &amp; Neale, B. M. (2015). LD Score regression distinguishes confounding from polygenicity in genome-wide association studies. Nature genetics, 47(3), 291-295.</p>"},{"location":"InferBuild/","title":"Infer Genome Build","text":"<p>GWASLab use the chromosome and basepair position information for Hapmap3 SNPs to infer the reference genome build for sumstats.</p> <p>Reference genome build will be simply assigned based on the matching count. (Note: the results are more reliable if you have more than 10,000 variants)</p> <p>Status codes (first two digits) will be changed based on the matching results.</p> <p>Example</p> <pre><code>mysumstats.infer_build()\n\nWed Oct 19 11:01:01 2022  -Start to infer genome build version using hapmap3 SNPs...\nWed Oct 19 11:01:01 2022  -Loading Hapmap3 variants data...\nWed Oct 19 11:01:04 2022  -chr:pos will be used for matching...\nWed Oct 19 11:01:33 2022  -Matching variants for hg19: num_hg19= 1092441\nWed Oct 19 11:01:33 2022  -Matching variants for hg38: num_hg38= 15997\nWed Oct 19 11:01:33 2022  -Since num_hg19&gt;num_hg38, assigning genome build hg19...\n</code></pre>"},{"location":"KnownIssues/","title":"Known issues","text":""},{"location":"KnownIssues/#p-value-conversion-during-extracting-lead-variants","title":"P value conversion during extracting lead variants","text":"<ul> <li>gwaslab&lt;=3.4.18 : In older versions, gwaslab converts MLOG10P to P (if P column is not available) and then uses P to extract lead variants using <code>.get_lead()</code>. But during conversion, since MLOG10P was set as float32, and then P was accordingly set as float32. The minimum of float32 is around 1e-38, below which P values will become 0. This could cause error when extracting lead variants. </li> <li>Solution: simply use scaled=True to directly use MLOG10P instead of P values.</li> </ul>"},{"location":"LiftOver/","title":"Liftover","text":"<p>GWASLab can directly liftover the positions of variants in sumstats.</p>"},{"location":"LiftOver/#1-usage","title":"1. Usage","text":"<pre><code>mysumstats.liftover(n_cores=3, \n                    from_build=\"19\", \n                    to_build=\"38\",\n                    remove=True)\n</code></pre> <p>Note</p> <p>GWASLab will only liftover basepair positions. If needed, please perform harmonization using the reference file of the target build.  </p>"},{"location":"LiftOver/#2-options","title":"2. Options","text":"<code>.liftover()</code> options DataType Description Default <code>n_cores</code> <code>interger</code> Number of threads to use for liftover. <code>1</code> <code>from_build</code> <code>\"19\"</code> or <code>\"38\"</code> Original genome build - <code>to_build</code> <code>\"19\"</code> or <code>\"38\"</code> Target genome build - <code>remove</code> <code>boolean</code> If True, remove unmapped variants <code>True</code> <p>Quote</p> <p>This method is based on GitHub - jeremymcrae/liftover: liftover for python, made fast with cython</p>"},{"location":"LiftOver/#3-example","title":"3. Example","text":"<p>Example</p> <pre><code>mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNP\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             ea=\"ALT\",\n             nea=\"REF\",\n             neaf=\"Frq\",\n             beta=\"BETA\",\n             se=\"SE\",\n             p=\"P\")\nmysumstats.basic_check()\nmysumstats.liftover(n_cores=3, from_build=\"19\", to_build=\"38\")\n</code></pre>"},{"location":"LoadLDSC/","title":"Batch load LDSC log file","text":"<p>GWASLab provides a standalone function for batch loading ldsc log file into a <code>pd.DataFrame</code>. </p> <p>GWASLab uses regular expression to match the values and fill them into a dataframe.</p> <p><code>gl.read_ldsc()</code> </p>"},{"location":"LoadLDSC/#usage","title":"Usage","text":"<pre><code>gl.read_ldsc(filelist, mode=\"h2\")\n</code></pre>"},{"location":"LoadLDSC/#opions","title":"Opions","text":"<ul> <li><code>filelist</code> : <code>list</code> .A list of paths to ldsc log files</li> <li><code>mode</code> : <code>string</code>. <code>h2</code> or <code>rg</code>.  </li> </ul>"},{"location":"LoadLDSC/#example","title":"Example","text":"<p>Example</p> <pre><code>#mode=h2\npaths = [\n    '/home/he/work/GWASTutorial/08_LDSC/BBJ_HDLC.log',\n    '/home/he/work/GWASTutorial/08_LDSC/BBJ_LDLC.log'\n]\n\ndf = gl.read_ldsc(ldsc_file_list, mode=\"h2\")\n\nLoading file 1 :/home/he/work/GWASTutorial/08_LDSC/BBJ_HDLC.log ...\nLoading file 2 :/home/he/work/GWASTutorial/08_LDSC/BBJ_LDLC.log ...\n\ndf\nFilename    h2_obs  h2_se   Lambda_gc   Mean_chi2   Intercept   Intercept_se    Ratio   Ratio_se\nBBJ_HDLC.log    0.1583  0.0281  1.1523  1.2843  1.0563  0.0114  0.1981  0.0402\nBBJ_LDLC.log    0.0743  0.0123  1.0833  1.1465  1.0296  0.0107  0.2019  0.0727\n</code></pre> <p>Example</p> <pre><code>#mode=rg\n\npaths = [\n    '/home/he/work/GWASTutorial/08_LDSC/BBJ_HDLC_LDLC.log',\n]\n\ndf = gl.read_ldsc(paths, mode=\"rg\")\nLoading file 1 :/home/he/work/GWASTutorial/08_LDSC/BBJ_HDLC_LDLC.log ...\n\ndf\np1  p2  rg  se  z   p   h2_obs  h2_obs_se   h2_int  h2_int_se   gcov_int    gcov_int_se\nBBJ_HDLC.sumstats.gz    BBJ_LDLC.sumstats.gz    0.1601  0.1821  0.8794  0.3792  0.0543  0.0211  1.0583  0.0335  -0.0198 0.0121\n</code></pre>"},{"location":"LoadLDSC/#plot-ldsc-rg-under-construction","title":"plot ldsc rg (under construction)","text":"<p>For genetic correlation, after loading, you can use <code>gl.plot_rg()</code> to plot a heat map to visualize the results. No extra manipulation needed.</p> <pre><code>gl.plot_rg(myldscrg)\n</code></pre>"},{"location":"MiamiPlot/","title":"Miami plot","text":"<p>Implemented since v3.3.4</p> <p>As a standalone function, GWASLab can plot miami plot given a pair of sumstats files.</p>"},{"location":"MiamiPlot/#usage","title":"Usage","text":"<pre><code>gl.plot_miami( \n          path1,\n          path2,\n          cols1=[\"CHR\",\"POS\",\"P\"],\n          cols2=[\"CHR\",\"POS\",\"P\"],\n          sep=[\"\\t\",\"\\t\"],\n          anno= None\n          )\n</code></pre> Option DataType Description Default <code>path1</code> <code>string</code>, <code>pd.DataFrame</code>, or <code>gl.Sumstats</code> path to sumstats1, or pd.DataFrame object, or gl.Sumstats Object - <code>path2</code> <code>string</code>, <code>pd.DataFrame</code>, or <code>gl.Sumstats</code> path to sumstats2, or pd.DataFrame object, or gl.Sumstats Object - <code>cols1</code> <code>list</code> CHR,POS,P names for sumstats1 <code>[\"CHR\",\"POS\",\"P\"]</code> <code>cols2</code> <code>list</code> CHR,POS,P names for sumstats2 <code>[\"CHR\",\"POS\",\"P\"]</code> <code>sep</code> <code>list</code> separator for each sumstats (when path is <code>string</code>) <code>[\"\\t\",\"\\t\"]</code> <code>anno</code> <code>boolean</code> or <code>GENENAME</code> if True, annotate <code>CHR:POS</code>; if <code>GENENAME</code>, annotate gene name <code>None</code> <code>region</code> <code>tuple</code> only plot a region. For example, <code>region=(2,2153874,21753874)</code> <code>None</code> <code>highlight</code> <code>list</code> list of loci (tuples of CHR and POS) to highlight for both sumstats. For example, <code>highlight=[(2,2153874),(5,124289158)]</code> <code>None</code> <code>highlight1</code> <code>list</code> list of loci (tuples of CHR and POS) to highlight for sumstats1. For example, <code>highlight1=[(2,2153874),(5,124289158)]</code> <code>None</code> <code>highlight2</code> <code>list</code> list of loci (tuples of CHR and POS) to highlight for sumstats2. For example, <code>highlight2=[(2,2153874),(5,124289158)]</code> <code>None</code> <code>highlight_windowkb</code> <code>int</code> window size for highlighting loci <code>500</code> <code>highlight_color</code> <code>color</code> color for highlighting loci <code>\"#CB132D\"</code> <code>pinpoint</code> <code>list</code> list of variants (tuples of CHR and POS) to pinpoint for both sumstats.  For example, <code>pinpoint=[(2,2153874),(5,124289158)]</code> <code>None</code> <code>pinpoint1</code> <code>list</code> list of variants (tuples of CHR and POS) to pinpoint for sumstats1.  For example, <code>pinpoint1=[(2,2153874),(5,124289158)]</code> <code>None</code> <code>pinpoint2</code> <code>list</code> list of variants (tuples of CHR and POS) to pinpoint for sumstats2.  For example, <code>pinpoint2=[(2,2153874),(5,124289158)]</code> <code>None</code> <code>pinpoint_color</code> <code>color</code> color for highlighting loci <code>\"red\"</code> <code>anno_set</code> <code>list</code> list of variants (tuples of CHR and POS) to annotate for both sumstats.  For example, <code>anno_set=[(2,2153874),(5,124289158)]</code> <code>None</code> <code>anno_set1</code> <code>list</code> list of variants (tuples of CHR and POS) to annotate for sumstats1.  For example, <code>anno_set1=[(2,2153874),(5,124289158)]</code> <code>None</code> <code>anno_set2</code> <code>list</code> list of variants (tuples of CHR and POS) to annotate for sumstats2.  For example, <code>anno_set2=[(2,2153874),(5,124289158)]</code> <code>None</code> <code>titles</code> <code>list</code> titles for sumstats. For example,<code>titles=[\"male\",\"female\"]</code> <code>[\"\",\"\"]</code> <code>titles_pad</code> <code>list</code> paddings for titles <code>[0.2,0.2]</code> <code>build</code> <code>list</code> genome build for annotate gene names. For example,<code>titles=[\"male\",\"female\"]</code> <code>\"19\"</code> <code>save</code> <code>boolean</code> or <code>string</code> if true, save to default path. if string, save to path specified by string <code>True</code> <code>save_args</code> <code>dict</code> additional parameters for <code>plt.save_fig</code> <code>{\"dpi\":100,\"facecolor\":\"white\"}</code>"},{"location":"MiamiPlot/#example","title":"Example","text":"<p>Miami plot for male- amd female-specific GWAS on BMI</p> <p>Sample datasets are obtained from JENGER:</p> <pre><code>!wget -O bmi_male_bbj.txt.gz http://jenger.riken.jp/2analysisresult_qtl_download/\n!wget -O bmi_female_bbj.txt.gz http://jenger.riken.jp/4analysisresult_qtl_download/\n</code></pre> <pre><code>mysumstats = gl.plot_miami(path1=\"bmi_male_bbj.txt.gz\" ,\n                           path2=\"bmi_female_bbj.txt.gz\",\n                           cols1=[\"CHR\",\"POS\",\"P\"],\n                           cols2=[\"CHR\",\"POS\",\"P\"],\n                           titles=[\"bmi male\",\"bmi female\"],\n                           titles_pad=[0.15,0.0],\n                           anno=\"GENENAME\",\n                           highlight1=[(5,124289158)],\n                           pinpoint2=[(2,653874)]\n                           )\n</code></pre> <p></p>"},{"location":"PerSNPh2/","title":"Per SNP Heritability","text":"<p>GWASLab provides a simple function to calculate the variance explained by each SNP.</p> <p>Available since v3.4.20</p> <pre><code>mysumstats.get_per_snp_r2()\n</code></pre> <p>It needs effect size <code>BETA</code> and effect allele frequency <code>EAF</code> for calculation. If <code>N</code> is available, it will also calculate the F-statistics.</p>"},{"location":"PerSNPh2/#options","title":"Options","text":"<code>.get_per_snp_r2()</code> options DataType Description Default <code>mode</code> <code>q</code> or <code>b</code> <code>q</code>: quantitative trait; <code>b</code>: binary trait <code>q</code> <p>For quantitative traits (<code>mode=\"q\"</code>), GWASLab will use <code>BETA</code>, <code>EAF</code> to calculate <code>SNPR2</code>.</p> <code>.get_per_snp_r2()</code> options DataType Description Default <code>vary</code> <code>float</code> or <code>se</code> Var(Y); if <code>vary=\"se\"</code>,Var(Y) will be estimated using <code>SE</code> 1 <code>k</code> <code>int</code> k for calculating F 1 <p>For SNP <code>i</code></p> <p>When <code>vary=1</code> and k=1:</p> \\[ h^2_{i} = 2 \\times \\beta_i^2 \\times EAF \\times (1 - EAF) \\] \\[ F = h^2_{i} \\times (n -2) / (1 - h^2_{i}) \\] <p>For binary traits  (<code>mode=\"b\"</code>), <code>ncase</code>, <code>ncontrol</code> and <code>prevalence</code> are needed to estimate the variance of liability explained by variants:</p> <code>.get_per_snp_r2()</code> options DataType Description Default <code>ncase</code> <code>int</code> number of cases - <code>ncontrol</code> <code>int</code> number of controls - <code>prevalence</code> <code>float</code> prevalence in general population - <p>Quote</p> <p>Equation 10 in Lee, S. H., Goddard, M. E., Wray, N. R., &amp; Visscher, P. M. (2012). A better coefficient of determination for genetic profile analysis. Genetic epidemiology, 36(3), 214-224.</p> <ul> <li>Implementation adopted from TwoSampleMR https://rdrr.io/github/MRCIEU/TwoSampleMR/src/R/add_rsq.r</li> </ul> <p>Example</p> <pre><code>SNPID   EAF BETA    N   STATUS\n0   1:725932_G_A    0.9960  -0.0737 166718  9999999\n1   1:725933_A_G    0.0040  0.0737  166718  9999999\n2   1:737801_T_C    0.0051  0.0490  166718  9999999\n3   1:749963_T_TAA  0.8374  0.0213  166718  9999999\n4   1:751343_T_A    0.8593  0.0172  166718  9999999\n\nmysumstats.get_per_snp_r2()\n\nMon Jul 17 01:39:02 2023 Start to calculate per-SNP heritability...\nMon Jul 17 01:39:02 2023  -Calculating per-SNP rsq by 2 * (BETA**2) * AF * (1-AF) / Var(y)...\nMon Jul 17 01:39:02 2023  -Var(y) is provided: 1...\nMon Jul 17 01:39:02 2023  -Calculating F-statistic: F = [(N-k-1)/k] * (r2/1-r2)... where k = 1\nMon Jul 17 01:39:02 2023  -For r2, SNPR2 is used.\nMon Jul 17 01:39:02 2023 Finished calculating per-SNP heritibility!\n\nSNPID   EAF BETA    N   STATUS  SNPR2   F\n0   1:725932_G_A    0.9960  -0.0737 166718  9999999 0.000043    7.215732\n1   1:725933_A_G    0.0040  0.0737  166718  9999999 0.000043    7.215732\n2   1:737801_T_C    0.0051  0.0490  166718  9999999 0.000024    4.062184\n3   1:749963_T_TAA  0.8374  0.0213  166718  9999999 0.000124    20.600305\n4   1:751343_T_A    0.8593  0.0172  166718  9999999 0.000072    11.927080\n</code></pre>"},{"location":"Pickle/","title":"Save the Sumstats Object","text":"<p>GWASLab provides functions to save and load unfinished <code>gl.Sumstats</code> Objects.</p>"},{"location":"Pickle/#usage","title":"Usage","text":"<pre><code>gl.dump_pickle(SumstatsObject, path, overwrite=False)\n\ngl.load_pickle(path)\n</code></pre>"},{"location":"Pickle/#options","title":"Options","text":"<ul> <li><code>SumstatsObject</code> : <code>gl.Sumstats()</code>. GWASLab Sumstats Object.</li> <li><code>path</code> : <code>string</code>. dumped pickle file path.</li> <li><code>overwrite</code> : <code>boolean</code>. If <code>True</code>, overwrite the file if it already exists.</li> </ul>"},{"location":"Pickle/#example","title":"Example","text":"<p>Example</p> <pre><code>gl.dump_pickle(mysumstats,\"./first.pickle\",overwrite=True)\nWed Jan 11 23:29:47 2023 Start to dump the Sumstats Object.\nWed Jan 11 23:29:47 2023  -Dump the Sumstats Object to :  ./first.pickle\n\nmy2sumstats = gl.load_pickle(\"./first.pickle\")\nWed Jan 11 23:45:59 2023 Loaded dumped Sumstats object from :  ./first.pickle\n</code></pre>"},{"location":"QC%26Filtering/","title":"QC and filtering","text":"<p>GWASLab provides all-in-one functions and customizable functions for sumstats QC and filtering.</p>"},{"location":"QC%26Filtering/#1-methods-summary","title":"1. Methods Summary","text":"Sumstats Methods Options Description <code>.check_sanity()</code> <code>n</code>.<code>ncase</code>,<code>ncontrol</code>,<code>beta</code>,<code>se</code>,<code>eaf</code> ... sanity check for statistics including BETA, SE, Z, CHISQ, EAF, OR, N... <code>.check_data_consistency()</code> check if <code>BETA/SE-drived P/MLOG10P = original P/MLOG10P</code>, <code>N = N_CASE + N_CONTROL</code>... <code>.remove_dup()</code> <code>mode=\"md\"</code>, <code>keep='first'</code>, <code>keep_col=\"P\"</code>, <code>remove=False</code> remove duplicated, multiallelic or NA variants <code>.filter_value()</code> <code>expr</code> ,  <code>inplace=False</code> filter in variants base on expr <code>.filter_flanking_by_id()</code> <code>snpid</code> ,  <code>inplace=False</code> filter in variants in the specified flacking regions (SNPID/rsID) <code>.filter_flanking_by_chrpos()</code> <code>chrpos</code> ,  <code>inplace=False</code> filter in variants in the specified flacking regions (CHR POS tuples) <code>.filter_region_in()</code> <code>path</code> ,  <code>inplace=False</code> , <code>high_ld=False</code>,  <code>build=\"19\"</code> filter in variants in the specified region define by a bed file <code>.filter_region_out()</code> <code>path</code> ,  <code>inplace=False</code> , <code>high_ld=False</code>,  <code>build=\"19\"</code> filter out variants in the specified region define by a bed file"},{"location":"QC%26Filtering/#2-statistics-sanity-check","title":"2. Statistics Sanity Check","text":"<p>Note: Default parameters have been updated since v3.3.36</p> <p><code>.check_sanity()</code>: Basic sanity check will. be performed on statistics to check if there are any <code>extreme values</code> or <code>values out of expected ranges</code>.</p> <p>Comparison will be performed with <code>float_tolerence = 1e-7</code> for any float type statistics. For example, <code>eaf=(0, 1)</code> will be converted to <code>eaf=(-1e-7, 1 + 1e-7)</code>.</p> Parameters Type Range <code>float_tolerence</code> <code>float</code> tolerence for comparison <code>n=(0,2**31-1))</code> <code>interger</code> 0&lt;N&lt; \\(2^{31}-1\\) <code>ncase=(0,2**31-1)</code> <code>interger</code> 0&lt;N&lt; \\(2^{31}-1\\) <code>ncontrol=(0,2**31-1)</code> <code>interger</code> 0&lt;N&lt; \\(2^{31}-1\\) <code>mac=(0,2**31-1)</code> <code>interger</code> MAC&gt;=0 <code>eaf=(0,1)</code> <code>float</code> 0&lt;EAF&lt;1 <code>chisq=(0,float(\"Inf\"))</code> <code>float</code> CHISQ&gt;0 <code>p=(0,1)</code> <code>float</code> 0&lt;P&lt;1   (Any P=0 will cause a warning) <code>mlog10p=(0,9999)</code> <code>float</code> 0&lt;MLOG10P&lt;9999 <code>beta=(-100,100)</code> <code>float</code> -10&lt;BETA&lt;10 <code>z=(-9999,9999)</code> <code>float</code> -9999&lt;z&lt;9999 <code>se=(0,float(\"Inf\"))</code> <code>float</code> SE&gt;0 <code>OR=(-100,100)</code> <code>float</code> -100&lt;log(OR)&lt;100 <code>OR_95L=(0,float(\"Inf\"))</code> <code>float</code> OR_95L&gt;0 <code>OR_95U=(0,float(\"Inf\"))</code> <code>float</code> OR_95U&gt;0 <code>HR=(-100,100)</code> <code>float</code> -100&lt;log(HR)&lt;100 <code>HR_95L=(0,float(\"Inf\"))</code> <code>float</code> HR_95L&gt;0 <code>HR_95U=(0,float(\"Inf\"))</code> <code>float</code> HR_95U&gt;0 <code>info=(0,1)</code> <code>float</code> 0&lt;INFO&lt;1 <code>direction</code> <code>string</code> only contains <code>\"+\"</code>,<code>\"-\"</code> ,<code>\"0\"</code>or <code>\"?\"</code>"},{"location":"QC%26Filtering/#3-remove-duplicated-or-multiallelic-variants","title":"3. Remove duplicated or multiallelic variants","text":"<p>After standardizing and normalizing the sumstats, you can also remove duplicated or multiallelic variants using</p> <pre><code>.remove_dup(mode=\"md\")\n</code></pre> <ul> <li><code>mode=d</code> , remove duplicate variants.<ul> <li>remove duplicate SNPs based on  1. SNPID, </li> <li>remove duplicate SNPs based on  2. CHR, POS, EA, and NEA</li> <li>remove duplicate SNPs based on  3. rsID</li> </ul> </li> <li><code>mode=s</code> ,remove duplicate variants.<ul> <li>remove duplicate SNPs based on  1. SNPID</li> </ul> </li> <li><code>mode=c</code> ,remove duplicate variants.<ul> <li>remove duplicate SNPs based on  2. CHR, POS, EA, and NEA</li> </ul> </li> <li><code>mode=r</code> ,remove duplicate variants.<ul> <li>remove duplicate SNPs based on  3. rsID</li> </ul> </li> <li><code>mode=m</code>, remove multiallelic variants.<ul> <li>remove multiallelic SNPs based on  4. CHR, POS</li> </ul> </li> <li><code>remove=True</code> : remove NAs </li> <li><code>keep_col</code> : use which column to sort the values (<code>keep_ascend=True</code>: ascending order)</li> <li><code>keep</code>: keep 'first' or 'last'.</li> </ul> <p>Example</p> <pre><code>sumstats.remove_dup(mode=\"md\",keep='first',keep_col=\"P\",remove=False)\n\nFri Jan 13 17:34:38 2023 Start to sort the sumstats using P...\nFri Jan 13 17:34:38 2023 Start to remove duplicated variants based on snpid...\nFri Jan 13 17:34:38 2023  -Current Dataframe shape : 9  x  11\nFri Jan 13 17:34:38 2023  -Which variant to keep:  first\nFri Jan 13 17:34:38 2023  -Removed  1  based on SNPID...\nFri Jan 13 17:34:38 2023 Start to remove duplicated variants based on rsID...\nFri Jan 13 17:34:38 2023  -Removed  1  based on rsID...\nFri Jan 13 17:34:38 2023 Start to remove duplicated variants based on CHR,POS,EA and NEA...\nFri Jan 13 17:34:38 2023  -Current Dataframe shape : 7  x  11\nFri Jan 13 17:34:38 2023  -Which variant to keep:  first\nFri Jan 13 17:34:38 2023  -Removed  1  based on CHR,POS,EA and NEA...\nFri Jan 13 17:34:38 2023 Start to remove multiallelic variants based on chr:pos...\nFri Jan 13 17:34:38 2023  -Which variant to keep:  first\nFri Jan 13 17:34:38 2023  -Removed  0  multiallelic variants...\nFri Jan 13 17:34:38 2023  -Removed  3  variants in total.\nFri Jan 13 17:34:38 2023  -Sort the coordinates...\nFri Jan 13 17:34:38 2023 Finished removing successfully!\n</code></pre> <p>This will remove duplicated and multiallelic variants and keep the one with the lowest P.</p> <p>Before:</p> <p></p> <p>After</p> <p></p>"},{"location":"QC%26Filtering/#4-filtering-by-condition","title":"4. Filtering by condition","text":"<p>Filter the sumstats by <code>expr</code> (a wrapper of <code>pandas.DataFrame.query</code>), and return a new Sumstats Object by default. This allows method chaining. For example, you can filter certain variants first and then create a Mahanttan plot like <code>mysumstats.filter_value('BETA&lt;0 &amp; CHR==1').plot_mqq()</code>.</p> <pre><code>.filter_value(expr,inplace=False)\n</code></pre> Options DataType Description Default <code>expr</code> <code>string</code> the query string used fot filtering. For example: '1&gt;BETA&gt;0 &amp; N&gt;10000' <code>inplace</code> <code>boolean</code> if False, return a new Sumstats object. If true, the current Sumstats object will be filtered in place. <code>False</code> <p>!!! quote pd.DataFrame.query()     Please check https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html</p> <p>Example</p> <p><pre><code>mysumstats.filter_value('BETA&lt;0 &amp; CHR==1').plot_mqq()\nWed Dec  7 01:32:06 2022 Start filtering values by condition: BETA&lt;0 &amp; CHR==1\nWed Dec  7 01:32:06 2022  -Removing 12075769 variants not meeting the conditions: BETA&lt;0 &amp; CHR==1\nWed Dec  7 01:32:06 2022 Finished filtering values.\nWed Dec  7 01:32:06 2022 Start to plot manhattan/qq plot with the following basic settings:\nWed Dec  7 01:32:06 2022  -Genome-wide significance level is set to 5e-08 ...\nWed Dec  7 01:32:06 2022  -Raw input contains 481992 variants...\nWed Dec  7 01:32:06 2022  -Plot layout mode is : mqq\nWed Dec  7 01:32:06 2022 Finished loading specified columns from the sumstats.\nWed Dec  7 01:32:06 2022 Start conversion and sanity check:\nWed Dec  7 01:32:06 2022  -Removed 0 variants with nan in CHR or POS column ...\nWed Dec  7 01:32:06 2022  -Removed 0 variants with nan in P column ...\nWed Dec  7 01:32:06 2022  -P values are being converted to -log10(P)...\nWed Dec  7 01:32:06 2022  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nWed Dec  7 01:32:06 2022  -Sanity check: 0 na/inf/-inf variants will be removed...\nWed Dec  7 01:32:07 2022  -Maximum -log10(P) values is 10.598771832501887 .\nWed Dec  7 01:32:07 2022 Finished data conversion and sanity check.\nWed Dec  7 01:32:07 2022 Start to create manhattan plot with 481992 variants:\nWed Dec  7 01:32:09 2022  -Found 2 significant variants with a sliding window size of 500 kb...\nWed Dec  7 01:32:09 2022 Finished creating Manhattan plot successfully!\nWed Dec  7 01:32:09 2022  -Skip annotating\nWed Dec  7 01:32:09 2022 Start to create QQ plot with 481992 variants:\nWed Dec  7 01:32:09 2022  -Calculating GC using P : 1.2372836632762023\nWed Dec  7 01:32:09 2022 Finished creating QQ plot successfully!\n</code></pre> </p>"},{"location":"QC%26Filtering/#5-flanking-regions","title":"5. Flanking regions","text":"<p>Available since v3.3.37</p> <pre><code>.filter_flanking_by_chrpos(snpid)\n\n.filter_flanking_by_id(chrpos)\n</code></pre> <p>Extract variants in the specified flacking regions.</p> Options DataType Description Default <code>snpid</code> <code>list</code> a list of reference SNPID or rsID. <code>[\"rs123\", \"1:123:A:G\"]</code> <code>snpid</code> <code>list</code> a list of reference CHR, POS tuples <code>[(1, 12345), (2, 67891)]</code> <code>windonsizekb</code> <code>int</code> flanking window size in kb <code>[\"rs123\", \"1:123:A:G\"]</code> <code>500</code> <code>inplace</code> <code>boolean</code> if False, return a new Sumstats object. If true, the current Sumstats object will be filtered in place. <code>False</code>"},{"location":"QC%26Filtering/#6-filtering-regions","title":"6. Filtering regions","text":"<pre><code>.filter_region_in()\n.filter_region_out()\n</code></pre> <p>Filter variants in  predifined regions or regions defined in bed files.</p> Options DataType Description Default <code>path</code> <code>string</code> path to the bed files <code>None</code> <code>high_ld</code> <code>boolean</code> if True, filter high ld regions using built-in data <code>False</code> <code>inplace</code> <code>boolean</code> if False, return a new Sumstats object. If true, the current Sumstats object will be filtered in place. <code>False</code> <p>Example</p> <pre><code>mysumstats.filter_region_in(high_ld=True,inplace=False).data\n\nmysumstats.filter_region_out(high_ld=True,inplace=False).data\n</code></pre>"},{"location":"QC%26Filtering/#7-filter_in-filter_out-deprecated","title":"7. filter_in &amp; filter_out (deprecated)","text":"<p><pre><code>.filter_in(gt={},lt={},eq={},inplace=False)\n\n.filter_out(gt={},lt={},eq={},inplace=False)\n</code></pre> - <code>gt</code>: greater than - <code>lt</code>: less than - <code>eq</code>: equal to - <code>inplace</code>: True or False. If False, return a dataframe. If true, the Sumstats object will be filtered.</p>"},{"location":"Reference/","title":"Reference data for handling Sumstats","text":""},{"location":"Reference/#reference-genome-sequence-for-variant-allele-alignment","title":"Reference genome sequence for variant allele alignment","text":"<ul> <li>GRCh37 / hg19 : ucsc_hg19</li> <li>GRCh38 / hg38 : ucsc_hg38</li> </ul> <p>For details about reference genome, please check https://cloufield.github.io/CTGCatalog/Reference_data_Genome_README/</p>"},{"location":"Reference/#processed-reference-files-for-harmonization","title":"Processed Reference files for harmonization","text":""},{"location":"Reference/#1000-genome-projecthg19","title":"1000 Genome Project(hg19)","text":"<p>Download: Index of /vol1/ftp/release/20130502/</p> <p>Process the 1000 genome vcf file for EAS sample:</p> <ul> <li>Extract EAS sample</li> <li>Split multiallelic variants</li> <li>Normalize variants</li> <li>Rename variants as CHR:POS:REF:ALT</li> <li>Remove duplicated variants</li> <li>Calculate Alternative allele frequency</li> <li>Tabix index</li> </ul>"},{"location":"Reference/#sample-code","title":"Sample code:","text":"<p><pre><code>#!/bin/bash\n# extract EAS sample ID\nawk '$3==\"EAS\"{print $1}' integrated_call_samples_v3.20130502.ALL.panel &gt;EAS.sample\n\n# process\nfor chr in {1..22}\ndo\n    bcftools view -S EAS.sample ALL.chr\"${chr}\".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz | \\\n        bcftools norm -m-any --check-ref w -f human_g1k_v37.fasta | \\\n        bcftools annotate -x ID,INFO -I +'%CHROM:%POS:%REF:%ALT' | \\\n        bcftools norm --rm-dup both | \\\n        bcftools +fill-tags -Oz  -- -t AF  \\\n          &gt; EAS.chr\"${chr}\".split_norm_af.vcf.gz\n\u00a0\u00a0\u00a0\u00a0tabix -p vcf EAS.chr\"${chr}\".split_norm_af.vcf.gz\n    echo \"EAS.chr\"${chr}\".split_norm_af.vcf.gz\" &gt;&gt;concat_list.txt \ndone\n\n# merge\nbcftools concat -a -d both -f concat_list.txt -Ob | bcftools sort -Oz  &gt; EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\ntabix -p vcf EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\n</code></pre> The processed dataset can then be used for:</p> <ul> <li>infer palindromic SNPs / indels</li> <li>check allele frequency difference </li> <li>regional plot</li> </ul>"},{"location":"Reference/#rsid-conversion-table-for-quick-annotation","title":"rsID conversion table for quick annotation","text":"<p>Since GWASLab will check chr:pos and ea/nea to match rsID, it would take a little bit longer if we only use vcf. </p> <p>But we can use a pre-annotated conversion table for common SNPs, and then annotate the rest of SNPs using large VCF file from dbSNP.  <pre><code>for i in range(1,23):\n    sumstats = gl.Sumstats(\"./EAS.chr\"+str(i)+\".split_norm_af.vcf.gz\",snpid=\"ID\",fmt=\"vcf\")\n    sumstats.harmonize( basic_check=True,\n                        ref_seq=\"./reference_genome/hg19/human_g1k_v37_decoy.fasta\",\n                        ref_rsid_vcf=\"./All_20180423.vcf.gz\", \n                        n_cores=4)\n    sumstats.data.loc[:,[\"SNPID\",\"rsID\",\"CHR\",\"POS\",\"NEA\",\"EA\"]].to_csv(\"./1kg_af_dbsnp151.\"+str(i)+\".txt.gz\",\"\\t\",index=None)\n</code></pre></p> <p>In terminal, combine the files: <pre><code># get header\nzcat 1kg_af_dbsnp151.1.txt.gz | head -1 &gt; 1kg_af_dbsnp151_auto.txt\n\nfor i in $(seq 1 22)\ndo\n# get complete SNPID-rsID pairs\nzcat 1kg_af_dbsnp151.${i}.txt.gz | awk -v FS=\"\\t\" -v OFS=\"\\t\" 'NR&gt;1 &amp;&amp; $2!=\"\" {print $0}' &gt;&gt;1kg_af_dbsnp151_auto.txt\ndone\n</code></pre></p>"},{"location":"Reference/#dbsnp-database-for-annotation-of-rsid","title":"dbsnp: database for annotation of rsID","text":"<ul> <li>dbsnp v151 (GRCh37): https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz</li> <li>dbsnp v151 (GRCh37): https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz.tbi</li> <li>dbsnp v151 (GRCh38): https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh38p7/VCF//00-All.vcf.gz</li> <li>dbsnp v151 (GRCh38): https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh38p7/VCF//00-All.vcf.gz.tbi</li> <li>latest release: Index of /snp/latest_release/VCF</li> </ul>"},{"location":"Reference/#gnomad","title":"gnomad","text":"<ul> <li>Allele frequency for major ancestries and rsID</li> <li>gnomAD v2 &amp; gnomAD v2 liftover &amp; gnomAD v3:   gnomAD </li> </ul>"},{"location":"Reference/#reference-library-for-variants-annotation","title":"Reference Library for variants annotation","text":"<p>GWASLab uses:</p> <ul> <li>ensembl release 87 (hg19): https://ftp.ensembl.org/pub/grch37/release-109/gtf/homo_sapiens/</li> <li>ensembl release 109 (hg38):  https://ftp.ensembl.org/pub/release-109/gtf/homo_sapiens/</li> <li>NCBI refseq GRCh37 : https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh37_latest/refseq_identifiers/GRCh37_latest_genomic.gtf.gz</li> <li>NCBI refseq GRCh38 : https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh38_latest/refseq_identifiers/GRCh38_latest_genomic.gtf.gz</li> </ul> <p>Currently, GWASLab could use either ensembl or refseq gtf reference data to annotate lead SNPs with the nearest gene name.</p>"},{"location":"RegionalPlot/","title":"Regional plots","text":"<p>GWASLab provides functions for creating regional plots.</p>"},{"location":"RegionalPlot/#1-usage","title":"1. Usage","text":"<pre><code>.plot_mqq(mode=\"r\",\n          region = None,\n          ...\n          ):\n</code></pre> <p>GWASLab regional plot function is based on plot_mqq(). Most options are largely the same as Manhattan plot.</p> Option DataType Description Default <code>mode</code> <code>r</code> specify regional plot mode - <code>region</code> <code>tuple</code> a three elements tuple (chr, start, end); for example, (7,156538803,157538803) - <code>vcf_path</code> <code>string</code> path to LD reference in VCF format: if None, LD information will not be plotted. <code>None</code> <code>region_ref</code> <code>boolean</code> the SNPID or rsID (if SNPID is not available) for reference variant; if None, lead variants will be selected <code>None</code> <code>region_ref2</code> <code>boolean</code> the SNPID or rsID for the second reference variant <code>None</code> <code>region_grid</code> <code>boolean</code> If True, plot the grid line <code>False</code> <code>region_grid_line</code> <code>dict</code> parameters for the grid line <code>{\"linewidth\": 2,\"linestyle\":\"--\"}</code> <code>region_lead_grid</code> <code>string</code> If True, plot a line to show the reference variants - <code>region_lead_grid_line</code> <code>string</code> parameters for the line to show the reference variants {\"alpha\":0.5,\"linewidth\" : 2,\"linestyle\":\"--\",\"color\":\"#FF0000\"} <code>region_ld_threshold</code> <code>list</code> LD r2 categories <code>[0.2,0.4,0.6,0.8]</code> <code>region_ld_colors</code> <code>list</code> LD r2 categories colors <code>[\"#E4E4E4\",\"#020080\",\"#86CEF9\",\"#24FF02\",\"#FDA400\",\"#FF0000\",\"#FF0000\"]</code> <code>region_ld_colors1</code> <code>list</code> LD r2 categories colors for the first reference varaint (when region_ref2 is specified) <code>[\"#E4E4E4\",\"#F8CFCF\",\"#F5A2A5\",\"#F17474\",\"#EB4445\",\"#E51819\",\"#E51819\"]</code> <code>region_ld_colors2</code> <code>list</code> LD r2 categories colors for the second reference varaint (when region_ref2 is specified) <code>[\"#E4E4E4\",\"#D8E2F2\",\"#AFCBE3\",\"#86B3D4\",\"#5D98C4\",\"#367EB7\",\"#367EB7\"]</code> <code>region_hspace</code> <code>float</code> the space between the scatter plot and the gene track <code>0.02</code> <code>region_step</code> <code>int</code> number of X axis ticks <code>21</code> <code>region_recombination</code> <code>boolean</code> <code>True</code> <code>tabix</code> <code>string</code> path to tabix; if None, GWASLab will search in environmental path; Note: if tabix is available, the speed is much faster!!! <code>None</code> <code>taf</code> <code>list</code> a five-element list; number of gene track lanes, offset for gene track, font_ratio, exon_ratio, text_offset <code>[4,0,0.95,1,1]</code> <code>build</code> <code>19</code> or <code>38</code> reference genome build; <code>99</code> for unknown <code>99</code> <p>Calculation of LD r2</p> <p>The calculation is based on Rogers and Huff r implemented in scikit-alle. Variants in refernece vcf file should be biallelic format. Unphased data is acceptable. AF information is not needed. Variant ID is not required. Missing genotype is allowed.</p>"},{"location":"RegionalPlot/#2-examples","title":"2. Examples","text":""},{"location":"RegionalPlot/#21-regional-mqq-plot","title":"2.1 Regional mqq plot","text":"<pre><code>!wget -O t2d_bbj.txt.gz http://jenger.riken.jp/14/\n</code></pre> <p><pre><code>mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNP\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             neaf=\"Frq\",\n             p=\"P\")\n\nmysumstats.plot_mqq(region=(7,156538803,157538803))\n</code></pre> </p>"},{"location":"RegionalPlot/#22-regional-plot-without-ld","title":"2.2 Regional plot without LD","text":"<p><pre><code>mysumstats.plot_mqq(mode=\"r\", region=(7,156538803,157538803),region_grid=True)\n</code></pre> </p>"},{"location":"RegionalPlot/#23-regional-plot","title":"2.3 Regional plot","text":"<p><pre><code>mysumstats.plot_mqq(mode=\"r\",region=(7,156538803,157538803),region_grid=True,\n                    vcf_path=\"/home/yunye/mydata/d_disk/eas_1kg_af/EAS.chr7.split_norm_af.vcf.gz\")\n</code></pre> </p>"},{"location":"RegionalPlot/#24-two-reference-variant-regional-plot","title":"2.4 Two-reference-variant regional plot","text":"<p><pre><code>mysumstats.plot_mqq(mode=\"r\",region=(7,156538803,157538803),\n                    region_grid=True,\n                    region_ref =\"7:156994964_C_T\",\n                    region_ref2=\"7:156793713_T_C\",\n                    vcf_path=gl.get_path(\"1kg_eas_hg19\"))\n</code></pre> </p>"},{"location":"RegionalPlot/#faq","title":"FAQ","text":"<ol> <li>Why some genes are missing in the gene track?</li> </ol> <p>We only included protein-coding genes in the reference GTF files for plotting the gene track.</p> <ol> <li>Why some exons are missing in the gene track?</li> </ol> <p>Sometimes the exon is too short to reach even 1 pixel in the plot. You can either increase the dpi or reduce the length of the region.</p> <ol> <li>Why an error occurs even if both variants are in the reference VCF?</li> </ol> <p>When the reference variant is mono-allelic in the reference VCF, LD can not be calculated.</p>"},{"location":"Standardization/","title":"Standardization and Normalization","text":"<p>After loading raw sumstats into gwaslab.Sumstats Object, the first thing we probably want to do is to standardize the variant-related notations, normalize the indels and check if there are any unexpected errors in the statistics. When checking is finished, the status code will be automatically changed.</p>"},{"location":"Standardization/#1-methods-summary","title":"1. Methods Summary","text":"Sumstats Methods Options Description <code>.fix_id()</code> <code>fixchrpos=False</code>, <code>fixid=False</code>, <code>fixsep=False</code>,<code>overwrite=False</code>,<code>forcefixid=False</code> check and\u00a0 fix rsID or SNPID(chr:pos:ref:alt), or use snpid to fix CHR and POS <code>.fix_chr()</code> <code>remove=False</code>, <code>x=(\"X\",23)</code>, <code>y=(\"Y\",24)</code>, <code>mt=(\"MT\",25)</code>, <code>chrom_list = gl.get_chr_list()</code> standardize chromsome notation <code>.fix_pos()</code> <code>remove=False</code> , <code>limit=250000000</code> standardize basepair posituion notation and filter out bad values <code>.fix_allele()</code> <code>remove=False</code> standardize base notations to ATCG <code>.normalize_allele()</code> <code>n_cores=1</code> normalize indels (only support ATA:AA -&gt; AT:A but not -:T) <code>.sort_coordinate()</code> sort the variant coordinates <code>.sort_column()</code> <code>order</code> sort the column order to GWASLab default <code>.basic_check()</code> all-in-one function to perform the default pipeline"},{"location":"Standardization/#2-ids-snpid-and-rsid","title":"2. IDs - SNPID and rsID","text":"<p>GWASLab requires at least one ID column for sumstats, either in the form of SNPID or rsID, (or both). GWASLab will automatically check if SNPID is mixed in rsID.</p> <ul> <li><code>SNPID</code> : it could be user-provided IDs, or in <code>CHR:POS:REF:ALT</code> format, delimiters can be <code>\":\"</code>,<code>\"_\"</code> or <code>\"-\"</code>.</li> <li><code>rsID</code>: dbSNP rsIDs</li> </ul> <p>GWASLab will check if the IDs are valid SNPID or rsID.  It can also extract CHR and POS information from the <code>CHR:POS:REF:ALT</code> formatted IDs using <code>.fix_id()</code> method.</p> <p>SNPID will be fixed by <code>CHR:POS:NEA:EA</code>  only when the variants are already aligned with the reference genome. Otherwise, a temporary SNPID in the format of <code>CHR:POS</code> will be assigned.</p> <p><code>.fix_id()</code>: check or fix SNPID and rsID.\u00a0\u00a0\u00a0</p> <code>.fix_id()</code> options Type Description <code>fixchrpos</code> <code>Boolean</code> If True, extract CHR and POS from SNPID (CHR:POS:NEA:EA) to fill CHR and POS columns (default:<code>False</code>) <code>fixid</code> <code>Boolean</code> If True, use CHR/POS/NEA/EA to reconstruct the SNPID. For variant that are not aligned with reference genome. Only CHR/POS will be used. (default:<code>False</code>) <code>forcefixid</code> <code>Boolean</code> If True, use CHR/POS/NEA/EA to reconstruct the SNPID without checking if the variant is aligned. (default:<code>False</code>) <code>fixsep</code> <code>Boolean</code> If True, fix SNPID delimiter (For example: 1:123_A_C to 1:123:A:C) (default:<code>False</code>) <code>overwrite</code> <code>Boolean</code> If True, overwrite existing data. (default:<code>False</code>) <p>Example</p> <pre><code>sumstats.fix_id(fixchrpos=False,\n                fixid=False,\n                fixsep=False,\n                forcefixid=False,\n                overwrite=False)\n</code></pre>"},{"location":"Standardization/#3-chr-chromosomes","title":"3. CHR - Chromosomes","text":"<pre><code>.fix_chr()\n</code></pre> <p>CHR will be standardized. </p> <ul> <li>Prefixes like \"chr\" will be removed.</li> <li>String datatype will be converted to integers.</li> <li>Sex chromosomes will be converted to integers.</li> <li>Variants with unrecognized chromosome notations will be removed. (notations not in <code>chrom_list</code>)</li> <li>Variants with CHR&lt;=0 will be removed. </li> </ul> <p>Options:</p> <code>.fix_chr()</code> options DataType Description Default <code>x</code> <code>tuple</code> how to convert X chromosomes. For examplem <code>x = (\"X\",23)</code> <code>(\"X\",23)</code> <code>y</code> <code>tuple</code> how to convert Y chromosomes. <code>(\"Y\",24)</code> <code>mt</code> <code>tuple</code> how to convert Mitochondrial DNA. <code>(\"MT\",25)</code> <code>chrom_list</code> <code>list</code> vaild chromosome notations for filtering. Datatype should be <code>string</code> <code>gl.get_chr_list()</code> <p>(by default) For human chromosomes, CHR will be converted to integers for autosomes, <code>23</code> for <code>X</code>, <code>24</code> for <code>Y</code>, and <code>25</code> for <code>MT</code>. </p> <p>For other species, you can change it like: - <code>x=(\"X\",26)</code>  - <code>y=(\"Y\",27)</code> - <code>mt=(\"MT\",28)</code> - <code>chrom_list=gl.get_chr_list(n=28)</code></p> <p>Example</p> <pre><code>sumstats.fix_chr()\n</code></pre> <p>!!! tip gl.get_chr_list()     Get a chromosome list for n autosomes plus 'X', 'Y', 'M', 'MT. (`string`` data type)</p> <pre><code>```python\ngl.get_chr_list()\n['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','X','Y','M','MT']\n\ngl.get_chr_list(n=10)\n['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'X', 'Y', 'M', 'MT']\n```\n</code></pre>"},{"location":"Standardization/#4-pos-base-pair-positions","title":"4. POS - Base-pair positions","text":"<pre><code>.fix_pos()\n</code></pre> <p>Check and fix values in POS.</p> <ul> <li>Values in POS must be positive integer numbers. </li> <li>Basepair position will be force converted to integers. </li> <li>Invalid POS values will be converted to NA. </li> <li>POS outliers will be removed.</li> </ul> <code>.fix_pos()</code> options DataType Description Default <code>limit</code> <code>integer</code> After conversion, GWASLab will also perform a sanity check for POS (if is in the range of 1 to 250,000,000). (The longest chromosome for human, namely chromosome 1, is less than 250,000,000bp long) <code>250000000</code> <p>Example</p> <pre><code>sumstats.fix_pos()\n</code></pre>"},{"location":"Standardization/#5-allele","title":"5. Allele","text":""},{"location":"Standardization/#51-allele-notation-standardization","title":"5.1 Allele notation Standardization","text":"<p><code>.fix_allele()</code></p> <ul> <li>Currently, GWASLab only supports processing SNPs and INDELs. </li> <li>All alleles will be checked if containing letters other than <code>A</code>,<code>T</code>,<code>C</code>,<code>G</code>.</li> <li>Copy number variants (CNV) like <code>&lt;CN0&gt;</code> won't be recognized.</li> <li>Lower cases will be converted to UPPERCASES.</li> </ul> <p>Example</p> <pre><code>sumstats.fix_allele()\n</code></pre>"},{"location":"Standardization/#52-variant-normalization","title":"5.2 Variant Normalization","text":"<p><code>.normalize_allele()</code></p> <p>Alleles will be normalized according to the left alignment and parsimony principle. For example, chr1:123456:ATG:AT will be normalized to chr1:123457:TG:T.</p> <code>.normalize_allele()</code> options DataType Description Default <code>n_cores</code> <code>integer</code> threads to use for normalization. <code>1</code> <p>Warning</p> <p>Currently, the normalization is implemented without checking reference, which means it can not normalize variants like chr1:123456:G:- if the missing allele information needs to be obtained from a reference genome.  </p> <p>Variant Normalization</p> <p>For details on variant normalization, please check: https://genome.sph.umich.edu/wiki/Variant_Normalization</p> <p>Example</p> <pre><code>sumstats.normalize_allele(n_cores=1)\n</code></pre> <p>Before:</p> <p></p> <p>After:</p> <p></p>"},{"location":"Standardization/#6-genome-coordinate-sorting","title":"6. Genome coordinate sorting","text":"<p>Sort genomic coordinates. Make sure CHR and POS are fixed beforehand.</p> <p>Example</p> <pre><code>sumstats.sort_coordinate()\n</code></pre>"},{"location":"Standardization/#7-column-sorting","title":"7. Column sorting","text":"<pre><code>.sort_column()\n</code></pre> <code>.sort_column()</code> options DataType Description Default <code>order</code> <code>list</code> sort the columns The default column order is <code>\"SNPID\",\"rsID\", \"CHR\", \"POS\", \"EA\", \"NEA\", \"EAF\", \"MAF\", \"BETA\", \"SE\",\"BETA_95L\",\"BETA_95U\", \"Z\", \"CHISQ\", \"P\", \"MLOG10P\", \"OR\", \"OR_95L\", \"OR_95U\",\"HR\", \"HR_95L\", \"HR_95U\",\"INFO\", \"N\",\"N_CASE\",\"N_CONTROL\",\"DIRECTION\",\"I2\",\"P_HET\",\"DOF\",\"SNPR2\",\"STATUS\"</code> and other additional columns. <p>Example</p> <pre><code>sumstats.sort_column()\n</code></pre>"},{"location":"Standardization/#8-all-in-one-basic_check","title":"8. All-in-one <code>.basic_check()</code>","text":"<p><pre><code>.basic_check()\n</code></pre> Fix data without dropping any variant.</p> <p><code>basic_check()</code> pipeline</p> <ul> <li>fix_id()</li> <li>remove_dup()</li> <li>fix_chr()</li> <li>fix_pos()</li> <li>fix_allele()</li> <li>normalize_allele()</li> <li>check_sanity()  </li> <li>sort_coordinate()</li> <li>sort_column()</li> </ul> <p>For <code>remove_dup()</code> and <code>check_sanity()</code>, please check QC and filtering</p> <code>.basic_check()</code> options DataType Description Default <code>remove</code> <code>boolean</code> if True, remove duplicate and multi-allelic variants <code>False</code> <code>removedup_args</code> <code>dict</code> options for remove_dup() <code>{}</code> <code>fixid_args</code> <code>dict</code> options for <code>.fix_id()</code> <code>{}</code> <code>fixchr_agrs</code> <code>dict</code> options for <code>.fix_chr()</code> <code>{}</code> <code>fixpos_args</code> <code>dict</code> options for <code>.fix_pos()</code> <code>{}</code> <code>fixallele_args</code> <code>dict</code> options for <code>.fix_allele()</code> <code>{}</code> <code>sanitycheckstats_args</code> <code>dict</code> options for <code>.check_sanity()</code> <code>{}</code> <code>normalizeallele_args</code> <code>dict</code> options for <code>.normalize_allele()</code> <code>{}</code> <code>verbose</code> <code>boolean</code> if True, print log <code>True</code>"},{"location":"StatusCode/","title":"Status Code","text":"<ul> <li>A 7-digit code:  showing the status of a variant.</li> <li>Reflecting the reliability of the statistics.</li> <li>Design principals:<ul> <li>Traceable</li> <li>Higher value -&gt; higher uncertainty </li> </ul> </li> </ul> Digit Description 1,2 Genome_build 3 rsID &amp; SNPID 4 CHR, POS 5 EA, NEA 6 REF-NEA Alignment 7 Palindromic SNPs + Indels"},{"location":"StatusCode/#1-summary","title":"1. Summary","text":"<pre><code>mysumstats.summary()\n</code></pre>"},{"location":"StatusCode/#2-look-up-the-status-code","title":"2. Look up the status code","text":"<pre><code>mysumstats.lookup_status()\n</code></pre>"},{"location":"StatusCode/#3-reference-table","title":"3. Reference table","text":""},{"location":"SumstatsObject/","title":"Sumstats Object in GWASLab","text":"<p>In GWASLab, sumstats were stored in a <code>Sumstats Object</code>, which is built on <code>pandas Dataframe</code>. All other functions are designed as methods of this Sumstats Object. </p> <p>To load any sumstats into the object, simply specify the column name and load the raw GWAS summary statistics from a pandas DataFrame or specify a file path. All raw data will be loaded as <code>\"string\"</code> datatype. </p>"},{"location":"SumstatsObject/#1-usage","title":"1. Usage","text":"<pre><code>mysumstats = gl.Sumstats(\n             sumstats,\n             fmt=None,\n             snpid=None,\n             rsid=None,\n             chrom=None,\n             pos=None,\n             ea=None,\n             nea=None,\n             ...\n)\n</code></pre>"},{"location":"SumstatsObject/#2-loading-options","title":"2. Loading options","text":"<p><code>sumstats</code>: either a file path <code>string</code> or a pandas <code>DataFrame</code></p> <p>Currently, GWASLab supports the following columns:</p> Option DataType Description Header in GWASLab <code>snpid</code> <code>string</code> variant ID column name, preferably in chr:pos:ea:nea format. <code>SNPID</code> <code>rsid</code> <code>string</code> dbSNP rsID column name <code>rsID</code> <p>The minimum required columns are just either <code>rsid</code>or <code>snpid</code>.  All other columns and options are optional.</p> Option DataType Description Header in GWASLab <code>fmt</code> <code>string</code> input sumstats format. For formats supported by GWASLab, please check https://github.com/Cloufield/formatbook - <code>chrom</code> <code>string</code> chromosome column name <code>CHR</code> <code>pos</code> <code>string</code> basepair position column name <code>POS</code> <code>ea</code> <code>string</code> effect allele column name; BETA, OR, HR, EAF are in reference to EA... <code>EA</code> <code>nea</code> <code>string</code> non-effect allele column name <code>NEA</code> <code>ref</code> <code>string</code> reference allele column name; the allele on reference genome <code>REF</code> <code>alt</code> <code>string</code> alternative allele column name; the allele that is not on reference genome; when <code>ea</code>,<code>ref</code> and <code>alt</code> are specified, <code>nea</code> will be inferred. <code>ALT</code> <code>eaf</code> <code>string</code> effect allele frequency <code>EAF</code> <code>neaf</code> <code>string</code> non-effect allele frequency. NEAF will be converted to EAF (EAF = 1 - NEAF) while loading. <code>EAF</code> <code>n</code> <code>string</code> or <code>integer</code> sample size column name or just input a single <code>integer</code> as sample size for all variants <code>N</code> <code>beta</code> <code>string</code> effect size beta column name; in reference to EA <code>BETA</code> <code>se</code> <code>string</code> standard error column name <code>SE</code> <code>chisq</code> <code>string</code> chi square column name <code>CHISQ</code> <code>z</code> <code>string</code> z score column name <code>Z</code> <code>p</code> <code>string</code> p value column name <code>P</code> <code>mlog10p</code> <code>string</code> -log10(P) column name <code>MLOG10P</code> <code>info</code> <code>string</code> imputation info or rsq column name <code>INFO</code> <code>OR</code> <code>string</code> odds ratio column name; in reference to EA <code>OR</code> <code>OR_95L</code> <code>string</code> odds ratio lower 95% CI column name <code>OR_95L</code> <code>OR_95U</code> <code>string</code> odds ratio upper 95% CI column name <code>OR_95U</code> <code>direction</code> <code>string</code> direction column name. GWASLab uses METAL format (e.g. <code>++--+?+0</code>) <code>DIRECTION</code> <code>other</code> <code>list</code> a list  of other column names you want to keep with the core columns (probably some annotations). - <code>status</code> <code>string</code> status code column name. GWASLab uses a 7-digit vairant status code. For details, please check status code page. <code>STATUS</code> <code>verbose</code> <code>boolean</code> if True, print log. - <code>build</code> <code>string</code> genome build. <code>19</code> for hg19, <code>38</code> for hg38 and <code>99</code> for unknown. The first two digits of <code>STATUS</code> <code>**arg</code> <code>string</code> additional parameters for pd.read_table() function. Some common options include : <code>sep</code>,<code>nrows</code>, <code>skiprows</code> and <code>na_values</code>. - <p>Other columns GWASLab uses (these will be implemented soon)</p> Option DataType Description Header in GWASLab <code>ncontrol</code> <code>string</code> or <code>integer</code> sample size column name for controls or just input a single <code>integer</code> as sample size for all variants <code>N_CONTROL</code> <code>ncase</code> <code>string</code> or <code>integer</code> sample size column name for cases or just input a single <code>integer</code> as sample size for all variants <code>N_CASE</code> <code>HR</code> <code>string</code> hazrad ratio column name <code>HR</code> <code>HR_95U</code> <code>string</code> hazrad ratio upper 95% CI column name <code>HR_95U</code> <code>HR_95L</code> <code>string</code> hazrad ratio lower 95% CI column name <code>HR_95L</code> <code>beta_95L</code> <code>string</code> beta upper 95% CI column name <code>BETA_95L</code> <code>beta_95U</code> <code>string</code> beta upper 95% CI column name <code>BETA_95U</code> <code>i2</code> <code>string</code> I2 column name <code>I2_HET</code> <code>phet</code> <code>string</code> heterogeneity test P value <code>P_HET</code> <code>dof</code> <code>string</code> or <code>integer</code> degree of freedom <code>DOF</code> <code>snpr2</code> <code>string</code> column name for proportion of phenotypic variance explained by each variant <code>SNPR2</code> <code>maf</code> <code>string</code> minor allele frequency column header <code>MAF</code> <code>f</code> <code>string</code> F statistics column header <code>F</code>"},{"location":"SumstatsObject/#3-loading-sumstats","title":"3 Loading sumstats","text":""},{"location":"SumstatsObject/#31-loading-by-specifying-columns","title":"3.1 Loading by specifying columns","text":"<p>You can load the sumstats by specifying the columns like:</p> <p>Load sumstats by manually specifying columns</p> <pre><code>mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNPID\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             ea=\"Allele2\",\n             nea=\"Allele1\",\n             eaf=\"AF_Allele2\",\n             beta=\"BETA\",\n             se=\"SE\",\n             p=\"p.value\",\n             n=\"N\")\n</code></pre>"},{"location":"SumstatsObject/#32-loading-by-specifying-formats","title":"3.2 Loading by specifying formats","text":"<p>GWASLab supports common sumstats formats and you can load sumstats by specifying <code>fmt</code>.  </p> <p>GWASLab uses a manually curated format conversion dictionary in https://github.com/Cloufield/formatbook. Currently, it supports the following formats:</p> <code>Keyword</code> <code>Description</code> <code>ssf</code> GWAS-SSF <code>gwascatalog</code> GWAS Catalog format <code>pgscatalog</code> PGS Catalog format <code>plink</code> PLINK output format <code>plink2</code> PLINK2 output format <code>saige</code> SAIGE output format <code>regenie</code> output format <code>fastgwa</code> output format <code>metal</code> output format <code>mrmega</code> output format <code>fuma</code> input format <code>ldsc</code> input format <code>locuszoom</code> input format <code>vcf</code> gwas-vcf format <code>bolt_lmm</code> output format <p>Update Formatbook using <code>gl.update_formaybook()</code></p> <pre><code>gl.update_formatbook()\nMon Jul 17 17:38:11 2023 Updating formatbook from: https://raw.github.com/Cloufield/formatbook/main/formatbook.json\nMon Jul 17 17:38:12 2023 Overwrite formatbook to :  /home/yunye/gwaslab/gwaslab/src/gwaslab/data/formatbook.json\nMon Jul 17 17:38:12 2023 Available formats: auto,bolt_lmm,fastgwa,gwascatalog,gwascatalog_hm,gwaslab,ldsc,metal,mrmega,mtag,pgscatalog,pgscatalog_hm,pheweb,plink,plink2,regenie,saige,ssf,template,vcf\nMon Jul 17 17:38:12 2023 Formatbook has been updated!\n</code></pre> <p>Load sumstats by simply specifying the format</p> <pre><code>mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", fmt=\"saige\")\n</code></pre>"},{"location":"SumstatsObject/#33-load-sumstats-with-auto-mode","title":"3.3 Load sumstats with <code>auto</code> mode","text":"<p>GWASLab also provides an auto mode (<code>fmt=\"auto\"</code>; available since v3.4.21) which assumes A1 or alternative allele (ALT) is the effect allele (EA) and Frq refers to the allele frequency of effect allele (EAF). Common headers will be detected. You can find the conversion table here</p> <p>Load sumstats with auto mode</p> <pre><code>mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", fmt=\"auto\")\n</code></pre>"},{"location":"SumstatsObject/#34-loading-sumstats-from-chromosome-separated-files","title":"3.4 Loading sumstats from chromosome-separated files","text":"<p>GWASLab supports loading sumstats from chromosome-separated files (file names need to be in the same pattern.). Just use @ to replace the chromosome numbers. </p> <p>Example</p> <pre><code>mysumstats = gl.Sumstats(\"t2d.chr@.txt.gz\",fmt=\"metal\")\n</code></pre>"},{"location":"SumstatsObject/#4-check-and-save-sumstats","title":"4. Check and save sumstats","text":"<p>After loading, the raw data columns will be renamed to new columns without ambiguity and the dataframe is stored in <code>.data</code> :</p> <p>Example</p> <pre><code>mysumstats.data\n</code></pre> <p>You can simply save the processed data using pandas saving functions, for example:</p> <p>Example</p> <pre><code>mysumstats.data.to_csv(\"./mysumstats.csv\")\n</code></pre> <p>or convert the sumstats to other sumstats using GWASLab <code>to_format()</code> function (recommended):</p> <p>Example</p> <pre><code>mysumstats.to_format(\"./mysumstats\", fmt=\"ldsc\",hapmap3=True, exclude_hla=True, build=\"19\")\n</code></pre> <p>Please check GWASLab - Format for more details.</p>"},{"location":"SumstatsObject/#5-saving-half-finished-sumstats-object","title":"5. Saving half-finished Sumstats Object","text":"<p>If the pipeline is very long, and you need to temporarily save the Sumstats Object, you can use the <code>.dump_pickle()</code> method to temporarily save the Sumstats Object.</p> <p>Please check GWASLab - Pickle for more details.</p>"},{"location":"SumstatsObject/#6-logging","title":"6. Logging","text":"<p>All manipulation conducted to the sumstats will be logged for reproducibility and traceability. </p> <p>The log is stored in a <code>gl.Log()</code> object. You can check it by <code>.log.show()</code>and save it using <code>.log.save()</code></p> <p>Example</p> <pre><code>mysumstats.log.show()\n\nmysumstats.log.save()\n</code></pre>"},{"location":"SumstatsObject/#7-sumstats-summary","title":"7. Sumstats summary","text":"<p>You can check the meta information of sumstats by:</p> <p>Example</p> <pre><code>mysumstats.summary()\n</code></pre>"},{"location":"SumstatsObject/#8-other-functions","title":"8. Other functions","text":"<p>Other functions of GWASLab are implemented as the methods of Sumstats Object.</p> <p>Example</p> <pre><code>mysumstats.basic_check()\n\nmysumstats.plot_mqq()\n\n...\n</code></pre>"},{"location":"TrumpetPlot/","title":"Trumpet plot","text":"<p>Under testing. Will be available since v3.4.20</p>"},{"location":"TrumpetPlot/#description","title":"Description","text":"<p>Scatter plot for visualization of the relationship between Minor Allele Frequency (MAF) and Effect size (BETA/ log(OR))</p> <ul> <li>X axis: MAF</li> <li>Y axis: Effect size</li> <li>additional curves : power</li> </ul>"},{"location":"TrumpetPlot/#usage","title":"Usage","text":""},{"location":"TrumpetPlot/#q-mode-for-quantitative-traits","title":"\"q\" mode for quantitative traits","text":"Option Type Description Default <code>sig_level</code> <code>float</code> signiifcance level for power calculation <code>5e-8</code> <code>n</code> <code>string</code> or <code>int</code> column name for sample size or an integer for sample size required <code>ts</code> <code>list</code> a list of power curve to draw <code>[0.2,0.4,0.6,0.8]</code>"},{"location":"TrumpetPlot/#b-mode-for-binary-traits","title":"\"b\" mode for binary traits","text":"Option Type Description Default <code>sig_level</code> <code>float</code> signiifcance level for power calculation <code>5e-8</code> <code>ncase</code> <code>int</code> number of cases required <code>ncontrol</code> <code>int</code> number of controls required <code>prevalence</code> <code>float</code> disease prevalence in general population required <code>or_to_rr</code> <code>boolean</code> if estimate RR using OR/beta and prevalence; for prevalence &lt;10%, RR is similar to OR \"False\" <code>ts</code> <code>list</code> a list of power curve to draw <code>[0.2,0.4,0.6,0.8]</code>"},{"location":"TrumpetPlot/#other-option","title":"other option","text":"Option Type Description Default <code>build</code> <code>string</code> <code>19</code> or <code>38</code>, which build to use for annotation \"99\" <code>p_level</code> <code>float</code> upper limit of p values; variants with p values higher than this will be excluded from plotting <code>5e-8</code> <code>anno</code> <code>string</code> which column in sumstats to use to annotate the variants None <code>anno_style</code> <code>string</code> <code>expand</code>, <code>tight</code> or <code>right</code> <code>expand</code> <code>anno_args</code> <code>dict</code> augurments for annotation <code>{\"fontsize\":12,\"fontstyle\":\"italic\"}</code> <code>anno_x</code> <code>float</code> upper bound of abs(y) for annotation <code>0.05</code> <code>anno_y</code> <code>float</code> lower bound of abs(y) for annotation <code>1</code> <code>repel_force</code> <code>float</code> determine the interval between each annotation <code>0.05</code> <code>sort</code> <code>string</code> <code>beta</code> or <code>eaf</code>, which to use to determine the order for annotation <code>beta</code> <code>ylim</code> <code>tuple</code> ylim auto <code>cmap</code> <code>string</code> matplotlib color map for power line \"cool\" <code>xscale</code> <code>string</code> <code>log</code> or <code>nonlog</code> <code>log</code> <code>yscale_factor</code> <code>float</code> effect size will be multiplied by a factor 1 <code>n_matrix</code> <code>int</code> The higher the value is, the smoother the power line will be 1000 <code>markercolor</code> <code>string</code> color \"#597FBD\" <code>ylabel</code> <code>string</code> Y axis label <code>Effect size</code> <code>xlabel</code> <code>string</code> X axis label <code>Minor allele frequency</code> <code>xticks</code> <code>list</code> X axis ticks <code>Effect size</code> <code>xticklabels</code> <code>list</code> X axis tick labels <code>Minor allele frequency</code> <p>|<code>save</code>|<code>string</code> or <code>True</code>|if True, the figure will be saved in the current directory with a default name. If <code>string</code> is provided, it will be used as the path for the figure |<code>False</code>| |<code>save_args</code>|<code>dict</code>|augurments for matplotlib savefig|None|</p>"},{"location":"TrumpetPlot/#example","title":"example","text":"<p>Trumpet plot for quantitative traits</p> <p><pre><code>mysumstats.plot_trumpet(mode=\"q\",\n                            ts=[0.2,0.4,0.6,0.8] ,\n                            anno=\"Gene\",\n                            anno_style=\"expand\",\n                            cmap=\"cool\",\n                            sig_level=5e-8,\n                            build=\"19\",\n                            anno_x=0.01,\n                            anno_y=1,\n                            p_level=5e-8,\n                            n_matrix=2000,\n                            fontsize=12,\n                            xscale=\"log\",\n                            repel_force=0.15,\n                            yscale_factor=5.63,\n                            sort=\"eaf\",\n                            ylim=(-5,4),\n                            save=True)\n</code></pre> </p> <p>Trumpet plot for binary traits</p> <p><pre><code>mysumstats.get_lead(sig_level=5e-6,gls=True).plot_trumpet(mode=\"b\",\n                            ncase=36614,\n                            ncontrol=155150,\n                            sig_level=5e-6,\n                            p_level=5e-6,\n                            ts=[0.2,0.4,0.6,0.8] ,\n                            anno=\"GENENAME\",\n                            anno_style=\"right\",\n                            cmap=\"cool\",\n                            or_to_rr=True,\n                            build=\"19\",\n                            anno_x=0.01,\n                            anno_y=0,\n                            n_matrix=2000,\n                            fontsize=12,\n                            xscale=\"log\",\n                            repel_force=0.15,\n                            sort=\"eaf\",\n                            ylim=(-5,4),\n                            save=True)\n</code></pre> </p>"},{"location":"TrumpetPlot/#citation","title":"Citation","text":"<p>Quote</p> <p>This function was adapted from Corte, L., Liou, L., O'Reilly, P. F., &amp; Garc\u00eda-Gonz\u00e1lez, J. (2023). Trumpet plots: Visualizing The Relationship Between Allele Frequency And Effect Size In Genetic Association Studies. medRxiv, 2023-04.  R Shiny app : https://juditgg.shinyapps.io/shinytrumpets/</p> <p>Power</p> <p>For power calculation: </p> <ul> <li>Sham, P. C., &amp; Purcell, S. M. (2014). Statistical power and significance testing in large-scale genetic studies. Nature Reviews Genetics, 15(5), 335-346.</li> <li>Skol, A. D., Scott, L. J., Abecasis, G. R., &amp; Boehnke, M. (2006). Joint analysis is more efficient than replication-based analysis for two-stage genome-wide association studies. Nature genetics, 38(2), 209-213.</li> </ul>"},{"location":"UpdateLogs/","title":"Update Logs","text":""},{"location":"UpdateLogs/#3438","title":"3.4.38","text":"<ul> <li>fixed seaborn version</li> <li>replaced array_split</li> <li>fixed warnings due to pandas upgrade </li> <li>renamed get_flanking to filter_flanking</li> <li>fixed error in cbar for regional plot</li> <li>restructured log system</li> <li>restructured sanity checking</li> <li>restructured stats flipping</li> </ul>"},{"location":"UpdateLogs/#3437-20240129","title":"3.4.37 20240129","text":"<ul> <li>added data consistency check</li> <li>added \"s\",\"r\",\"n\" mode for remove_dup()</li> <li>updated fix_id</li> <li>added sample data</li> <li>added datatype check for rsID and SNPID</li> <li>added memory usage check </li> <li>added extreme P value check</li> </ul>"},{"location":"UpdateLogs/#3436-20240126","title":"3.4.36 20240126","text":"<ul> <li>removed statsmodels</li> <li>updated functions in basic_check()</li> <li>added a test example for basic_check()</li> <li>fixed fontsize and font_family errors in plot_mqq() for ax4</li> <li>added new options for plot_mqq(mode=\"r\"); cbar_fontsize, cbar_font_family, cbar_title</li> <li>added new options for plot_mqq(mode=\"r\"); track_n, track_n_offset, track_fontsize_ratio, track_exon_ratio, track_text_offset, track_font_family </li> </ul>"},{"location":"UpdateLogs/#3435-20240123","title":"3.4.35 20240123","text":"<ul> <li>fixed version number</li> </ul>"},{"location":"UpdateLogs/#3434-20240123","title":"3.4.34 20240123","text":"<ul> <li>get_lead will use MLOG10P first instead of P (<code>scaled</code> is deprecated in <code>get_lead</code>)</li> <li>added datatype check for fill_data</li> <li>added datatype verification</li> <li>updated sanity check default values (BETA, OR, HR)</li> </ul>"},{"location":"UpdateLogs/#3433-20240122","title":"3.4.33 20240122","text":"<ul> <li>fix_allele() now prints out allele information </li> <li>updated sanity check default values (added tolerance for floats)</li> <li>fixed error in loading pickle created by older versions</li> <li>fixed bug in flipping OR and HR</li> <li>added version information to the start line of each checking function</li> <li>updated reference VCF</li> <li>updated clump() / to_finemapping() / run_susie_rss() (beta)</li> <li>updated Manhattan-like plotting system </li> <li>updated datatype for certain statistics</li> <li>updated file naming system (beta)</li> <li>added stacked mqq plot (beta)</li> <li>plot_miami2() can iteratively call plot_mqq to create miami plot, which supports more functions (beta)</li> </ul>"},{"location":"UpdateLogs/#3432-20231118","title":"3.4.32 20231118","text":"<ul> <li>fixed bug in sanity_check : N = N_CASE + N_CONTROL</li> <li>fixed the logic chain for normalization</li> <li>added extra log in compare_effect</li> <li>fixed a few typos (credit to @gmauro Mr. Gianmauro Cuccuru)</li> <li>added clump() for beta testing</li> <li>added to_finemapping() for beta testing</li> <li>added run_susie_rss() for beta testing</li> </ul>"},{"location":"UpdateLogs/#3431-20231115","title":"3.4.31 20231115","text":"<ul> <li>updated version requirements</li> </ul>"},{"location":"UpdateLogs/#3430-20231103","title":"3.4.30 20231103","text":"<ul> <li>updated random seed range (0,2^32-1).</li> <li>fixed error for suggestive_sig_line in miami plot.</li> <li>loosened version requirements for python, pandas and matplotlib.  </li> </ul>"},{"location":"UpdateLogs/#3429-20231003","title":"3.4.29 20231003","text":"<ul> <li>set <code>scatter_kwargs={\"rasterized\":True}</code> as default for miami plot</li> </ul>"},{"location":"UpdateLogs/#3428-20231003","title":"3.4.28 20231003","text":"<ul> <li>fixed a bug in <code>compare_effect</code></li> </ul>"},{"location":"UpdateLogs/#3427-20231002","title":"3.4.27 20231002","text":"<ul> <li>update reference book</li> <li>added extra parameters for tabix_index()</li> <li>update random variants</li> </ul>"},{"location":"UpdateLogs/#3426-20230911","title":"3.4.26 20230911","text":"<ul> <li>added <code>infer_af()</code></li> <li>updated reference datasets</li> </ul>"},{"location":"UpdateLogs/#3424-20230821","title":"3.4.24 20230821","text":"<ul> <li>supported <code>highlight</code> and <code>pinpoint</code> for multiple sets of loci and variants in <code>.plot_mqq()</code></li> <li>added <code>overwrite</code> option for <code>gl.download_ref()</code></li> </ul>"},{"location":"UpdateLogs/#3424-20230821_1","title":"3.4.24 20230821","text":"<ul> <li>update references</li> </ul>"},{"location":"UpdateLogs/#3423-20230817","title":"3.4.23 20230817","text":"<ul> <li>fixed bug in <code>get_lead()</code>. In some rare cases, it was not counted when the last variant is a new lead variant.</li> </ul>"},{"location":"UpdateLogs/#3422-20230803","title":"3.4.22 20230803","text":"<ul> <li>added plot_power() and plot_power_x()</li> <li>added support for multiple EFO IDs</li> <li>updated built-in formatbook</li> <li>fixed regex error in read_ldsc for numbers in the format of 1e-01</li> <li>fixed typos</li> </ul>"},{"location":"UpdateLogs/#3421-20230718","title":"3.4.21 2023/07/18","text":"<ul> <li>fix error in gc calculation for mqq plot when <code>expected_min_mlog10p</code> is not 0 and <code>stratified=True</code>.</li> </ul>"},{"location":"UpdateLogs/#3420-20230715","title":"3.4.20 2023/07/15","text":"<ul> <li>reimplement and unified the module for saving figures</li> <li>added trumpet plot document page   </li> <li>added CHR range check in <code>.fix_chr()</code> and <code>.plot_mqq()</code> (remove variants with CHR&lt;=0) (#42)</li> <li>fixed error in column headers for plot_mqq \"b\" mode (#40)</li> <li>fixed many typos.. (#41)</li> <li>fixed error in plot_mqq logging (warning for genome build) </li> <li>fixed error in annotation for miami plot </li> </ul>"},{"location":"UpdateLogs/#3419-20230629","title":"3.4.19 2023/06/29","text":"<ul> <li>added annotation using custom column for miami plot</li> <li>updated alogorithm for extracting lead variants (using scaled P)</li> </ul>"},{"location":"UpdateLogs/#3418-20230628","title":"3.4.18 2023/06/28","text":"<ul> <li>fixed bugs for miami plot</li> </ul>"},{"location":"UpdateLogs/#3417-20230627","title":"3.4.17 2023/06/27","text":"<ul> <li>added <code>expected_min_mlog10p</code> for qq mode in <code>plot_mqq()</code></li> <li>added trumpet plot</li> <li>added support for gwaslab Sumstats object for gl.compare_effect()</li> <li>added saving options for gl.compare_effect()</li> <li>fixed bug for <code>is_q=False</code> in gl.compare_effect().</li> </ul>"},{"location":"UpdateLogs/#3416-20230622","title":"3.4.16 2023/06/22","text":"<ul> <li>fixed bug for qq mode in <code>plot_mqq()</code></li> </ul>"},{"location":"UpdateLogs/#3415-20230620","title":"3.4.15 2023/06/20","text":"<ul> <li>LDSC-rg genetic correlation heatmap</li> <li>Allele frequency correlation plot</li> <li>Miami plot using gl.Sumstats Object pickle files</li> <li>Auto-check for VCF chromosome prefix (chr1 or 1)</li> <li>fill_data() is now implemented iteratively</li> <li>Downloaded files auto detection.</li> </ul>"},{"location":"UpdateLogs/#3414-20230609","title":"3.4.14 2023/06/09","text":"<ul> <li>fixed bug</li> </ul>"},{"location":"UpdateLogs/#3413-20230609","title":"3.4.13 2023/06/09","text":"<ul> <li>added two-reference-variant mode for regional plot</li> <li>auto-check for genome build version</li> <li>added <code>additional_line</code> and <code>additional_line_color</code> for plot_mqq</li> <li>fixed bugs for sig_level_lead</li> </ul>"},{"location":"UpdateLogs/#3412-20230530","title":"3.4.12 2023/05/30","text":"<ul> <li>added highlight_anno_args in plot_mqq()</li> <li>added GWAS-SSF style metadata yaml output support</li> <li>added region_ref for regional plots</li> <li>updated default formatbook</li> </ul>"},{"location":"UpdateLogs/#3411-20230428","title":"3.4.11 - 2023/04/28","text":"<ul> <li>fixed anno=None in miami plot</li> </ul>"},{"location":"UpdateLogs/#3410-20230427","title":"3.4.10 - 2023/04/27","text":"<ul> <li>fixed variant_id sep for ssf</li> <li>update tutorials</li> </ul>"},{"location":"UpdateLogs/#349-20230425","title":"3.4.9 - 2023/04/25","text":"<ul> <li>update variant matching criteria for regional plot</li> <li>fixed default values for mqqplot</li> <li>added qq_scatter_args</li> <li>added connection timeout, status code check and md5sum verification for download_ref</li> </ul>"},{"location":"UpdateLogs/#348-20230421","title":"3.4.8 - 2023/04/21","text":"<ul> <li>fixed regional plot lead variant line error</li> <li>added tutorial for v3.4</li> <li>fixed anno_alias priority</li> </ul>"},{"location":"UpdateLogs/#347-20230420","title":"3.4.7 - 2023/04/20","text":"<ul> <li>fixed font_family for annotation</li> <li>get_lead can now use mlo10p to extract lead variants </li> <li>added sig_level_lead in plot_mqq</li> </ul>"},{"location":"UpdateLogs/#346-20230418","title":"3.4.6 - 2023/04/18","text":"<ul> <li>updated yticklabel fontsize</li> <li>updated drop_chr_start</li> </ul>"},{"location":"UpdateLogs/#345-20230406","title":"3.4.5 - 2023/04/06","text":"<ul> <li>added rr_lim : input a tuple like (0,100) or \"max\"</li> </ul>"},{"location":"UpdateLogs/#344-20230404","title":"3.4.4 - 2023/04/04","text":"<ul> <li>fixed error in mqqplot (chr &gt; 26)</li> </ul>"},{"location":"UpdateLogs/#343-20230329","title":"3.4.3 - 2023/03/29","text":"<ul> <li>added jagged y-axis</li> <li>added cut_log</li> </ul>"},{"location":"UpdateLogs/#342-20230328","title":"3.4.2 - 2023/03/28","text":"<ul> <li>fixed y tick labels</li> <li>added font_family</li> <li>added ylabels</li> </ul>"},{"location":"UpdateLogs/#341-20230328","title":"3.4.1 - 2023/03/28","text":"<ul> <li>added sc_linewidth</li> <li>fixed use_rank</li> <li>fixed ystep</li> </ul>"},{"location":"UpdateLogs/#340","title":"3.4.0","text":"<ul> <li>restructured plot functions</li> <li>added dtype conversion for input pd.DataFrame</li> <li>reimplemented gtfparse and revised requirements</li> <li>update reference datasets</li> <li>fixed bugs when no variants were selected for mqqplot</li> <li>fixed bugs in <code>gl.check_downloaded_ref()</code></li> <li>added suggestive significance line</li> </ul>"},{"location":"UpdateLogs/#3324-20230201","title":"3.3.24 - 2023/02/01","text":"<ul> <li>update bugs in init.py</li> </ul>"},{"location":"UpdateLogs/#3323-20230131","title":"3.3.23 - 2023/01/31","text":"<ul> <li>update annotation arrow style <code>anno_style</code> for <code>.plot_mqq</code></li> <li>fixed effect size comparison bugs (added sorting)</li> <li>added allele check for effect size comparison</li> <li>update large number selection algorithm</li> <li>fixed dtype errors in <code>fix_chr</code> and <code>fix_pos</code></li> <li>added perSNPh2 <code>.get_per_snp_r2()</code> and F statistics</li> <li>implemented save in Miami plots</li> <li>fixed annotation error in Miami plots</li> </ul>"},{"location":"UpdateLogs/#3322-20230127","title":"3.3.22 - 2023/01/27","text":"<ul> <li>added checks for duplicates and NAs in compare_effect()</li> </ul>"},{"location":"UpdateLogs/#3321-20230127","title":"3.3.21 - 2023/01/27","text":"<ul> <li>implement package info gl.show_version()</li> <li>fixed rsid_to_chrpos()</li> </ul>"},{"location":"UpdateLogs/#3320","title":"3.3.20","text":"<ul> <li>updated get_density() to calculate the signal density for sumstats</li> <li>implemented winner's curse correction for effect size comparison</li> </ul>"},{"location":"UpdateLogs/#3319","title":"3.3.19","text":"<ul> <li>updated fontsize options for plot_mqq(). Added anno_fontsize, title_fontsize.</li> <li>updated default values and optimized methods for remove_dup(), fix_chr(), basic_check(),check_sanity().</li> <li>added dump_pickle() load_pickle() to save half-finished sumstats object.</li> </ul>"},{"location":"UpdateLogs/#3318","title":"3.3.18","text":"<ul> <li>updated config and downloading system</li> </ul>"},{"location":"UpdateLogs/#3317","title":"3.3.17","text":"<ul> <li>added xtcik_chr_dict</li> <li>fixed bugs in miami plot</li> </ul>"},{"location":"UpdateLogs/#3316","title":"3.3.16","text":"<ul> <li>added hg38 recombination rate file</li> <li>fixed bugs in get_novel</li> </ul>"},{"location":"UpdateLogs/#3315","title":"3.3.15","text":"<ul> <li>fixed bugs for reading gtf files</li> </ul>"},{"location":"UpdateLogs/#3314","title":"3.3.14","text":"<ul> <li>updated requirements for dependencies <ul> <li>pandas&gt;=1.3,&lt;1.5</li> <li>pyensembl==2.2.3</li> </ul> </li> <li>support customized gtf/vcf/recombination_rate files</li> <li>fixed bugs for regional plot</li> <li>calculate_gc()</li> <li>fill MAF : <code>.fill_data(to_fill=[\"MAF\"])</code></li> </ul>"},{"location":"UpdateLogs/#3313","title":"3.3.13","text":"<ul> <li>specified python engine for query </li> </ul>"},{"location":"UpdateLogs/#3312","title":"3.3.12","text":"<ul> <li>fixed bugs for matplotlib v3.6.x</li> <li>added method chain for filter_xxx functions</li> <li>updated requirements for dependencies <ul> <li>pySAM&gt;=0.18.1,&lt;0.20</li> <li>matplotlib&gt;=3.5</li> <li>pyensembl&gt;=2.2.3</li> </ul> </li> </ul>"},{"location":"UpdateLogs/#3311","title":"3.3.11","text":"<ul> <li>updated requirements for dependencies</li> </ul>"},{"location":"UpdateLogs/#3310","title":"3.3.10","text":"<ul> <li>updated bugs for mqqplot</li> </ul>"},{"location":"UpdateLogs/#v339","title":"v3.3.9","text":"<ul> <li>updated download system</li> </ul>"},{"location":"UpdateLogs/#v338","title":"v3.3.8","text":"<ul> <li>included recombination data</li> </ul>"},{"location":"UpdateLogs/#v337","title":"v3.3.7","text":"<ul> <li>updated packaging methods. Now when installing gwaslab, pip will install all dependencies as well.</li> </ul>"},{"location":"UpdateLogs/#v336-20221105","title":"v3.3.6 - 2022/11/05","text":"<ul> <li>added download function: <ul> <li>now you can download reference files from predefined list via gwaslab</li> <li><code>gl.check_available_ref()</code> : list available reference files</li> <li><code>gl.check_downloaded_ref()</code> : list downloaded reference files</li> <li><code>gl.download_ref(name)</code> : download reference files</li> <li><code>gl.remove_file(name)</code> : remove the local reference files</li> <li><code>gl.get_path(name)</code> : get the local path for the reference data name</li> </ul> </li> <li>implemented parsing gwas-vcf (<code>fmt=\"vcf\"</code>)</li> <li>implemented <code>Sumstats.filter_value(expr)</code></li> <li>fixed bugs for check_allele</li> <li>optimized functions for sorting columns</li> <li>removed outdated codes in Sumstats</li> </ul>"},{"location":"UpdateLogs/#v335-20221102","title":"v3.3.5 - 2022/11/02","text":"<ul> <li>added <code>filter_value</code></li> <li>integrate <code>gwascatalog</code> to <code>get_novel</code></li> <li>optimized <code>remove_dup</code></li> <li>fixed bugs</li> </ul>"},{"location":"UpdateLogs/#v334-20221031","title":"v3.3.4 - 2022/10/31","text":"<ul> <li>added gwascatalog_trait()</li> <li>optimized check_sanity()</li> <li>optimized the logic for removing duplicated and multiallelic variants </li> <li>added update_formatbook()</li> <li>added functions to read vcf.gz <code>gl.Sumstats(\"myvcf.vcf.gz\",fmt=\"vcf\")</code></li> <li>gwaslab is now able to read chromosome-separated files</li> <li>fixed bugs</li> </ul>"},{"location":"UpdateLogs/#v333","title":"v3.3.3","text":"<ul> <li>added Miami plot</li> <li>added Brisbane plot</li> <li>updated tutorials </li> <li>mqq plot annotation: new customization options</li> </ul>"},{"location":"UpdateLogs/#v332-20221021","title":"v3.3.2 - 2022/10/21","text":"<ul> <li>added forcefixid for fix_id()</li> <li>fixed bugs for plotting gene tracks</li> </ul>"},{"location":"UpdateLogs/#v331","title":"v3.3.1","text":"<ul> <li>extract novel loci given a list of known lead variants</li> <li>fixed bugs in fill_data()</li> <li>fixed path for hapmap3 snps for infer_build()</li> </ul>"},{"location":"UpdateLogs/#v330-20221018","title":"v3.3.0 - 2022/10/18","text":"<ul> <li>added forest plot</li> <li>fixed options for mqqplot</li> <li>supported vcf</li> </ul>"},{"location":"UpdateLogs/#v320","title":"v3.2.0","text":"<ul> <li>incorporated pyensembl and scikit-allel.</li> <li>get_lead() : support automatic gene name annotation (using pyensembl)</li> <li>to_format():<ul> <li>support common sumstats formats </li> <li>support 1-based bed-like formats for VEP</li> <li>support 0-based bed-like formats</li> </ul> </li> <li>manhattan plot:<ul> <li>optimized plotting logic</li> <li>annotate gene names</li> <li>added regional plot feature using a user-provided reference panel</li> </ul> </li> <li>comparison effect plot: <ul> <li>fix using OR</li> </ul> </li> </ul>"},{"location":"UpdateLogs/#v310","title":"v3.1.0","text":"<ul> <li>implemented formatbook: easily import sumstats and output sumstats in certain formats (support for commonly used formats including ldsc, plink, plink2, gwas-ssf, saige, regenie, fastgwa, metal, mrmega, pgscatalog, pgscatalog_hm, gwascatalog, gwascatalog_hm and gwaslab)</li> <li>added <code>.filter_region_in/out</code> using bed files (or in-built regions like high-ld or hla)</li> <li>implemented <code>.summay()</code> methods.</li> <li>optimized rsID annotation pipeline. Support annotation using curated chr:pos:ref:alt - rsID tsv for quick annotation.</li> <li>changed some datatypes and optimized memory usage.</li> <li>replaced pyVCF with pySAM</li> </ul>"},{"location":"Upload_checklist/","title":"Checklist for uploading to PyPI","text":"<ul> <li>update package info</li> <li>update the badge and install command in index.md</li> <li>update Update log</li> <li>update toml</li> <li>build package</li> <li>upload to PyPI</li> </ul>"},{"location":"Visualization/","title":"Manhattan plot and QQ plot : plot_mqq()","text":"<p>GWASLab provides a customizable plotting function for Manhattan and Q-Q plots.</p> <pre><code>.plot_mqq()\n</code></pre>"},{"location":"Visualization/#1-a-simple-example","title":"1. A simple example","text":"<p>Quick Manhattan and Q-Q plot without any options</p> <pre><code>mysumstats.plot_mqq()\n</code></pre> <p></p>"},{"location":"Visualization/#2-options","title":"2. Options","text":"<ul> <li>Using P or MLOG10P</li> <li>Adjusting x axis</li> <li>Adjusting y axis</li> <li>Changing layout</li> <li>Annotation</li> <li>Adding lines</li> <li>Highlight loci and Pinpoint variants </li> <li>Colors and fonts</li> <li>MAF-stratified QQ plot.</li> <li>Changing titles</li> <li>Saving figures</li> </ul> <p>By setting the options, you can create highly customized Manhattan plots and Q-Q plots.</p> <p>A customized Manhattan and QQ plot</p> <pre><code>mysumstats.plot_mqq(\n                  mode=\"qqm\",\n                  cut=14,\n                  skip=3, \n                  anno_set=[\"rs12509595\",\"rs7989823\"] ,\n                  pinpoint=[\"rs7989823\"], \n                  highlight=[\"rs12509595\",\"19:15040733:T:C\"],\n                  highlight_windowkb =1000,\n                  stratified=True,\n                  marker_size=(5,10),\n                  figargs={\"figsize\":(15,5),\"dpi\":300})\n</code></pre> <p></p>"},{"location":"Visualization/#21-manhattan-and-qq-plot-layout","title":"2.1 Manhattan and QQ plot layout","text":"Option DataType Description Default <code>mode</code> <code>mqq</code>,<code>qqm</code>,<code>qq</code>,<code>m</code> Determine the layout of manhattan plot and qq plot.  <code>mqq</code>: left manhatan, right QQ plot <code>qqm</code>: left QQ plot, right Manhattan plot <code>m</code>: only Manhattan plot <code>\"qq\"</code>: only qq plot <code>mqq</code> <code>mqqratio</code> <code>float</code> width ratio of Manhattan plot and QQ plot <code>3</code> <p>Layout</p> <p></p>"},{"location":"Visualization/#22-use-mlog10p-for-extreme-p-values","title":"2.2 Use MLOG10P for extreme P values","text":"Option DataType Description Default <code>scaled</code> <code>boolean</code> By default, GWASLab uses P values for mqq plot. But you can set <code>scaled=Ture</code> to use MLOG10P to plot. <code>False</code> <p>Variant with extreme P values</p> <p>To plot the variant with extreme P values (P &lt; 1e-300), you can use <code>scaled=False</code> to create the plot with MLOG10P instead of raw P values. To calculate MLOG10P for extreme P values from BETA/SE or Z scores, you can use <code>mysumstats.fill_data(to_fill=[\"MLOG10P\"], extreme=True)</code>. For details, please refer to the \"Extreme P values\" section in https://cloufield.github.io/gwaslab/Conversion/.</p>"},{"location":"Visualization/#23-x-axis-physical-position-or-rank","title":"2.3 X axis: Physical position or rank","text":"Option DataType Description Default <code>use_rank</code> <code>boolean</code> If True, GWASLab will use position rank instead of the physical base-pair positions for x aixs. <code>False</code> <p>Note</p> <p>If using rank, there will be no gap in the plot. If using base-pair positions, certain regions of the chromosome might be reflected in the plot like the heterochromatin.</p>"},{"location":"Visualization/#24-y-axis-skip-low-and-shrink-high","title":"2.4 Y axis: Skip \"low\" and shrink \"high\"","text":"Option DataType Description Default <code>skip</code> <code>float</code> Sometimes it is not necessary to plot all variants, we can skip the variants with low -log10(P) values for plotting. For example, we can omit varints with -log10(P) lower than 3 from the plot by specifying <code>skip=3</code>. Calculation of lambda GC won't be affected by this <code>None</code> <code>cut</code> <code>float</code> loci with extremly large -log10(P) value are very likely to dwarf other significant loci, so we want to scale down the -log10(P) for variants above a certain threshold. <code>None</code> <code>cutfactor</code> <code>float</code> shrinkage factor <code>10</code> <code>cut_line_color</code> <code>float</code> the color of the line above which y axis is rescaled. <code>500</code> <code>sig_level</code> <code>float</code> genome-wide significance threshold <code>5e-8</code> <p>Auxiliary lines</p> <p></p> <p>Note</p> <p>lambda GC calculation for QQ plot will not be affected by skip and cut. The calculation is conducted using all variants in the original dataset.</p>"},{"location":"Visualization/#25-annotation","title":"2.5 Annotation","text":"Option DataType Description Default <code>anno</code> <code>boolean</code> or <code>string</code> or <code>\"GENENAME\"</code> If <code>anno = True</code>, variants will anotated with chr:pos; or <code>string</code>, the column name used for annotation; or <code>\"GENENAME\"</code>, automatically annotate nrearest gene names, using pyensembl. (remember to specify <code>build</code>, default is <code>build=\"19\"</code>) <code>False</code> <code>anno_set</code> <code>list</code> If you want to annotate only a few specific variants, you can simply provide a list of SNPIDs or rsIDs for annotation. If None, the variants to annotate will be selected automatically using a sliding window with <code>windowsize=500</code>kb. <code>None</code> <code>repel_force</code> <code>float</code> when the annotation overlaps with other, try increasing the repel_force to increase the padding between annotations. <code>0.01</code> <code>anno_alias</code> <code>dict</code> snpid:text dictionary for customized annotation <code>None</code> <p>Repel force</p> <p></p> <p>Skip variants with -log10P&lt;3 and annotate the lead variants with chr:pos</p> <pre><code>mysumstats.plot_mqq(skip=3,anno=True)\n</code></pre> <p></p> <p>Skip variants with -log10P&lt;3 and annotate the lead variants with GENENAME</p> <pre><code>mysumstats.plot_mqq(skip=3,anno=\"GENENAME\",build=\"19\")\n</code></pre> <p></p> <p>Skip variants with -log10P&lt;3 and annotate the variants in <code>anno_set</code></p> <pre><code>mysumstats.plot_mqq(skip=3, anno_set=[\"rs12509595\",\"19:15040733:T:C\"])\n</code></pre> <p></p> <p>Skip variants with -log10P&lt;3 and annotate the variants in <code>anno_set</code> with alias in <code>anno_alias</code></p> <pre><code>mysumstats.plot_mqq(skip=3, anno_set=[\"rs12509595\",\"19:15040733:T:C\"], anno_alias={\"rs12509595\":\"anything you want here\"})\n</code></pre> <p></p>"},{"location":"Visualization/#26-annotation-style","title":"2.6 Annotation style","text":"<p>Added since 3.3.23</p> <p>GWASLab now support 3 types of annotation styles:</p> <ul> <li><code>expand</code></li> <li><code>right</code></li> <li><code>tight</code></li> </ul> <p><code>anno_style=\"expand\"</code></p> <p></p> <p><code>anno_style=\"right\"</code></p> <p></p> <p><code>anno_style=\"tight\"</code></p> <p></p>"},{"location":"Visualization/#27-adjust-arm-position","title":"2.7 Adjust arm position","text":"Option DataType Description Default <code>anno_d</code> <code>dict</code> key is the number of arm starting form 0, value is the direction you want the arm to shift towards . For example, <code>anno_d = {4:\"r\"}</code> means shift the 4th arm to the right <code>None</code> <code>arm_offset</code> <code>float</code> distance in points <code>500</code> <code>arm_scale</code> <code>float</code> factors to adjust the height for all arms <code>1.0</code> <code>arm_scale_d</code> <code>dict</code> factors to adjust the height for specific arms. key is the number of arm startinf form 0, value is the factor which will be multiplied to arm height. <code>None</code> <p>Adjust the direction the first to left and the thrd to right</p> <pre><code>mysumstats.plot_mqq(skip=2,anno=True)\n</code></pre> <p></p> <pre><code>mysumstats.plot_mqq(skip=2,anno=True,          \n                    anno_d={1:\"l\",3:\"r\"},\n                    arm_offset=50)\n</code></pre> <p></p> <p>Adjust the length of arm</p> <pre><code>mysumstats.plot_mqq(skip=2,anno=True,arm_scale=1.5)\n</code></pre> <p></p> <p>Adjust the length of arm for each variant</p> <pre><code>mysumstats.plot_mqq(skip=2,anno=True,arm_scale_d={1:1.5,2:1.2,3:1.1})\n</code></pre> <p></p>"},{"location":"Visualization/#28-highlight-specified-loci","title":"2.8 Highlight specified loci","text":"<p>Highlight specified loci (color all variants in a region by specifying variants and the length of flanking regions). </p> Highlighting Option DataType Description Default <code>highlight</code> <code>list</code> a list of SNPID or rsID; these loci (all variants in the specified variants positions +/- <code>highlight_windowkb</code>) will be highlighted in <code>pinpoint_color</code> <code>True</code> <code>highlight_windowkb</code> <code>int</code> Specify the span of highlighted region in kbp <code>500</code> <code>highlight_color</code> <code>list</code> Color for highlighting loci <code>\"#CB132D\"</code>"},{"location":"Visualization/#29-pinpoint-specified-variants","title":"2.9 Pinpoint specified variants","text":"<p>Pinpoint certain variants in the Manhattan plot.</p> Pinpointing Option DataType Description Default <code>pinpoint</code> <code>list</code> a list of SNPID or rsID; these variants will be highlighted in <code>pinpoint_color</code> <code>True</code> <code>pinpoint_color</code> <code>list</code> color for pinpointing variants <code>\"red\"</code> <p>Highlight loci and pinpoint variants</p> <pre><code>mysumstats.plot_mqq(skip=3,anno=\"GENENAME\",build=\"19\",\n                   highlight=[\"rs12509595\",\"rs7989823\"],\n                   pinpoint=[\"rs671\",\"19:15040733:T:C\"])\n</code></pre> <p></p>"},{"location":"Visualization/#210-lines","title":"2.10 Lines","text":"Line Option DataType Description Default <code>sig_line</code> <code>boolean</code> If True, plot the significant threshold line <code>True</code> <code>sig_level</code> <code>float</code> The significance threshold <code>5e-8</code> <code>sig_level_lead</code> <code>float</code> The significance threshold for extracting lead variants to annotate <code>5e-8</code> <code>sig_line_color</code> <code>string</code> If True, plot the significant threshold line <code>True</code> <code>suggestive_sig_line</code> <code>boolean</code> If True, plot the suggestive threshold line <code>True</code> <code>suggestive_sig_level</code> <code>float</code> The suggestive threshold <code>5e-6</code> <code>suggestive_sig_line_color</code> <code>string</code> Suggestive level line color <code>\"grey\"</code> <code>additional_line</code> <code>list</code> list of P values used to plot additional lines <code>None</code> <code>additional_line_color</code> <code>list</code> list of colors for the additional lines <code>None</code> <code>cut_line_color</code> <code>string</code> If True, plot the significant threshold line <code>\"#ebebeb\"</code> <p>Plot lines</p> <p><pre><code>mysumstats.plot_mqq(skip=3,\n                build=\"19\",\n                anno=\"GENENAME\",\n                windowsizekb=1000000,\n                cut=20,\n                cut_line_color=\"purple\",\n                sig_level=5e-8,  \n                sig_level_lead=1e-6, \n                sig_line_color=\"grey\",\n                suggestive_sig_line = True,\n                suggestive_sig_level = 1e-6,\n                suggestive_sig_line_color=\"blue\",\n                additional_line=[1e-40,1e-60],\n                additional_line_color=[\"yellow\",\"green\"])\n</code></pre> </p>"},{"location":"Visualization/#211-maf-stratified-qq-plot","title":"2.11 MAF-stratified QQ plot","text":"QQ plot Option DataType Description Default <code>stratified</code> <code>boolean</code> if True, plot MAF straitified QQ plot. Require EAF in sumstats. <code>False</code> <code>maf_bins</code> <code>list</code> MAF bins for straitification. <code>[(0, 0.01), (0.01, 0.05), (0.05, 0.25),(0.25,0.5)]</code> <code>maf_bin_colors</code> <code>list</code> colors used for each MAF bin. <code>[\"#f0ad4e\",\"#5cb85c\", \"#5bc0de\",\"#000042\"]</code> <p>MAF-stratified Q-Q plot</p> <p></p>"},{"location":"Visualization/#212-colors-and-fontsizes","title":"2.12 Colors and Fontsizes","text":"<pre><code>mysumstats.plot_mqq(\n          colors=[\"#597FBD\",\"#74BAD3\"],\n          cut_line_color=\"#ebebeb\",\n          sig_line_color=\"grey\",\n          highlight_color=\"#CB132D\",\n          pinpoint_color =\"red\",\n          maf_bin_colors = [\"#f0ad4e\",\"#5cb85c\", \"#5bc0de\",\"#000042\"],\n          fontsize = 10,\n          anno_fontsize = 10,\n          title_fontsize = 13,\n          marker_size=(5,25)\n)\n</code></pre> <p>Color-related options</p> Color Option DataType Description Default <code>colors</code> <code>list</code> a list of colors for chromsomes in the Manhattan plot; it will be used repetitively. <code>[\"#597FBD\",\"#74BAD3\"]</code> <code>cut_line_color</code> <code>string</code> color for the cut line. <code>\"#EBEBEB\"</code> <code>sig_line_color</code> <code>string</code> color for significance threshold line. <code>\"grey\"</code> <code>highlight_color</code> <code>string</code> color for highlighting loci <code>\"#CB132D\"</code> <code>pinpoint_color</code> <code>string</code> color for pinpointing variants <code>\"red\"</code> <code>maf_bin_colors</code> <code>list</code> a list of colors for maf-stratified Q-Q plot. <code>[\"#f0ad4e\",\"#5cb85c\", \"#5bc0de\",\"#000042\"]</code> <p>Font-related options</p> Font Option DataType Description Default <code>fontsize</code> <code>list</code> fontsize for ticklabels. <code>9</code> <code>title_fontsize</code> <code>13</code> fontsize for title. <code>13</code> <code>anno_fontsize</code> <code>10</code> fontsize for annotation. <code>9</code> <code>font_family</code> <code>string</code> font family <code>\"Arial\"</code> <p>Example</p> <p><pre><code>mysumstats.plot_mqq(skip=2,\n                    cut=20,\n                    colors=sns.color_palette(\"Set3\"),\n                    sig_line_color=\"red\",\n                    fontsize = 8)\n</code></pre> </p>"},{"location":"Visualization/#213-titles","title":"2.13 Titles","text":"<pre><code>mysumstats.plot_mqq(\n          title =None,\n          mtitle=None,\n          qtitle=None,\n          title_pad=1.08\n        )\n</code></pre> Title Option DataType Description Default <code>title</code> <code>string</code> title for the figure. `` <code>mtitle</code> <code>string</code> title for the Manhattan plot `` <code>qtitle</code> <code>string</code> title for the Q-Q plot `` <code>title_pad</code> <code>float</code> padding for title <code>1.08</code>"},{"location":"Visualization/#214-figure-settings","title":"2.14 Figure settings","text":"<pre><code>figargs= {\"figsize\":(15,5),\"dpi\":100}\n</code></pre> Figure Option DataType Description Default <code>figargs</code> <code>dict</code> key-values pairs that are passed to matplotlib <code>plt.subplots()</code> <code>{\"figsize\":(15,5),\"dpi\":200}</code> <p>Commonly used ones: </p> <ul> <li><code>figsize</code> : figure size</li> <li><code>dpi</code> : dots per inch. For pulications, dpi&gt;=300 is on of the common criteria.</li> </ul>"},{"location":"Visualization/#215-saving-plots","title":"2.15 Saving plots","text":"<pre><code>mysumstats.plot_mqq(save=\"mymqqplots.png\",save_args={\"dpi\":400,\"facecolor\":\"white\"})\n</code></pre> <p>Two options for saving plots in <code>.plot_mqq</code></p> Saving Option DataType Description Default <code>save</code> <code>string</code> or <code>boolean</code> If <code>string</code>, the plot will be saved to the specified path; If <code>True</code>, it will be saved to default path <code>True</code> <code>save_args</code> <code>dict</code> other parameters passed to matplotlib <code>savefig</code> function. <code>{\"dpi\":300,\"facecolor\":\"white\"}</code> <p>Example</p> <ul> <li>save as png: <code>mysumstats.plot_mqq(save=\"mymqqplots.png\",save_args={\"dpi\":300})</code></li> <li>save as PDF: <code>mysumstats.plot_mqq(save=\"mymqqplots.pdf\",save_args={\"dpi\":300})</code></li> </ul>"},{"location":"functions/","title":"gwaslab.Sumstats methods","text":""},{"location":"functions/#glsumstats","title":"gl.Sumstats","text":""},{"location":"functions/#standardization","title":"Standardization","text":"Sumstats Methods Options Description <code>.fix_id()</code> <code>fixchrpos=False</code>, <code>fixid=False</code>, <code>fixsep=False</code>,<code>overwrite=False</code>,<code>forcefixid=False</code> check and\u00a0 fix rsID or SNPID(chr:pos:ref:alt), or use snpid to fix CHR and POS <code>.fix_CHR()</code> <code>remove=False</code> standardize chromsome notation <code>.fix_POS()</code> <code>remove=False</code> standardize basepair posituion notation and filter out bad values <code>.fix_allele()</code> <code>remove=False</code> standardize base notation to ATCG <code>.normalize_allele()</code> <code>n_cores=1</code> normalize indels (only support ATA:AA -&gt; AT:A but not -:T) <code>.sort_coordinate()</code> sort the variant coordinates <code>.sort_column()</code> sort the column order to GWASLab default <code>.basic_check()</code> all in one function"},{"location":"functions/#qc-and-filtering","title":"QC and filtering","text":"Sumstats Methods Options Description <code>.check_sanity()</code> <code>n=(0,float(\"Inf\"))</code>, <code>eaf=(0,1)</code>, <code>mac=(5,float(\"Inf\"))</code>, <code>chisq=(0,float(\"Inf\"))</code>, <code>p=(5e-300,1)</code>, <code>mlog10p=(0,float(\"Inf\"))</code>, <code>beta=(-10,10)</code>, <code>z=(-37.5,37.5)</code>, <code>se=(0,float(\"Inf\"))</code>, <code>OR=(-10,10)</code> , <code>OR_95L=(0,float(\"Inf\"))</code>, <code>OR_95U=(0,float(\"Inf\"))</code>, <code>info=(0,float(\"Inf\"))</code> sanity check for statistics including BETA, SE, Z, CHISQ, EAF, OR, N... <code>.remove_dup()</code> <code>mode=\"md\"</code>, <code>keep='first'</code>, <code>keep_col=\"P\"</code>, <code>remove=False</code> remove duplicated, multiallelic or NA variants <code>.filter_value()</code> expr filter in variants base on expr <code>.filter_in()</code> lt, gt, eq, inplace filter in variants base on given threshold <code>.filter_out()</code> lt, gt, eq, inplace filter out variants base on given threshold <code>.filter_region_in()</code> <code>path</code> ,  <code>inplace=True</code> , <code>high_ld=False</code>,  <code>build=\"19\"</code> filter in variants in the specified region define by a bed file <code>.filter_region_out()</code> <code>path</code> ,  <code>inplace=True</code> , <code>high_ld=False</code>,  <code>build=\"19\"</code> filter out variants in the specified region define by a bed file"},{"location":"functions/#harmonization","title":"Harmonization","text":"Sumstats Methods Options Description <code>.check_ref()</code> ref_path check alignment with a reference sequence <code>.rsid_to_chrpos()</code> path,\u00a0n_cores use rsid to fill CHR and POS <code>.rsid_to_chrpos2()</code> path use rsid to fill CHR and POS (muilti-thread, need hd5 file) <code>.assign_rsid()</code> path annotate rsid using a reference vcf file <code>.infer_strand()</code> ref_infer=\"\" , ref_alt_freq=None,\u00a0 maf_threshold=0.43 infer the strand of a variant using reference vcf file with EAF in INFO <code>.check_daf()</code> ref_infer=\"\" , ref_alt_freq=None, calculate difference in allele frequencies <code>.flip_allele_stats()</code> After alignment and inferring, flip the alleles to harmonise the variants. <code>.liftover()</code> n_cores=1,from_build=\"19\", to_build=\"38\" perform liftover"},{"location":"functions/#standalone-functions","title":"Standalone functions","text":"function catagory description"},{"location":"harmonization_workflow/","title":"Harmonization","text":"In\u00a0[1]: Copied! <pre>import gwaslab as gl\n</pre> import gwaslab as gl In\u00a0[2]: Copied! <pre>mysumstats = gl.Sumstats(\"/home/yunye/work/gwaslab/examples/toy_data/to_harmonize.tsv\",fmt=\"gwaslab\",other=[\"NOTE\"])\n</pre> mysumstats = gl.Sumstats(\"/home/yunye/work/gwaslab/examples/toy_data/to_harmonize.tsv\",fmt=\"gwaslab\",other=[\"NOTE\"]) <pre>Fri Feb  2 19:36:24 2024 GWASLab v3.4.38 https://cloufield.github.io/gwaslab/\nFri Feb  2 19:36:24 2024 (C) 2022-2024, Yunye He, Kamatani Lab, MIT License, gwaslab@gmail.com\nFri Feb  2 19:36:24 2024 Start to load format from formatbook....\nFri Feb  2 19:36:24 2024  -gwaslab format meta info:\nFri Feb  2 19:36:24 2024   - format_name  : gwaslab\nFri Feb  2 19:36:24 2024   - format_source  : https://cloufield.github.io/gwaslab/\nFri Feb  2 19:36:24 2024   - format_version  : 20231220_v4\nFri Feb  2 19:36:24 2024 Start to initialize gl.Sumstats from file :/home/yunye/work/gwaslab/examples/toy_data/to_harmonize.tsv\nFri Feb  2 19:36:24 2024  -Reading columns          : CHR,NEA,SE,P,DIRECTION,BETA,SNPID,NOTE,N,EAF,EA,POS\nFri Feb  2 19:36:24 2024  -Renaming columns to      : CHR,NEA,SE,P,DIRECTION,BETA,SNPID,NOTE,N,EAF,EA,POS\nFri Feb  2 19:36:24 2024  -Current Dataframe shape : 15  x  12\nFri Feb  2 19:36:24 2024  -Initiating a status column: STATUS ...\nFri Feb  2 19:36:24 2024  #WARNING! Version of genomic coordinates is unknown...\nFri Feb  2 19:36:24 2024 Start to reorder the columns...v3.4.38\nFri Feb  2 19:36:24 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 19.94 MB\nFri Feb  2 19:36:24 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,P,N,DIRECTION,STATUS,NOTE\nFri Feb  2 19:36:24 2024 Finished reordering the columns.\nFri Feb  2 19:36:24 2024  -Column  : SNPID  CHR    POS   EA       NEA      EAF     BETA    SE      P       N     DIRECTION STATUS   NOTE  \nFri Feb  2 19:36:24 2024  -DType   : object string int64 category category float64 float64 float64 float64 int64 object    category object\nFri Feb  2 19:36:24 2024  -Verified: T      F      T     T        T        T       T       T       T       T     T         T        NA    \nFri Feb  2 19:36:24 2024  #WARNING! Columns with possibly incompatable dtypes: CHR\nFri Feb  2 19:36:24 2024  -Current Dataframe memory usage: 19.94 MB\nFri Feb  2 19:36:24 2024 Finished loading data successfully!\n</pre> <p>A list of variants that needs to be harmonized. Issues are described in NOTE column.</p> In\u00a0[3]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[3]: SNPID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS NOTE 0 1:1066403:T:C 1 1066403 C T 0.5276 0.0043 0.0109 0.68910 191764 ++-+ 9999999 Clean 1 1:1163266:G:A 1 1163266 G A 0.8355 0.0122 0.0120 0.30810 191764 -+++ 9999999 Flip 2 1:1213224:T:A 1 1213224 T A 0.3345 0.0071 0.0095 0.45280 191764 +++- 9999999 Flip + Palindromic 3 1:3066761:A:T 1 3066761 T A 0.1245 -0.0066 0.0157 0.67420 191764 -+++ 9999999 Palindromic + No flip 4 1:3997271:T:TTTTA 1 3997271 TTTTA T 0.3840 0.0188 0.0135 0.16300 191764 ++++ 9999999 Indel + Both on genome + No flip 5 1:4007705:TC:T 1 4007705 TC T 0.4368 0.0306 0.0125 0.01421 191764 ++++ 9999999 Indel  + Both on genome + Flip 6 1:5164281:A:AAGAG 1 5164281 AAGAG A 0.9871 0.0167 0.0454 0.71200 191764 -+++ 9999999 Indel 7 1:12799025:C:CCT 1 12799025 C CCT 0.1730 -0.0186 0.0118 0.11500 191764 ---+ 9999999 Indel + Flip 8 1:19323015:T:A 1 19323015 T A 0.4389 -0.0165 0.0088 0.05949 191764 ---- 9999999 Palindromic + Flip + Indistinguishable 9 1:22841855:A:T 1 22841855 T A 0.4527 0.0080 0.0095 0.39980 191764 -++- 9999999 Palindromic + Indistinguishable 10 3:183629306:T:TTCTC 3 183629306 TTCTC T 0.0082 -0.0083 0.0555 0.88060 191764 +--+ 9999999 Indel  + Both on genome + No information 11 4:99731866:G:C 4 99731866 G C 0.3883 0.0052 0.0093 0.57360 191764 +-++ 9999999 Palindromic+ Flip + Different strand (REF G, T... 12 8:89935201:C:G 8 89935201 G C 0.3533 0.0103 0.0094 0.27560 191764 ++++ 9999999 Palindromic + Different strand (REF A; TOMMO G... 13 X:4206466:G:C X 4206466 G C 0.8727 -0.0055 0.0104 0.59840 191764 -+-- 9999999 Palindromic + Flip + No information 14 X:5053229:A:T X 5053229 T A 0.9747 0.0218 0.0225 0.33180 191764 ++++ 9999999 Palindromic + No information <ul> <li>ref_seq : reference genome fasta file for allele alignment</li> <li>ref_infer : vcf file with allele frequency information for inferring strand and comparing allele frequency </li> <li>ref_alt_freq : field in INFO of vcf file for alternative allele frequency</li> </ul> In\u00a0[4]: Copied! <pre>mysumstats.harmonize(   basic_check=True,\n                        n_cores=1,\n                        ref_seq=gl.get_path(\"ucsc_genome_hg19\"),\n                        ref_infer=gl.get_path(\"1kg_eas_hg19\"),\n                        ref_alt_freq=\"AF\")\n</pre> mysumstats.harmonize(   basic_check=True,                         n_cores=1,                         ref_seq=gl.get_path(\"ucsc_genome_hg19\"),                         ref_infer=gl.get_path(\"1kg_eas_hg19\"),                         ref_alt_freq=\"AF\") <pre>Fri Feb  2 19:36:24 2024 Start to check SNPID/rsID...v3.4.38\nFri Feb  2 19:36:24 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 19.94 MB\nFri Feb  2 19:36:24 2024  -Checking SNPID data type...\nFri Feb  2 19:36:24 2024  -Converting SNPID to pd.string data type...\nFri Feb  2 19:36:24 2024  -Checking if SNPID is CHR:POS:NEA:EA...(separator: - ,: , _)\nFri Feb  2 19:36:25 2024 Finished checking SNPID/rsID.\nFri Feb  2 19:36:25 2024 Start to fix chromosome notation (CHR)...v3.4.38\nFri Feb  2 19:36:25 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 19.94 MB\nFri Feb  2 19:36:25 2024  -Checking CHR data type...\nFri Feb  2 19:36:25 2024  -Variants with standardized chromosome notation: 13\nFri Feb  2 19:36:25 2024  -Variants with fixable chromosome notations: 2\nFri Feb  2 19:36:25 2024  -No unrecognized chromosome notations...\nFri Feb  2 19:36:25 2024  -Identifying non-autosomal chromosomes : X, Y, and MT ...\nFri Feb  2 19:36:25 2024  -Identified  2  variants on sex chromosomes...\nFri Feb  2 19:36:25 2024  -Standardizing sex chromosome notations: X to 23...\nFri Feb  2 19:36:27 2024 Finished fixing chromosome notation (CHR).\nFri Feb  2 19:36:27 2024 Start to fix basepair positions (POS)...v3.4.38\nFri Feb  2 19:36:27 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 19.94 MB\nFri Feb  2 19:36:27 2024  -Converting to Int64 data type ...\nFri Feb  2 19:36:28 2024  -Position bound:(0 , 250,000,000)\nFri Feb  2 19:36:28 2024  -Removed outliers: 0\nFri Feb  2 19:36:28 2024 Finished fixing basepair positions (POS).\nFri Feb  2 19:36:28 2024 Start to fix alleles (EA and NEA)...v3.4.38\nFri Feb  2 19:36:28 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 19.94 MB\nFri Feb  2 19:36:28 2024  -Converted all bases to string datatype and UPPERCASE.\nFri Feb  2 19:36:28 2024  -Variants with bad EA  : 0\nFri Feb  2 19:36:28 2024  -Variants with bad NEA : 0\nFri Feb  2 19:36:28 2024  -Variants with NA for EA or NEA: 0\nFri Feb  2 19:36:28 2024  -Variants with same EA and NEA: 0\nFri Feb  2 19:36:28 2024  -Detected 0 variants with alleles that contain bases other than A/C/T/G .\nFri Feb  2 19:36:30 2024 Finished fixing alleles (EA and NEA).\nFri Feb  2 19:36:30 2024 Start to perform sanity check for statistics...v3.4.38\nFri Feb  2 19:36:30 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 19.94 MB\nFri Feb  2 19:36:30 2024  -Comparison tolerance for floats: 1e-07\nFri Feb  2 19:36:30 2024  -Checking if 0 &lt;= N &lt;= 2147483647 ...\nFri Feb  2 19:36:30 2024  -Removed 0 variants with bad/na N.\nFri Feb  2 19:36:30 2024  -Checking if -1e-07 &lt; EAF &lt; 1.0000001 ...\nFri Feb  2 19:36:30 2024  -Removed 0 variants with bad/na EAF.\nFri Feb  2 19:36:30 2024  -Checking if -1e-07 &lt; P &lt; 1.0000001 ...\nFri Feb  2 19:36:30 2024  -Removed 0 variants with bad/na P.\nFri Feb  2 19:36:30 2024  -Checking if -100.0000001 &lt; BETA &lt; 100.0000001 ...\nFri Feb  2 19:36:30 2024  -Removed 0 variants with bad/na BETA.\nFri Feb  2 19:36:30 2024  -Checking if -1e-07 &lt; SE &lt; inf ...\nFri Feb  2 19:36:30 2024  -Removed 0 variants with bad/na SE.\nFri Feb  2 19:36:30 2024  -Checking STATUS and converting STATUS to categories....\nFri Feb  2 19:36:30 2024  -Removed 0 variants with bad statistics in total.\nFri Feb  2 19:36:30 2024  -Data types for each column:\nFri Feb  2 19:36:30 2024  -Column  : SNPID  CHR   POS   EA       NEA      EAF     BETA    SE      P       N     DIRECTION STATUS   NOTE  \nFri Feb  2 19:36:30 2024  -DType   : string Int64 Int64 category category float32 float64 float64 float64 Int64 object    category object\nFri Feb  2 19:36:30 2024  -Verified: T      T     T     T        T        T       T       T       T       T     T         T        NA    \nFri Feb  2 19:36:30 2024 Finished sanity check for statistics.\nFri Feb  2 19:36:30 2024 Start to normalize indels...v3.4.38\nFri Feb  2 19:36:30 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 19.94 MB\nFri Feb  2 19:36:30 2024  -No available variants to normalize..\nFri Feb  2 19:36:30 2024 Finished normalizing variants successfully!\nFri Feb  2 19:36:30 2024 Start to reorder the columns...v3.4.38\nFri Feb  2 19:36:30 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 19.94 MB\nFri Feb  2 19:36:30 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,P,N,DIRECTION,STATUS,NOTE\nFri Feb  2 19:36:30 2024 Finished reordering the columns.\nFri Feb  2 19:36:31 2024 Start to check if NEA is aligned with reference sequence...v3.4.38\nFri Feb  2 19:36:31 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 19.94 MB\nFri Feb  2 19:36:31 2024  -Reference genome FASTA file: /home/yunye/.gwaslab/hg19.fa\nFri Feb  2 19:36:31 2024  -Checking records: 1  2  3  4  5  6  7  X  8  9  10  11  12  13  14  15  16  17  18  20  Y  19  22  21  M  \nFri Feb  2 19:36:47 2024  -Variants allele on given reference sequence :  6\nFri Feb  2 19:36:47 2024  -Variants flipped :  6\nFri Feb  2 19:36:47 2024   -Raw Matching rate :  80.00%\nFri Feb  2 19:36:47 2024  -Variants inferred reverse_complement :  0\nFri Feb  2 19:36:47 2024  -Variants inferred reverse_complement_flipped :  0\nFri Feb  2 19:36:47 2024  -Both allele on genome + unable to distinguish :  3\nFri Feb  2 19:36:47 2024  -Variants not on given reference sequence :  0\nFri Feb  2 19:36:47 2024 Finished checking if NEA is aligned with reference sequence.\nFri Feb  2 19:36:47 2024 Start to adjust statistics based on STATUS code...v3.4.38\nFri Feb  2 19:36:47 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 0.00 MB\nFri Feb  2 19:36:47 2024 Start to flip allele-specific stats for SNPs with status xxxxx[35]x: ALT-&gt;EA , REF-&gt;NEA ...v3.4.38\nFri Feb  2 19:36:47 2024  -Flipping 6 variants...\nFri Feb  2 19:36:47 2024  -Swapping column: NEA &lt;=&gt; EA...\nFri Feb  2 19:36:47 2024  -Flipping column: BETA = - BETA...\nFri Feb  2 19:36:47 2024  -Flipping column: DIRECTION +-?0 &lt;=&gt; -+?0 ...\nFri Feb  2 19:36:47 2024  -Flipping column: EAF = 1 - EAF...\nFri Feb  2 19:36:47 2024  -Changed the status for flipped variants : xxxxx[35]x -&gt; xxxxx[12]x\nFri Feb  2 19:36:47 2024 Finished adjusting.\nFri Feb  2 19:36:47 2024 Start to infer strand for palindromic SNPs/align indistinguishable indels...v3.4.38\nFri Feb  2 19:36:47 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 0.00 MB\nFri Feb  2 19:36:47 2024  -Number of threads/cores to use: 1\nFri Feb  2 19:36:47 2024  -Reference VCF: /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\nFri Feb  2 19:36:47 2024  -Checking prefix for chromosomes in vcf files...\nFri Feb  2 19:36:47 2024  -No prefix for chromosomes in the VCF files.\nFri Feb  2 19:36:47 2024  -Field for alternative allele frequency in VCF INFO: AF\nFri Feb  2 19:36:47 2024  -Identified  8  palindromic SNPs...\nFri Feb  2 19:36:47 2024  -After filtering by MAF&lt; 0.4 , 6 palindromic SNPs with unknown strand will be inferred...\nFri Feb  2 19:36:47 2024   -Non-palindromic :  2\nFri Feb  2 19:36:47 2024   -Palindromic SNPs on + strand:  2\nFri Feb  2 19:36:47 2024   -Palindromic SNPs on - strand and needed to be flipped: 2\nFri Feb  2 19:36:47 2024   -Palindromic SNPs with MAF not available to infer :  2\nFri Feb  2 19:36:47 2024   -Palindromic SNPs with no macthes or no information :  1\nFri Feb  2 19:36:47 2024  -Identified  3  indistinguishable Indels...\nFri Feb  2 19:36:47 2024  -Indistinguishable indels will be inferred from reference vcf ref and alt...\nFri Feb  2 19:36:47 2024  -DAF tolerance: 0.2\nFri Feb  2 19:36:47 2024   -Indels ea/nea match reference :  1\nFri Feb  2 19:36:47 2024   -Indels ea/nea need to be flipped :  1\nFri Feb  2 19:36:47 2024   -Indels with no macthes or no information :  1\nFri Feb  2 19:36:47 2024 Finished inferring strand for palindromic SNPs/align indistinguishable indels.\nFri Feb  2 19:36:47 2024 Start to adjust statistics based on STATUS code...v3.4.38\nFri Feb  2 19:36:47 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 0.00 MB\nFri Feb  2 19:36:47 2024 Start to flip allele-specific stats for standardized indels with status xxxx[123][67][6]: ALT-&gt;EA , REF-&gt;NEA...v3.4.38\nFri Feb  2 19:36:47 2024  -Flipping 1 variants...\nFri Feb  2 19:36:47 2024  -Swapping column: NEA &lt;=&gt; EA...\nFri Feb  2 19:36:47 2024  -Flipping column: BETA = - BETA...\nFri Feb  2 19:36:47 2024  -Flipping column: DIRECTION +-?0 &lt;=&gt; -+?0 ...\nFri Feb  2 19:36:47 2024  -Flipping column: EAF = 1 - EAF...\nFri Feb  2 19:36:47 2024  -Changed the status for flipped variants xxxx[123][67]6 -&gt; xxxx[123][67]4\nFri Feb  2 19:36:47 2024 Start to flip allele-specific stats for palindromic SNPs with status xxxxx[12]5: (-)strand &lt;=&gt; (+)strand...v3.4.38\nFri Feb  2 19:36:47 2024  -Flipping 2 variants...\nFri Feb  2 19:36:47 2024  -Flipping column: BETA = - BETA...\nFri Feb  2 19:36:47 2024  -Flipping column: DIRECTION +-?0 &lt;=&gt; -+?0 ...\nFri Feb  2 19:36:47 2024  -Flipping column: EAF = 1 - EAF...\nFri Feb  2 19:36:47 2024  -Changed the status for flipped variants:  xxxxx[012]5: -&gt;  xxxxx[012]2\nFri Feb  2 19:36:47 2024 Finished adjusting.\nFri Feb  2 19:36:48 2024 Start to sort the genome coordinates...v3.4.38\nFri Feb  2 19:36:48 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 0.00 MB\nFri Feb  2 19:36:48 2024 Finished sorting coordinates.\nFri Feb  2 19:36:48 2024 Start to reorder the columns...v3.4.38\nFri Feb  2 19:36:48 2024  -Current Dataframe shape : 15 x 13 ; Memory usage: 0.00 MB\nFri Feb  2 19:36:48 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,P,N,DIRECTION,STATUS,NOTE\nFri Feb  2 19:36:48 2024 Finished reordering the columns.\n</pre> Out[4]: <pre>&lt;gwaslab.g_Sumstats.Sumstats at 0x7f6c69f86550&gt;</pre> <p>All variants were checked and harmonized based on the reference datasets. The manipulations are reflected in STATUS column.</p> In\u00a0[5]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[5]: SNPID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS NOTE 0 1:1066403:T:C 1 1066403 C T 0.5276 0.0043 0.0109 0.68910 191764 ++-+ 9960000 Clean 1 1:1163266:G:A 1 1163266 A G 0.1645 -0.0122 0.0120 0.30810 191764 +--- 9960010 Flip 2 1:1213224:T:A 1 1213224 A T 0.6655 -0.0071 0.0095 0.45280 191764 ---+ 9960011 Flip + Palindromic 3 1:3066761:A:T 1 3066761 T A 0.1245 -0.0066 0.0157 0.67420 191764 -+++ 9960001 Palindromic + No flip 4 1:3997271:T:TTTTA 1 3997271 TTTTA T 0.3840 0.0188 0.0135 0.16300 191764 ++++ 9960363 Indel + Both on genome + No flip 5 1:4007705:TC:T 1 4007705 T TC 0.5632 -0.0306 0.0125 0.01421 191764 ---- 9960364 Indel  + Both on genome + Flip 6 1:5164281:A:AAGAG 1 5164281 AAGAG A 0.9871 0.0167 0.0454 0.71200 191764 -+++ 9960309 Indel 7 1:12799025:C:CCT 1 12799025 CCT C 0.8270 0.0186 0.0118 0.11500 191764 +++- 9960319 Indel + Flip 8 1:19323015:T:A 1 19323015 A T 0.5611 0.0165 0.0088 0.05949 191764 ++++ 9960017 Palindromic + Flip + Indistinguishable 9 1:22841855:A:T 1 22841855 T A 0.4527 0.0080 0.0095 0.39980 191764 -++- 9960007 Palindromic + Indistinguishable 10 3:183629306:T:TTCTC 3 183629306 TTCTC T 0.0082 -0.0083 0.0555 0.88060 191764 +--+ 9960368 Indel  + Both on genome + No information 11 4:99731866:G:C 4 99731866 C G 0.3883 0.0052 0.0093 0.57360 191764 +-++ 9960012 Palindromic+ Flip + Different strand (REF G, T... 12 8:89935201:C:G 8 89935201 G C 0.6467 -0.0103 0.0094 0.27560 191764 ---- 9960002 Palindromic + Different strand (REF A; TOMMO G... 13 X:4206466:G:C 23 4206466 C G 0.1273 0.0055 0.0104 0.59840 191764 +-++ 9960018 Palindromic + Flip + No information 14 X:5053229:A:T 23 5053229 T A 0.9747 0.0218 0.0225 0.33180 191764 ++++ 9960008 Palindromic + No information In\u00a0[6]: Copied! <pre>mysumstats.summary()\n</pre> mysumstats.summary() Out[6]: Values Percentage Category Items META Row_num 15 &lt;NA&gt; Column_num 13 &lt;NA&gt; Column_names SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,P,N,DIRECTION... &lt;NA&gt; Last_checked_time Fri Feb  2 19:36:48 2024 &lt;NA&gt; MISSING Missing_total 0 0.0 MAF Common 12 80.0 Low_frequency 2 13.33 Rare 1 6.67 P Minimum 0.01421 0.09 Significant 0 0.0 Suggestive 0 0.0 STATUS 9960000 1 6.67 9960001 1 6.67 9960002 1 6.67 9960007 1 6.67 9960008 1 6.67 9960010 1 6.67 9960011 1 6.67 9960012 1 6.67 9960017 1 6.67 9960018 1 6.67 9960309 1 6.67 9960319 1 6.67 9960363 1 6.67 9960364 1 6.67 9960368 1 6.67 In\u00a0[7]: Copied! <pre>mysumstats.lookup_status()\n</pre> mysumstats.lookup_status() Out[7]: Genome_Build rsID&amp;SNPID CHR&amp;POS Stadardize&amp;Normalize Align Panlidromic_SNP&amp;Indel Count Percentage(%) 9960000 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Match: NEA=REF Not_palindromic_SNPs 1 6.67 9960001 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Match: NEA=REF Palindromic+strand 1 6.67 9960002 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Match: NEA=REF Palindromic-strand_fixed 1 6.67 9960007 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Match: NEA=REF Indistinguishable 1 6.67 9960008 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Match: NEA=REF No_matching_or_no_info 1 6.67 9960010 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Flipped_fixed Not_palindromic_SNPs 1 6.67 9960011 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Flipped_fixed Palindromic+strand 1 6.67 9960012 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Flipped_fixed Palindromic-strand_fixed 1 6.67 9960017 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Flipped_fixed Indistinguishable 1 6.67 9960018 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Flipped_fixed No_matching_or_no_info 1 6.67 9960309 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized &amp; normalized indel Match: NEA=REF Unchecked 1 6.67 9960319 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized &amp; normalized indel Flipped_fixed Unchecked 1 6.67 9960363 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized &amp; normalized indel Both_alleles_on_ref+indistinguishable Indel_match 1 6.67 9960364 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized &amp; normalized indel Both_alleles_on_ref+indistinguishable Indel_flipped_fixed 1 6.67 9960368 Unchecked rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized &amp; normalized indel Both_alleles_on_ref+indistinguishable No_matching_or_no_info 1 6.67 <p>For some reference file the chromosome notation is not in the form of 1, or chr1, instead, they are using NCBI Sequence Identifiers (for example: NC_000001.11).</p> <p>See https://www.ncbi.nlm.nih.gov/genbank/sequenceids/</p> For example: GCF_000001405.25.vcf.gz  NC_000001.10    10059   rs1570391745    C       G       .       .       RS=1570391745;dbSNPBuildID=154;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=SNV;R5;GNO;FREQ=KOREAN:0.9997,0.0003425|dbGaP_PopFreq:1,0  NC_000001.10    10060   rs1639544146    C       CT      .       .       RS=1639544146;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=INDEL;R5;GNO;FREQ=dbGaP_PopFreq:1,0  NC_000001.10    10060   rs1639544159    CT      C       .       .       RS=1639544159;SSR=0;PSEUDOGENEINFO=DDX11L1:100287102;VC=DEL;R5;GNO;FREQ=dbGaP_PopFreq:1,0  <p>In such case, gwaslab provide built-in conversion table.</p> In\u00a0[\u00a0]: Copied! <pre>gl.get_number_to_NC(build=\"19\")\n</pre> gl.get_number_to_NC(build=\"19\") <p>Specify it in assignrsid_args and inferstrand_args for the all-in-one function:</p> In\u00a0[\u00a0]: Copied! <pre>mysumstats.harmonize(   basic_check=False,\n                        n_cores=3,\n                        ref_infer=\"/home/yunye/mydata/d_disk/dbsnp/GCF_000001405.25.vcf.gz\",\n                        inferstrand_args= {\"chr_dict\" : gl.get_number_to_NC(build=\"19\")})\n</pre> mysumstats.harmonize(   basic_check=False,                         n_cores=3,                         ref_infer=\"/home/yunye/mydata/d_disk/dbsnp/GCF_000001405.25.vcf.gz\",                         inferstrand_args= {\"chr_dict\" : gl.get_number_to_NC(build=\"19\")})"},{"location":"harmonization_workflow/#harmonization","title":"Harmonization\u00b6","text":""},{"location":"harmonization_workflow/#load-test-data","title":"Load test data\u00b6","text":""},{"location":"harmonization_workflow/#perform-harmonization","title":"Perform harmonization\u00b6","text":""},{"location":"harmonization_workflow/#check-summary","title":"Check summary\u00b6","text":""},{"location":"harmonization_workflow/#vcf-ncbi-sequence-identifiers","title":"VCF : NCBI Sequence Identifiers\u00b6","text":""},{"location":"standardization_workflow/","title":"Standardization","text":"In\u00a0[1]: Copied! <pre>import gwaslab as gl\n</pre> import gwaslab as gl In\u00a0[2]: Copied! <pre>mysumstats = gl.Sumstats(\"/home/yunye/work/gwaslab/examples/toy_data/dirty_sumstats.tsv\",fmt=\"gwaslab\",other=[\"NOTE\"])\n</pre> mysumstats = gl.Sumstats(\"/home/yunye/work/gwaslab/examples/toy_data/dirty_sumstats.tsv\",fmt=\"gwaslab\",other=[\"NOTE\"]) <pre>Fri Feb  2 19:46:01 2024 GWASLab v3.4.38 https://cloufield.github.io/gwaslab/\nFri Feb  2 19:46:01 2024 (C) 2022-2024, Yunye He, Kamatani Lab, MIT License, gwaslab@gmail.com\nFri Feb  2 19:46:01 2024 Start to load format from formatbook....\nFri Feb  2 19:46:01 2024  -gwaslab format meta info:\nFri Feb  2 19:46:01 2024   - format_name  : gwaslab\nFri Feb  2 19:46:01 2024   - format_source  : https://cloufield.github.io/gwaslab/\nFri Feb  2 19:46:01 2024   - format_version  : 20231220_v4\nFri Feb  2 19:46:01 2024 Start to initialize gl.Sumstats from file :/home/yunye/work/gwaslab/examples/toy_data/dirty_sumstats.tsv\nFri Feb  2 19:46:01 2024  -Reading columns          : BETA,DIRECTION,EA,P,N,NOTE,NEA,CHISQ,EAF,POS,MLOG10P,Z,N_CONTROL,OR_95L,SNPID,CHR,OR_95U,SE,N_CASE,OR\nFri Feb  2 19:46:01 2024  -Renaming columns to      : BETA,DIRECTION,EA,P,N,NOTE,NEA,CHISQ,EAF,POS,MLOG10P,Z,N_CONTROL,OR_95L,SNPID,CHR,OR_95U,SE,N_CASE,OR\nFri Feb  2 19:46:01 2024  -Current Dataframe shape : 63  x  20\nFri Feb  2 19:46:01 2024  -Initiating a status column: STATUS ...\nFri Feb  2 19:46:01 2024  #WARNING! Version of genomic coordinates is unknown...\nFri Feb  2 19:46:01 2024 Start to reorder the columns...v3.4.38\nFri Feb  2 19:46:01 2024  -Current Dataframe shape : 63 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:01 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,Z,CHISQ,P,MLOG10P,OR,OR_95L,OR_95U,N,N_CASE,N_CONTROL,DIRECTION,STATUS,NOTE\nFri Feb  2 19:46:01 2024 Finished reordering the columns.\nFri Feb  2 19:46:01 2024  -Column  : SNPID  CHR    POS    EA       NEA      EAF     BETA    SE      Z       CHISQ   P       MLOG10P OR      OR_95L  OR_95U  N       N_CASE N_CONTROL DIRECTION STATUS   NOTE  \nFri Feb  2 19:46:01 2024  -DType   : object string object category category float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 float64 int64  int64     object    category object\nFri Feb  2 19:46:01 2024  -Verified: T      F      F      T        T        T       T       T       T       T       T       T       T       T       T       F       T      T         T         T        NA    \nFri Feb  2 19:46:01 2024  #WARNING! Columns with possibly incompatable dtypes: CHR,POS,N\nFri Feb  2 19:46:02 2024  -Current Dataframe memory usage: 19.95 MB\nFri Feb  2 19:46:02 2024 Finished loading data successfully!\n</pre> <p>Dirty sumstats with issues specified in NOTE column</p> In\u00a0[3]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[3]: SNPID CHR POS EA NEA EAF BETA SE Z CHISQ ... MLOG10P OR OR_95L OR_95U N N_CASE N_CONTROL DIRECTION STATUS NOTE 0 1:1_G_A 1 1 A G 0.004 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9999999 Duplicated 1 1:1_A_G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9999999 Duplicated 2 1:1_A_G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9999999 Duplicated 3 1:2 1 2 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9999999 Multiallelic 4 1:2 1 2 T TAA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9999999 Multiallelic ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 58 51 1 51 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 12345.000000 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9999999 MLOG10P out of range 59 52 1 52 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... -0.100000 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9999999 MLOG10P out of range 60 53 1 53 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... NaN 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9999999 MLOG10P missing 61 54 1 54 AG A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9999999 Clean sumstats 62 55 1 55 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9999999 Clean sumstats <p>63 rows \u00d7 21 columns</p> In\u00a0[4]: Copied! <pre>mysumstats.basic_check(remove=True,remove_dup=True)\n</pre> mysumstats.basic_check(remove=True,remove_dup=True) <pre>Fri Feb  2 19:46:02 2024 Start to check SNPID/rsID...v3.4.38\nFri Feb  2 19:46:02 2024  -Current Dataframe shape : 63 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:02 2024  -Checking SNPID data type...\nFri Feb  2 19:46:02 2024  -Converting SNPID to pd.string data type...\nFri Feb  2 19:46:02 2024  -Checking if SNPID is CHR:POS:NEA:EA...(separator: - ,: , _)\nFri Feb  2 19:46:03 2024 Finished checking SNPID/rsID.\nFri Feb  2 19:46:03 2024 Start to fix chromosome notation (CHR)...v3.4.38\nFri Feb  2 19:46:03 2024  -Current Dataframe shape : 63 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:03 2024  -Checking CHR data type...\nFri Feb  2 19:46:03 2024  -Variants with standardized chromosome notation: 56\nFri Feb  2 19:46:03 2024  -Variants with fixable chromosome notations: 4\nFri Feb  2 19:46:03 2024  -Variants with NA chromosome notations: 1\nFri Feb  2 19:46:03 2024  -Variants with invalid chromosome notations: 2\nFri Feb  2 19:46:03 2024  -A look at invalid chromosome notations: {'1.0001', '-1'}\nFri Feb  2 19:46:03 2024  -Identifying non-autosomal chromosomes : X, Y, and MT ...\nFri Feb  2 19:46:03 2024  -Identified  1  variants on sex chromosomes...\nFri Feb  2 19:46:03 2024  -Standardizing sex chromosome notations: X to 23...\nFri Feb  2 19:46:04 2024  -Valid CHR list: 1 - 25\nFri Feb  2 19:46:04 2024  -Removed 5 variants with chromosome notations not in CHR list.\nFri Feb  2 19:46:04 2024  -A look at chromosome notations not in CHR list: {'0', '300', &lt;NA&gt;}\nFri Feb  2 19:46:04 2024 Finished fixing chromosome notation (CHR).\nFri Feb  2 19:46:04 2024 Start to fix basepair positions (POS)...v3.4.38\nFri Feb  2 19:46:04 2024  -Current Dataframe shape : 58 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:04 2024  -Removing thousands separator \",\" or underbar \"_\" ...\nFri Feb  2 19:46:04 2024  -Converting to Int64 data type ...\nFri Feb  2 19:46:04 2024  -Force converting to Int64 data type ...\nFri Feb  2 19:46:05 2024  -Position bound:(0 , 250,000,000)\nFri Feb  2 19:46:05 2024  -Removed outliers: 2\nFri Feb  2 19:46:05 2024  -Removed 4 variants with bad positions.\nFri Feb  2 19:46:05 2024 Finished fixing basepair positions (POS).\nFri Feb  2 19:46:05 2024 Start to fix alleles (EA and NEA)...v3.4.38\nFri Feb  2 19:46:05 2024  -Current Dataframe shape : 54 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:05 2024  -Converted all bases to string datatype and UPPERCASE.\nFri Feb  2 19:46:05 2024  -Variants with bad EA  : 1\nFri Feb  2 19:46:05 2024  -Variants with bad NEA : 5\nFri Feb  2 19:46:05 2024  -Variants with NA for EA or NEA: 1\nFri Feb  2 19:46:05 2024  -Variants with same EA and NEA: 1\nFri Feb  2 19:46:05 2024  -A look at the non-ATCG EA: {'&lt;CN0&gt;'} ...\nFri Feb  2 19:46:05 2024  -A look at the non-ATCG NEA: {nan, '*', '&lt;CN1&gt;', 'N'} ...\nFri Feb  2 19:46:05 2024  -Removed 5 variants with NA alleles or alleles that contain bases other than A/C/T/G.\nFri Feb  2 19:46:05 2024  -Removed 1 variants with same allele for EA and NEA.\nFri Feb  2 19:46:09 2024 Finished fixing alleles (EA and NEA).\nFri Feb  2 19:46:09 2024 Start to perform sanity check for statistics...v3.4.38\nFri Feb  2 19:46:09 2024  -Current Dataframe shape : 48 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:09 2024  -Comparison tolerance for floats: 1e-07\nFri Feb  2 19:46:09 2024  -Checking if 0 &lt;= N &lt;= 2147483647 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 25,26,27 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (N): 12345700000000000,NA,-1 ...\nFri Feb  2 19:46:09 2024  -Removed 3 variants with bad/na N.\nFri Feb  2 19:46:09 2024  -Checking if 0 &lt;= N_CASE &lt;= 2147483647 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 29 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (N_CASE): -1 ...\nFri Feb  2 19:46:09 2024  -Removed 1 variants with bad/na N_CASE.\nFri Feb  2 19:46:09 2024  -Checking if 0 &lt;= N_CONTROL &lt;= 2147483647 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 28 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (N_CONTROL): -1 ...\nFri Feb  2 19:46:09 2024  -Removed 1 variants with bad/na N_CONTROL.\nFri Feb  2 19:46:09 2024  -Checking if -1e-07 &lt; EAF &lt; 1.0000001 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 31,32,33 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (EAF): 1.02,-0.01,NA ...\nFri Feb  2 19:46:09 2024  -Removed 3 variants with bad/na EAF.\nFri Feb  2 19:46:09 2024  -Checking if -1e-07 &lt; CHISQ &lt; inf ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 38,39 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (CHISQ): -0.01,NA ...\nFri Feb  2 19:46:09 2024  -Removed 2 variants with bad/na CHISQ.\nFri Feb  2 19:46:09 2024  -Checking if -9999.0000001 &lt; Z &lt; 9999.0000001 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 40,41 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (Z): NA,999999.0 ...\nFri Feb  2 19:46:09 2024  -Removed 2 variants with bad/na Z.\nFri Feb  2 19:46:09 2024  -Checking if -1e-07 &lt; P &lt; 1.0000001 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 48,49,50 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (P): 1.1,-0.01,NA ...\nFri Feb  2 19:46:09 2024  -Removed 3 variants with bad/na P.\nFri Feb  2 19:46:09 2024  -Checking if -1e-07 &lt; MLOG10P &lt; 9999.0000001 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 51,52,53 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (MLOG10P): 12345.0,-0.1,NA ...\nFri Feb  2 19:46:09 2024  -Removed 3 variants with bad/na MLOG10P.\nFri Feb  2 19:46:09 2024  -Checking if -100.0000001 &lt; BETA &lt; 100.0000001 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 34,35 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (BETA): 99999.0,NA ...\nFri Feb  2 19:46:09 2024  -Removed 2 variants with bad/na BETA.\nFri Feb  2 19:46:09 2024  -Checking if -1e-07 &lt; SE &lt; inf ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 37 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (SE): NA ...\nFri Feb  2 19:46:09 2024  -Removed 1 variants with bad/na SE.\nFri Feb  2 19:46:09 2024  -Checking if -100.0000001 &lt; OR &lt; 100.0000001 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 42,43 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (OR): 999999.0,NA ...\nFri Feb  2 19:46:09 2024  -Removed 2 variants with bad/na OR.\nFri Feb  2 19:46:09 2024  -Checking if -1e-07 &lt; OR_95L &lt; inf ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 44,45 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (OR_95L): -0.01,NA ...\nFri Feb  2 19:46:09 2024  -Removed 2 variants with bad/na OR_95L.\nFri Feb  2 19:46:09 2024  -Checking if -1e-07 &lt; OR_95U &lt; inf ...\nFri Feb  2 19:46:09 2024   -Examples of invalid variants(SNPID): 46,47 ...\nFri Feb  2 19:46:09 2024   -Examples of invalid values (OR_95U): -0.01,NA ...\nFri Feb  2 19:46:09 2024  -Removed 2 variants with bad/na OR_95U.\nFri Feb  2 19:46:09 2024  -Checking STATUS and converting STATUS to categories....\nFri Feb  2 19:46:09 2024  -Removed 27 variants with bad statistics in total.\nFri Feb  2 19:46:09 2024  -Data types for each column:\nFri Feb  2 19:46:09 2024  -Column  : SNPID  CHR   POS   EA       NEA      EAF     BETA    SE      Z       CHISQ   P       MLOG10P OR      OR_95L  OR_95U  N     N_CASE N_CONTROL DIRECTION STATUS   NOTE  \nFri Feb  2 19:46:09 2024  -DType   : string Int64 Int64 category category float32 float64 float64 float64 float64 float64 float64 float64 float64 float64 Int64 Int64  Int64     object    category object\nFri Feb  2 19:46:09 2024  -Verified: T      T     T     T        T        T       T       T       T       T       T       T       T       T       T       T     T      T         T         T        NA    \nFri Feb  2 19:46:09 2024 Finished sanity check for statistics.\nFri Feb  2 19:46:09 2024 Start to check data consistency across columns...v3.4.38\nFri Feb  2 19:46:09 2024  -Current Dataframe shape : 21 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:09 2024  -Tolerance: 0.001 (Relative) and 0.001 (Absolute)\nFri Feb  2 19:46:09 2024  -Checking if BETA/SE-derived-MLOG10P is consistent with MLOG10P...\nFri Feb  2 19:46:09 2024   -Variants with inconsistent values were not detected.\nFri Feb  2 19:46:09 2024  -Checking if BETA/SE-derived-P is consistent with P...\nFri Feb  2 19:46:09 2024   -Variants with inconsistent values were not detected.\nFri Feb  2 19:46:09 2024  -Checking if MLOG10P-derived-P is consistent with P...\nFri Feb  2 19:46:09 2024   -Variants with inconsistent values were not detected.\nFri Feb  2 19:46:09 2024  -Checking if N is consistent with N_CASE + N_CONTROL ...\nFri Feb  2 19:46:09 2024   -Not consistent: 1 variant(s)\nFri Feb  2 19:46:09 2024   -Variant SNPID with max difference: 30 with 10000\nFri Feb  2 19:46:09 2024  -Note: if the max difference is greater than expected, please check your original sumstats.\nFri Feb  2 19:46:09 2024 Finished checking data consistency across columns.\nFri Feb  2 19:46:09 2024 Start to normalize indels...v3.4.38\nFri Feb  2 19:46:09 2024  -Current Dataframe shape : 21 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:10 2024  -Not normalized allele IDs:22 ... \nFri Feb  2 19:46:10 2024  -Not normalized allele:['AT' 'GT']... \nFri Feb  2 19:46:10 2024  -Modified 1 variants according to parsimony and left alignment principal.\nFri Feb  2 19:46:10 2024 Finished normalizing indels.\nFri Feb  2 19:46:10 2024 Start to remove duplicated/multiallelic variants...v3.4.38\nFri Feb  2 19:46:10 2024  -Current Dataframe shape : 21 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:10 2024  -Removing mode:dm\nFri Feb  2 19:46:10 2024 Start to sort the sumstats using P...\nFri Feb  2 19:46:10 2024 Start to remove duplicated variants based on snpid...v3.4.38\nFri Feb  2 19:46:10 2024  -Current Dataframe shape : 21 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:10 2024  -Which variant to keep:  first\nFri Feb  2 19:46:10 2024  -Removed  2  based on SNPID...\nFri Feb  2 19:46:10 2024 Start to remove duplicated variants based on CHR,POS,EA and NEA...\nFri Feb  2 19:46:10 2024  -Current Dataframe shape : 19 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:10 2024  -Which variant to keep:  first\nFri Feb  2 19:46:10 2024  -Removed  1  based on CHR,POS,EA and NEA...\nFri Feb  2 19:46:10 2024 Start to remove multiallelic variants based on chr:pos...\nFri Feb  2 19:46:10 2024  -Current Dataframe shape : 18 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:10 2024  -Which variant to keep:  first\nFri Feb  2 19:46:10 2024  -Removed  1  multiallelic variants...\nFri Feb  2 19:46:10 2024  -Removed  4  variants in total.\nFri Feb  2 19:46:10 2024  -Sort the coordinates based on CHR and POS...\nFri Feb  2 19:46:10 2024 Finished removing duplicated/multiallelic variants.\nFri Feb  2 19:46:10 2024 Start to sort the genome coordinates...v3.4.38\nFri Feb  2 19:46:10 2024  -Current Dataframe shape : 17 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:10 2024 Finished sorting coordinates.\nFri Feb  2 19:46:10 2024 Start to reorder the columns...v3.4.38\nFri Feb  2 19:46:10 2024  -Current Dataframe shape : 17 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:10 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,Z,CHISQ,P,MLOG10P,OR,OR_95L,OR_95U,N,N_CASE,N_CONTROL,DIRECTION,STATUS,NOTE\nFri Feb  2 19:46:10 2024 Finished reordering the columns.\n</pre> In\u00a0[5]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[5]: SNPID CHR POS EA NEA EAF BETA SE Z CHISQ ... MLOG10P OR OR_95L OR_95U N N_CASE N_CONTROL DIRECTION STATUS NOTE 0 1:1_G_A 1 1 A G 0.004 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960099 Duplicated 1 1:2 1 2 T TAA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Multiallelic 2 1:3_T_GA 1 3 T GA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960399 Multiallelic 3 3 1 6 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 4 4 1 7 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 5 5 1 8 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 6 13 1 13 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 POS float 7 16 1 16 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Lowercase alleles 8 22 1 22 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Not normalizated allelels 9 23 1 23 AT A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Both Uppercase and lowercases 10 24 1 24 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 N float 11 30 1 30 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 130000 40000 --++ 9980099 N!=N_CONTROL +N_CASE 12 36 1 36 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 SE out of range 13 54 1 54 AG A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Clean sumstats 14 55 1 55 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Clean sumstats 15 10 1 123456789 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 POS with separator 16 1 23 4 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Sex chromosomes <p>17 rows \u00d7 21 columns</p> In\u00a0[6]: Copied! <pre>#reload\nmysumstats = gl.Sumstats(\"/home/yunye/work/gwaslab/examples/toy_data/dirty_sumstats.tsv\",fmt=\"gwaslab\",other=[\"NOTE\"], verbose=False)\n</pre> #reload mysumstats = gl.Sumstats(\"/home/yunye/work/gwaslab/examples/toy_data/dirty_sumstats.tsv\",fmt=\"gwaslab\",other=[\"NOTE\"], verbose=False) In\u00a0[7]: Copied! <pre>mysumstats.fix_id(fixsep=True)\n</pre> mysumstats.fix_id(fixsep=True) <pre>Fri Feb  2 19:46:11 2024 Start to check SNPID/rsID...v3.4.38\nFri Feb  2 19:46:11 2024  -Current Dataframe shape : 63 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:11 2024  -Checking SNPID data type...\nFri Feb  2 19:46:11 2024  -Converting SNPID to pd.string data type...\nFri Feb  2 19:46:11 2024  -Checking if SNPID is CHR:POS:NEA:EA...(separator: - ,: , _)\nFri Feb  2 19:46:12 2024  -Replacing [_-] in SNPID with \":\" ...\nFri Feb  2 19:46:12 2024 Finished checking SNPID/rsID.\n</pre> In\u00a0[8]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[8]: SNPID CHR POS EA NEA EAF BETA SE Z CHISQ ... MLOG10P OR OR_95L OR_95U N N_CASE N_CONTROL DIRECTION STATUS NOTE 0 1:1:G:A 1 1 A G 0.004 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9969999 Duplicated 1 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9969999 Duplicated 2 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9969999 Duplicated 3 1:2 1 2 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9989999 Multiallelic 4 1:2 1 2 T TAA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9989999 Multiallelic ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 58 51 1 51 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 12345.000000 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9989999 MLOG10P out of range 59 52 1 52 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... -0.100000 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9989999 MLOG10P out of range 60 53 1 53 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... NaN 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9989999 MLOG10P missing 61 54 1 54 AG A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9989999 Clean sumstats 62 55 1 55 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000.0 120000 40000 --++ 9989999 Clean sumstats <p>63 rows \u00d7 21 columns</p> In\u00a0[9]: Copied! <pre>mysumstats.fix_chr(remove=True)\n</pre> mysumstats.fix_chr(remove=True) <pre>Fri Feb  2 19:46:12 2024 Start to fix chromosome notation (CHR)...v3.4.38\nFri Feb  2 19:46:12 2024  -Current Dataframe shape : 63 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:12 2024  -Checking CHR data type...\nFri Feb  2 19:46:12 2024  -Variants with standardized chromosome notation: 56\nFri Feb  2 19:46:12 2024  -Variants with fixable chromosome notations: 4\nFri Feb  2 19:46:12 2024  -Variants with NA chromosome notations: 1\nFri Feb  2 19:46:12 2024  -Variants with invalid chromosome notations: 2\nFri Feb  2 19:46:12 2024  -A look at invalid chromosome notations: {'1.0001', '-1'}\nFri Feb  2 19:46:12 2024  -Identifying non-autosomal chromosomes : X, Y, and MT ...\nFri Feb  2 19:46:12 2024  -Identified  1  variants on sex chromosomes...\nFri Feb  2 19:46:12 2024  -Standardizing sex chromosome notations: X to 23...\nFri Feb  2 19:46:13 2024  -Valid CHR list: 1 - 25\nFri Feb  2 19:46:13 2024  -Removed 5 variants with chromosome notations not in CHR list.\nFri Feb  2 19:46:13 2024  -A look at chromosome notations not in CHR list: {'0', '300', &lt;NA&gt;}\nFri Feb  2 19:46:13 2024 Finished fixing chromosome notation (CHR).\n</pre> In\u00a0[10]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[10]: SNPID CHR POS EA NEA EAF BETA SE Z CHISQ ... MLOG10P OR OR_95L OR_95U N N_CASE N_CONTROL DIRECTION STATUS NOTE 0 1:1:G:A 1 1 A G 0.004 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9965999 Duplicated 1 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9965999 Duplicated 2 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9965999 Duplicated 3 1:2 1 2 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Multiallelic 4 1:2 1 2 T TAA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Multiallelic 5 1:3:T:A 1 3 A T 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9965999 Multiallelic 6 1:3:T:GA 1 3 T GA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9965999 Multiallelic 7 1 23 4 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Sex chromosomes 9 3 1 6 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 CHR with prefix 10 4 1 7 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 CHR with prefix 11 5 1 8 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 CHR with prefix 16 10 1 123,456,789 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 POS with separator 17 11 1 -1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 POS out of normal range 18 12 1 1.23214E+13 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 POS out of normal range 19 13 1 13.00000001 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 POS float 20 14 1 NaN A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 POS missing 21 13 1 abc A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 POS string 22 15 1 15 A A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Same alleles 23 16 1 16 a g 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Lowercase alleles 24 17 1 17 A &lt;CN1&gt; 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Unrecognized alleles 25 18 1 18 &lt;CN0&gt; &lt;CN1&gt; 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Unrecognized alleles 26 19 1 19 A * 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Unrecognized alleles 27 20 1 20 A N 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Unrecognized alleles 28 21 1 21 A NaN 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Allele missing 29 22 1 22 AT GT 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Not normalizated allelels 30 23 1 23 At A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Both Uppercase and lowercases 31 24 1 24 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600001e+05 120000 40000 --++ 9985999 N float 32 25 1 25 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.234570e+16 120000 40000 --++ 9985999 N out of range 33 26 1 26 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 NaN 120000 40000 --++ 9985999 N missing 34 27 1 27 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 -1.000000e+00 120000 40000 --++ 9985999 N out of range 35 28 1 28 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 -1 --++ 9985999 N_CASE out of range 36 29 1 29 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 -1 40000 --++ 9985999 N_CONTROL out of range 37 30 1 30 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 130000 40000 --++ 9985999 N!=N_CONTROL +N_CASE 38 31 1 31 A G 1.020 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 EAF out of range 39 32 1 32 A G -0.010 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 EAF out of range 40 33 1 33 A G NaN 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 EAF missing 41 34 1 34 A G 0.996 99999.0000 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 BETA out of range 42 35 1 35 A G 0.996 NaN 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 BETA missing 43 36 1 36 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 SE out of range 44 37 1 37 A G 0.996 0.0603 NaN 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 SE missing 45 38 1 38 A G 0.996 0.0603 0.0103 5.854369 -0.010000 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 CHISQ out of range 46 39 1 39 A G 0.996 0.0603 0.0103 5.854369 NaN ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 CHISQ missing 47 40 1 40 A G 0.996 0.0603 0.0103 NaN 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Z missing 48 41 1 41 A G 0.996 0.0603 0.0103 999999.000000 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Z out of range 49 42 1 42 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 999999.000000 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 OR out of range 50 43 1 43 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 NaN 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 OR missing 51 44 1 44 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 -0.010000 1.083816 1.600000e+05 120000 40000 --++ 9985999 OR_95L out of range 52 45 1 45 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 NaN 1.083816 1.600000e+05 120000 40000 --++ 9985999 OR_95L missing 53 46 1 46 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 -0.010000 1.600000e+05 120000 40000 --++ 9985999 OR_95U out of range 54 47 1 47 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 NaN 1.600000e+05 120000 40000 --++ 9985999 OR_95U missing 55 48 1 48 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... -0.041393 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 P out of range 56 49 1 49 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 P out of range 57 50 1 50 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 P missing 58 51 1 51 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 12345.000000 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 MLOG10P out of range 59 52 1 52 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... -0.100000 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 MLOG10P out of range 60 53 1 53 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... NaN 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 MLOG10P missing 61 54 1 54 AG A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Clean sumstats 62 55 1 55 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9985999 Clean sumstats <p>58 rows \u00d7 21 columns</p> In\u00a0[11]: Copied! <pre>mysumstats.fix_pos(remove=True)\n</pre> mysumstats.fix_pos(remove=True) <pre>Fri Feb  2 19:46:13 2024 Start to fix basepair positions (POS)...v3.4.38\nFri Feb  2 19:46:13 2024  -Current Dataframe shape : 58 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:13 2024  -Removing thousands separator \",\" or underbar \"_\" ...\nFri Feb  2 19:46:13 2024  -Converting to Int64 data type ...\nFri Feb  2 19:46:13 2024  -Force converting to Int64 data type ...\nFri Feb  2 19:46:15 2024  -Position bound:(0 , 250,000,000)\nFri Feb  2 19:46:15 2024  -Removed outliers: 2\nFri Feb  2 19:46:15 2024  -Removed 4 variants with bad positions.\nFri Feb  2 19:46:15 2024 Finished fixing basepair positions (POS).\n</pre> In\u00a0[12]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[12]: SNPID CHR POS EA NEA EAF BETA SE Z CHISQ ... MLOG10P OR OR_95L OR_95U N N_CASE N_CONTROL DIRECTION STATUS NOTE 0 1:1:G:A 1 1 A G 0.004 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9960999 Duplicated 1 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9960999 Duplicated 2 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9960999 Duplicated 3 1:2 1 2 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Multiallelic 4 1:2 1 2 T TAA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Multiallelic 5 1:3:T:A 1 3 A T 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9960999 Multiallelic 6 1:3:T:GA 1 3 T GA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9960999 Multiallelic 7 1 23 4 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Sex chromosomes 9 3 1 6 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 CHR with prefix 10 4 1 7 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 CHR with prefix 11 5 1 8 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 CHR with prefix 16 10 1 123456789 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 POS with separator 19 13 1 13 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 POS float 22 15 1 15 A A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Same alleles 23 16 1 16 a g 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Lowercase alleles 24 17 1 17 A &lt;CN1&gt; 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Unrecognized alleles 25 18 1 18 &lt;CN0&gt; &lt;CN1&gt; 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Unrecognized alleles 26 19 1 19 A * 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Unrecognized alleles 27 20 1 20 A N 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Unrecognized alleles 28 21 1 21 A NaN 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Allele missing 29 22 1 22 AT GT 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Not normalizated allelels 30 23 1 23 At A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Both Uppercase and lowercases 31 24 1 24 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600001e+05 120000 40000 --++ 9980999 N float 32 25 1 25 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.234570e+16 120000 40000 --++ 9980999 N out of range 33 26 1 26 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 NaN 120000 40000 --++ 9980999 N missing 34 27 1 27 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 -1.000000e+00 120000 40000 --++ 9980999 N out of range 35 28 1 28 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 -1 --++ 9980999 N_CASE out of range 36 29 1 29 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 -1 40000 --++ 9980999 N_CONTROL out of range 37 30 1 30 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 130000 40000 --++ 9980999 N!=N_CONTROL +N_CASE 38 31 1 31 A G 1.020 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 EAF out of range 39 32 1 32 A G -0.010 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 EAF out of range 40 33 1 33 A G NaN 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 EAF missing 41 34 1 34 A G 0.996 99999.0000 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 BETA out of range 42 35 1 35 A G 0.996 NaN 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 BETA missing 43 36 1 36 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 SE out of range 44 37 1 37 A G 0.996 0.0603 NaN 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 SE missing 45 38 1 38 A G 0.996 0.0603 0.0103 5.854369 -0.010000 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 CHISQ out of range 46 39 1 39 A G 0.996 0.0603 0.0103 5.854369 NaN ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 CHISQ missing 47 40 1 40 A G 0.996 0.0603 0.0103 NaN 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Z missing 48 41 1 41 A G 0.996 0.0603 0.0103 999999.000000 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Z out of range 49 42 1 42 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 999999.000000 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 OR out of range 50 43 1 43 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 NaN 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 OR missing 51 44 1 44 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 -0.010000 1.083816 1.600000e+05 120000 40000 --++ 9980999 OR_95L out of range 52 45 1 45 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 NaN 1.083816 1.600000e+05 120000 40000 --++ 9980999 OR_95L missing 53 46 1 46 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 -0.010000 1.600000e+05 120000 40000 --++ 9980999 OR_95U out of range 54 47 1 47 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 NaN 1.600000e+05 120000 40000 --++ 9980999 OR_95U missing 55 48 1 48 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... -0.041393 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 P out of range 56 49 1 49 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 P out of range 57 50 1 50 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 P missing 58 51 1 51 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 12345.000000 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 MLOG10P out of range 59 52 1 52 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... -0.100000 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 MLOG10P out of range 60 53 1 53 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... NaN 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 MLOG10P missing 61 54 1 54 AG A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Clean sumstats 62 55 1 55 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980999 Clean sumstats <p>54 rows \u00d7 21 columns</p> In\u00a0[13]: Copied! <pre>mysumstats.fix_allele(remove=True)\n</pre> mysumstats.fix_allele(remove=True) <pre>Fri Feb  2 19:46:15 2024 Start to fix alleles (EA and NEA)...v3.4.38\nFri Feb  2 19:46:15 2024  -Current Dataframe shape : 54 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:15 2024  -Converted all bases to string datatype and UPPERCASE.\nFri Feb  2 19:46:15 2024  -Variants with bad EA  : 1\nFri Feb  2 19:46:15 2024  -Variants with bad NEA : 5\nFri Feb  2 19:46:15 2024  -Variants with NA for EA or NEA: 1\nFri Feb  2 19:46:15 2024  -Variants with same EA and NEA: 1\nFri Feb  2 19:46:15 2024  -A look at the non-ATCG EA: {'&lt;CN0&gt;'} ...\nFri Feb  2 19:46:15 2024  -A look at the non-ATCG NEA: {nan, '*', '&lt;CN1&gt;', 'N'} ...\nFri Feb  2 19:46:15 2024  -Removed 5 variants with NA alleles or alleles that contain bases other than A/C/T/G.\nFri Feb  2 19:46:15 2024  -Removed 1 variants with same allele for EA and NEA.\nFri Feb  2 19:46:18 2024 Finished fixing alleles (EA and NEA).\n</pre> In\u00a0[14]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[14]: SNPID CHR POS EA NEA EAF BETA SE Z CHISQ ... MLOG10P OR OR_95L OR_95U N N_CASE N_CONTROL DIRECTION STATUS NOTE 0 1:1:G:A 1 1 A G 0.004 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9960099 Duplicated 1 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9960099 Duplicated 2 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9960099 Duplicated 3 1:2 1 2 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 Multiallelic 4 1:2 1 2 T TAA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980399 Multiallelic 5 1:3:T:A 1 3 A T 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9960099 Multiallelic 6 1:3:T:GA 1 3 T GA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9960399 Multiallelic 7 1 23 4 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 Sex chromosomes 9 3 1 6 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 CHR with prefix 10 4 1 7 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 CHR with prefix 11 5 1 8 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 CHR with prefix 16 10 1 123456789 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 POS with separator 19 13 1 13 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 POS float 23 16 1 16 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 Lowercase alleles 29 22 1 22 AT GT 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980599 Not normalizated allelels 30 23 1 23 AT A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980399 Both Uppercase and lowercases 31 24 1 24 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600001e+05 120000 40000 --++ 9980099 N float 32 25 1 25 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.234570e+16 120000 40000 --++ 9980099 N out of range 33 26 1 26 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 NaN 120000 40000 --++ 9980099 N missing 34 27 1 27 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 -1.000000e+00 120000 40000 --++ 9980099 N out of range 35 28 1 28 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 -1 --++ 9980099 N_CASE out of range 36 29 1 29 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 -1 40000 --++ 9980099 N_CONTROL out of range 37 30 1 30 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 130000 40000 --++ 9980099 N!=N_CONTROL +N_CASE 38 31 1 31 A G 1.020 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 EAF out of range 39 32 1 32 A G -0.010 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 EAF out of range 40 33 1 33 A G NaN 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 EAF missing 41 34 1 34 A G 0.996 99999.0000 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 BETA out of range 42 35 1 35 A G 0.996 NaN 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 BETA missing 43 36 1 36 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 SE out of range 44 37 1 37 A G 0.996 0.0603 NaN 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 SE missing 45 38 1 38 A G 0.996 0.0603 0.0103 5.854369 -0.010000 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 CHISQ out of range 46 39 1 39 A G 0.996 0.0603 0.0103 5.854369 NaN ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 CHISQ missing 47 40 1 40 A G 0.996 0.0603 0.0103 NaN 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 Z missing 48 41 1 41 A G 0.996 0.0603 0.0103 999999.000000 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 Z out of range 49 42 1 42 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 999999.000000 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 OR out of range 50 43 1 43 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 NaN 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 OR missing 51 44 1 44 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 -0.010000 1.083816 1.600000e+05 120000 40000 --++ 9980099 OR_95L out of range 52 45 1 45 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 NaN 1.083816 1.600000e+05 120000 40000 --++ 9980099 OR_95L missing 53 46 1 46 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 -0.010000 1.600000e+05 120000 40000 --++ 9980099 OR_95U out of range 54 47 1 47 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 NaN 1.600000e+05 120000 40000 --++ 9980099 OR_95U missing 55 48 1 48 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... -0.041393 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 P out of range 56 49 1 49 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 P out of range 57 50 1 50 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 P missing 58 51 1 51 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 12345.000000 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 MLOG10P out of range 59 52 1 52 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... -0.100000 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 MLOG10P out of range 60 53 1 53 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... NaN 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 MLOG10P missing 61 54 1 54 AG A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980399 Clean sumstats 62 55 1 55 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 1.600000e+05 120000 40000 --++ 9980099 Clean sumstats <p>48 rows \u00d7 21 columns</p> In\u00a0[15]: Copied! <pre>mysumstats.check_sanity()\n</pre> mysumstats.check_sanity() <pre>Fri Feb  2 19:46:18 2024 Start to perform sanity check for statistics...v3.4.38\nFri Feb  2 19:46:18 2024  -Current Dataframe shape : 48 x 21 ; Memory usage: 19.95 MB\nFri Feb  2 19:46:18 2024  -Comparison tolerance for floats: 1e-07\nFri Feb  2 19:46:18 2024  -Checking if 0 &lt;= N &lt;= 2147483647 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 25,26,27 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (N): 12345700000000000,NA,-1 ...\nFri Feb  2 19:46:18 2024  -Removed 3 variants with bad/na N.\nFri Feb  2 19:46:18 2024  -Checking if 0 &lt;= N_CASE &lt;= 2147483647 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 29 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (N_CASE): -1 ...\nFri Feb  2 19:46:18 2024  -Removed 1 variants with bad/na N_CASE.\nFri Feb  2 19:46:18 2024  -Checking if 0 &lt;= N_CONTROL &lt;= 2147483647 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 28 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (N_CONTROL): -1 ...\nFri Feb  2 19:46:18 2024  -Removed 1 variants with bad/na N_CONTROL.\nFri Feb  2 19:46:18 2024  -Checking if -1e-07 &lt; EAF &lt; 1.0000001 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 31,32,33 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (EAF): 1.02,-0.01,NA ...\nFri Feb  2 19:46:18 2024  -Removed 3 variants with bad/na EAF.\nFri Feb  2 19:46:18 2024  -Checking if -1e-07 &lt; CHISQ &lt; inf ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 38,39 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (CHISQ): -0.01,NA ...\nFri Feb  2 19:46:18 2024  -Removed 2 variants with bad/na CHISQ.\nFri Feb  2 19:46:18 2024  -Checking if -9999.0000001 &lt; Z &lt; 9999.0000001 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 40,41 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (Z): NA,999999.0 ...\nFri Feb  2 19:46:18 2024  -Removed 2 variants with bad/na Z.\nFri Feb  2 19:46:18 2024  -Checking if -1e-07 &lt; P &lt; 1.0000001 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 48,49,50 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (P): 1.1,-0.01,NA ...\nFri Feb  2 19:46:18 2024  -Removed 3 variants with bad/na P.\nFri Feb  2 19:46:18 2024  -Checking if -1e-07 &lt; MLOG10P &lt; 9999.0000001 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 51,52,53 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (MLOG10P): 12345.0,-0.1,NA ...\nFri Feb  2 19:46:18 2024  -Removed 3 variants with bad/na MLOG10P.\nFri Feb  2 19:46:18 2024  -Checking if -100.0000001 &lt; BETA &lt; 100.0000001 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 34,35 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (BETA): 99999.0,NA ...\nFri Feb  2 19:46:18 2024  -Removed 2 variants with bad/na BETA.\nFri Feb  2 19:46:18 2024  -Checking if -1e-07 &lt; SE &lt; inf ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 37 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (SE): NA ...\nFri Feb  2 19:46:18 2024  -Removed 1 variants with bad/na SE.\nFri Feb  2 19:46:18 2024  -Checking if -100.0000001 &lt; OR &lt; 100.0000001 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 42,43 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (OR): 999999.0,NA ...\nFri Feb  2 19:46:18 2024  -Removed 2 variants with bad/na OR.\nFri Feb  2 19:46:18 2024  -Checking if -1e-07 &lt; OR_95L &lt; inf ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 44,45 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (OR_95L): -0.01,NA ...\nFri Feb  2 19:46:18 2024  -Removed 2 variants with bad/na OR_95L.\nFri Feb  2 19:46:18 2024  -Checking if -1e-07 &lt; OR_95U &lt; inf ...\nFri Feb  2 19:46:18 2024   -Examples of invalid variants(SNPID): 46,47 ...\nFri Feb  2 19:46:18 2024   -Examples of invalid values (OR_95U): -0.01,NA ...\nFri Feb  2 19:46:18 2024  -Removed 2 variants with bad/na OR_95U.\nFri Feb  2 19:46:18 2024  -Checking STATUS and converting STATUS to categories....\nFri Feb  2 19:46:18 2024  -Removed 27 variants with bad statistics in total.\nFri Feb  2 19:46:18 2024  -Data types for each column:\nFri Feb  2 19:46:18 2024  -Column  : SNPID  CHR   POS   EA       NEA      EAF     BETA    SE      Z       CHISQ   P       MLOG10P OR      OR_95L  OR_95U  N     N_CASE N_CONTROL DIRECTION STATUS   NOTE  \nFri Feb  2 19:46:18 2024  -DType   : string Int64 Int64 category category float32 float64 float64 float64 float64 float64 float64 float64 float64 float64 Int64 Int64  Int64     object    category object\nFri Feb  2 19:46:18 2024  -Verified: T      T     T     T        T        T       T       T       T       T       T       T       T       T       T       T     T      T         T         T        NA    \nFri Feb  2 19:46:18 2024 Finished sanity check for statistics.\n</pre> In\u00a0[16]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[16]: SNPID CHR POS EA NEA EAF BETA SE Z CHISQ ... MLOG10P OR OR_95L OR_95U N N_CASE N_CONTROL DIRECTION STATUS NOTE 0 1:1:G:A 1 1 A G 0.004 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960099 Duplicated 1 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960099 Duplicated 2 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960099 Duplicated 3 1:2 1 2 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Multiallelic 4 1:2 1 2 T TAA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Multiallelic 5 1:3:T:A 1 3 A T 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960099 Multiallelic 6 1:3:T:GA 1 3 T GA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960399 Multiallelic 7 1 23 4 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Sex chromosomes 9 3 1 6 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 10 4 1 7 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 11 5 1 8 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 16 10 1 123456789 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 POS with separator 19 13 1 13 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 POS float 23 16 1 16 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Lowercase alleles 29 22 1 22 AT GT 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980599 Not normalizated allelels 30 23 1 23 AT A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Both Uppercase and lowercases 31 24 1 24 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 N float 37 30 1 30 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 130000 40000 --++ 9980099 N!=N_CONTROL +N_CASE 43 36 1 36 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 SE out of range 61 54 1 54 AG A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Clean sumstats 62 55 1 55 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Clean sumstats <p>21 rows \u00d7 21 columns</p> In\u00a0[17]: Copied! <pre>mysumstats.check_data_consistency()\n</pre> mysumstats.check_data_consistency() <pre>Fri Feb  2 19:46:19 2024 Start to check data consistency across columns...v3.4.38\nFri Feb  2 19:46:19 2024  -Current Dataframe shape : 21 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:19 2024  -Tolerance: 0.001 (Relative) and 0.001 (Absolute)\nFri Feb  2 19:46:19 2024  -Checking if BETA/SE-derived-MLOG10P is consistent with MLOG10P...\nFri Feb  2 19:46:19 2024   -Variants with inconsistent values were not detected.\nFri Feb  2 19:46:19 2024  -Checking if BETA/SE-derived-P is consistent with P...\nFri Feb  2 19:46:19 2024   -Variants with inconsistent values were not detected.\nFri Feb  2 19:46:19 2024  -Checking if MLOG10P-derived-P is consistent with P...\nFri Feb  2 19:46:19 2024   -Variants with inconsistent values were not detected.\nFri Feb  2 19:46:19 2024  -Checking if N is consistent with N_CASE + N_CONTROL ...\nFri Feb  2 19:46:19 2024   -Not consistent: 1 variant(s)\nFri Feb  2 19:46:19 2024   -Variant SNPID with max difference: 30 with 10000\nFri Feb  2 19:46:19 2024  -Note: if the max difference is greater than expected, please check your original sumstats.\nFri Feb  2 19:46:19 2024 Finished checking data consistency across columns.\n</pre> In\u00a0[18]: Copied! <pre>mysumstats.normalize_allele()\n</pre> mysumstats.normalize_allele() <pre>Fri Feb  2 19:46:19 2024 Start to normalize indels...v3.4.38\nFri Feb  2 19:46:19 2024  -Current Dataframe shape : 21 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:19 2024  -Not normalized allele IDs:22 ... \nFri Feb  2 19:46:19 2024  -Not normalized allele:['AT' 'GT']... \nFri Feb  2 19:46:19 2024  -Modified 1 variants according to parsimony and left alignment principal.\nFri Feb  2 19:46:19 2024 Finished normalizing indels.\n</pre> In\u00a0[19]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[19]: SNPID CHR POS EA NEA EAF BETA SE Z CHISQ ... MLOG10P OR OR_95L OR_95U N N_CASE N_CONTROL DIRECTION STATUS NOTE 0 1:1:G:A 1 1 A G 0.004 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960099 Duplicated 1 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960099 Duplicated 2 1:1:A:G 1 1 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960099 Duplicated 3 1:2 1 2 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Multiallelic 4 1:2 1 2 T TAA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Multiallelic 5 1:3:T:A 1 3 A T 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960099 Multiallelic 6 1:3:T:GA 1 3 T GA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960399 Multiallelic 7 1 23 4 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Sex chromosomes 9 3 1 6 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 10 4 1 7 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 11 5 1 8 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 16 10 1 123456789 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 POS with separator 19 13 1 13 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 POS float 23 16 1 16 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Lowercase alleles 29 22 1 22 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Not normalizated allelels 30 23 1 23 AT A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Both Uppercase and lowercases 31 24 1 24 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 N float 37 30 1 30 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 130000 40000 --++ 9980099 N!=N_CONTROL +N_CASE 43 36 1 36 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 SE out of range 61 54 1 54 AG A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Clean sumstats 62 55 1 55 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Clean sumstats <p>21 rows \u00d7 21 columns</p> In\u00a0[20]: Copied! <pre>mysumstats.remove_dup(mode=\"md\")\n</pre> mysumstats.remove_dup(mode=\"md\") <pre>Fri Feb  2 19:46:19 2024 Start to remove duplicated/multiallelic variants...v3.4.38\nFri Feb  2 19:46:19 2024  -Current Dataframe shape : 21 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:19 2024  -Removing mode:md\nFri Feb  2 19:46:19 2024 Start to sort the sumstats using P...\nFri Feb  2 19:46:19 2024 Start to remove duplicated variants based on snpid...v3.4.38\nFri Feb  2 19:46:19 2024  -Current Dataframe shape : 21 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:19 2024  -Which variant to keep:  first\nFri Feb  2 19:46:19 2024  -Removed  2  based on SNPID...\nFri Feb  2 19:46:19 2024 Start to remove duplicated variants based on CHR,POS,EA and NEA...\nFri Feb  2 19:46:19 2024  -Current Dataframe shape : 19 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:19 2024  -Which variant to keep:  first\nFri Feb  2 19:46:19 2024  -Removed  1  based on CHR,POS,EA and NEA...\nFri Feb  2 19:46:19 2024 Start to remove multiallelic variants based on chr:pos...\nFri Feb  2 19:46:19 2024  -Current Dataframe shape : 18 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:19 2024  -Which variant to keep:  first\nFri Feb  2 19:46:19 2024  -Removed  1  multiallelic variants...\nFri Feb  2 19:46:19 2024  -Removed  4  variants in total.\nFri Feb  2 19:46:19 2024  -Sort the coordinates based on CHR and POS...\nFri Feb  2 19:46:19 2024 Finished removing duplicated/multiallelic variants.\n</pre> In\u00a0[21]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[21]: SNPID CHR POS EA NEA EAF BETA SE Z CHISQ ... MLOG10P OR OR_95L OR_95U N N_CASE N_CONTROL DIRECTION STATUS NOTE 0 1:1:G:A 1 1 A G 0.004 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960099 Duplicated 1 1:2 1 2 T TAA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Multiallelic 2 1:3:T:GA 1 3 T GA 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9960399 Multiallelic 3 3 1 6 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 4 4 1 7 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 5 5 1 8 T C 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 CHR with prefix 6 13 1 13 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 POS float 7 16 1 16 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Lowercase alleles 8 22 1 22 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Not normalizated allelels 9 23 1 23 AT A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Both Uppercase and lowercases 10 24 1 24 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 N float 11 30 1 30 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 130000 40000 --++ 9980099 N!=N_CONTROL +N_CASE 12 36 1 36 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 SE out of range 13 54 1 54 AG A 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980399 Clean sumstats 14 55 1 55 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Clean sumstats 15 10 1 123456789 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 POS with separator 16 1 23 4 A G 0.996 0.0603 0.0103 5.854369 34.273636 ... 8.327348 1.062155 1.040927 1.083816 160000 120000 40000 --++ 9980099 Sex chromosomes <p>17 rows \u00d7 21 columns</p> In\u00a0[22]: Copied! <pre>mysumstats.sort_coordinate()\n</pre> mysumstats.sort_coordinate() <pre>Fri Feb  2 19:46:19 2024 Start to sort the genome coordinates...v3.4.38\nFri Feb  2 19:46:19 2024  -Current Dataframe shape : 17 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:19 2024 Finished sorting coordinates.\n</pre> In\u00a0[23]: Copied! <pre>mysumstats.sort_column()\n</pre> mysumstats.sort_column() <pre>Fri Feb  2 19:46:20 2024 Start to reorder the columns...v3.4.38\nFri Feb  2 19:46:20 2024  -Current Dataframe shape : 17 x 21 ; Memory usage: 19.94 MB\nFri Feb  2 19:46:20 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,Z,CHISQ,P,MLOG10P,OR,OR_95L,OR_95U,N,N_CASE,N_CONTROL,DIRECTION,STATUS,NOTE\nFri Feb  2 19:46:20 2024 Finished reordering the columns.\n</pre>"},{"location":"standardization_workflow/#standardization","title":"Standardization\u00b6","text":""},{"location":"standardization_workflow/#load-sample-data","title":"Load sample data\u00b6","text":""},{"location":"standardization_workflow/#all-in-one-function","title":"All in one function\u00b6","text":""},{"location":"standardization_workflow/#separate-functions","title":"Separate functions\u00b6","text":""},{"location":"standardization_workflow/#fix-id","title":"fix id\u00b6","text":""},{"location":"standardization_workflow/#fix-chromosome","title":"fix chromosome\u00b6","text":""},{"location":"standardization_workflow/#fix-position","title":"fix position\u00b6","text":""},{"location":"standardization_workflow/#fix-allele","title":"fix allele\u00b6","text":""},{"location":"standardization_workflow/#sanity-check-for-statistics","title":"sanity check for statistics\u00b6","text":""},{"location":"standardization_workflow/#check-data-consistency","title":"check data consistency\u00b6","text":""},{"location":"standardization_workflow/#normalize-variants","title":"normalize variants\u00b6","text":""},{"location":"standardization_workflow/#remove-duplicated-multiallelic-variants","title":"remove duplicated / multiallelic variants\u00b6","text":""},{"location":"standardization_workflow/#sort-genome-coordinate","title":"sort genome coordinate\u00b6","text":""},{"location":"standardization_workflow/#sort-column","title":"sort column\u00b6","text":""},{"location":"temp/","title":"Temp","text":"<pre><code>- \"Examples(outdated)\":\n   - \"Standardization and QC example\":\n      - \"Workflow\": standardization_workflow.ipynb\n      - \"QC and filtering\" : quality_control_and_filtering.ipynb\n   - \"Harmonization example\":\n      - \"Workflow\" : harmonization_workflow.ipynb\n      - \"Liftover\" : harmonization_liftover.ipynb\n   - \"Formatting and saving example\" : format_load_save.ipynb\n   - \"Utility example\":\n      - \"Data conversion\" : utility_data_conversion.ipynb\n      - \"Checking novel\" : utility_get_novel.ipynb\n   - \"Visualization example\" :\n      - \"Manhatann and Q-Q plot\" : visualization_mqq.ipynb\n      - \"Miami plot\": visualization_miami.ipynb\n      - \"Regional plot\": visualization_regional.ipynb\n      - \"Brisbane plot\": visualization_brisbane.ipynb\n   - \"Reference management\" :\n      - \"Download\" : Download_reference.ipynb\n</code></pre>"},{"location":"tutorial_3.4/","title":"Tutorial for gwaslab","text":"<ul> <li>In this tutorial, we will briefly describe the core functions in gwaslab for sumstats QC, standardization and harmonization. </li> <li>We will also show examples of visualization, including Manhattan plots, Q-Q plots and regional plots.</li> <li>This jupyter notebook can be downloaded from https://github.com/Cloufield/gwaslab/blob/main/docs/tutorial_3.4.ipynb</li> <li>Please note that the processed reference datasets are currently hosted on Dropbox. </li> </ul> <ul> <li>Using a jupyter notebook, we first download a sample dataset.</li> <li>The dataset we will use as an example is the sumstats of type 2 diabetes from BBJ (K. Suzuki et al., Nature Genetics. 51, 379\u2013386 (2019).)</li> <li>File size: 261M</li> </ul> In\u00a0[1]: Copied! <pre>!wget -O t2d_bbj.txt.gz http://jenger.riken.jp/14/\n</pre> !wget -O t2d_bbj.txt.gz http://jenger.riken.jp/14/ <pre>--2023-04-21 13:41:25--  http://jenger.riken.jp/14/\nResolving jenger.riken.jp (jenger.riken.jp)... 134.160.84.25, 161.232.72.25, 202.12.30.131, ...\nConnecting to jenger.riken.jp (jenger.riken.jp)|134.160.84.25|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 274187574 (261M) [text/plain]\nSaving to: \u2018t2d_bbj.txt.gz\u2019\n\nt2d_bbj.txt.gz      100%[===================&gt;] 261.49M  25.2MB/s    in 11s     \n\n2023-04-21 13:41:35 (24.7 MB/s) - \u2018t2d_bbj.txt.gz\u2019 saved [274187574/274187574]\n\n</pre> <p>Sometimes the link is not stable. You can also download from alternative source:  <code>!wget -O t2d_bbj.txt.gz https://www.dropbox.com/s/5vp93eq0gtsm92n/t2d_bbj.txt.gz?dl=1</code></p> <p>gwaslab can be installed using pip</p> In\u00a0[1]: Copied! <pre>!pip install gwaslab==3.4.10\n</pre> !pip install gwaslab==3.4.10 <p>If you installed gwaslab from pip, simply run the command to import the package:</p> In\u00a0[2]: Copied! <pre>import gwaslab as gl\n</pre> import gwaslab as gl <p>Or if you want to use the latest version from github (beta version), you can clone the repository and import the package by inserting your package path into the system path like:</p> In\u00a0[1]: Copied! <pre>import sys\nsys.path.insert(0,\"/home/yunye/work/gwaslab/src\")\nimport gwaslab as gl\n</pre> import sys sys.path.insert(0,\"/home/yunye/work/gwaslab/src\") import gwaslab as gl <p>Let's import the raw sumstats into the <code>gwaslab.Sumstats</code> Object by specifying the necessary columns.</p> <p>Note: you can either specify <code>eaf</code> (effect allele frequency) or <code>neaf</code> (non-effect allele frequency), if <code>neaf</code> is specified, it will be converted to <code>eaf</code> when loading the sumstats.</p> In\u00a0[2]: Copied! <pre>mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNP\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             ea=\"ALT\",\n             nea=\"REF\",\n             neaf=\"Frq\",\n             beta=\"BETA\",\n             se=\"SE\",\n             p=\"P\",\n             direction=\"Dir\",\n             n=\"N\",\n             sep=\"\\t\")\n</pre> mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",              snpid=\"SNP\",              chrom=\"CHR\",              pos=\"POS\",              ea=\"ALT\",              nea=\"REF\",              neaf=\"Frq\",              beta=\"BETA\",              se=\"SE\",              p=\"P\",              direction=\"Dir\",              n=\"N\",              sep=\"\\t\") <pre>Thu Apr 27 11:42:12 2023 GWASLab version 3.4.10 https://cloufield.github.io/gwaslab/\nThu Apr 27 11:42:12 2023 (C) 2022-2023, Yunye He, Kamatani Lab, MIT License, gwaslab@gmail.com\nThu Apr 27 11:42:12 2023 Start to initiate from file :t2d_bbj.txt.gz\nThu Apr 27 11:42:25 2023  -Reading columns          : Dir,SE,POS,ALT,N,Frq,P,SNP,BETA,CHR,REF\nThu Apr 27 11:42:25 2023  -Renaming columns to      : DIRECTION,SE,POS,EA,N,EAF,P,SNPID,BETA,CHR,NEA\nThu Apr 27 11:42:25 2023  -Current Dataframe shape : 12557761  x  11\nThu Apr 27 11:42:25 2023  -Initiating a status column: STATUS ...\nThu Apr 27 11:42:27 2023  -NEAF is specified...\nThu Apr 27 11:42:27 2023  -Checking if 0&lt;= NEAF &lt;=1 ...\nThu Apr 27 11:42:28 2023  -Converted NEAF to EAF.\nThu Apr 27 11:42:28 2023  -Removed 0 variants with bad NEAF.\nThu Apr 27 11:42:28 2023 Start to reorder the columns...\nThu Apr 27 11:42:28 2023  -Current Dataframe shape : 12557761  x  12\nThu Apr 27 11:42:28 2023  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,P,N,DIRECTION,STATUS\nThu Apr 27 11:42:28 2023 Finished sorting columns successfully!\nThu Apr 27 11:42:28 2023 Finished loading data successfully!\n</pre> <p>Sumstats are stored in <code>Sumstats.data</code> as a pandas.DataFrame, you can check the data like:</p> In\u00a0[3]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[3]: SNPID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS 0 1:725932_G_A 1 725932 G A 0.9960 -0.0737 0.1394 0.5970 166718 -?+- 9999999 1 1:725933_A_G 1 725933 G A 0.0040 0.0737 0.1394 0.5973 166718 +?-+ 9999999 2 1:737801_T_C 1 737801 C T 0.0051 0.0490 0.1231 0.6908 166718 +?-+ 9999999 3 1:749963_T_TAA 1 749963 TAA T 0.8374 0.0213 0.0199 0.2846 166718 -?++ 9999999 4 1:751343_T_A 1 751343 T A 0.8593 0.0172 0.0156 0.2705 166718 -?++ 9999999 ... ... ... ... ... ... ... ... ... ... ... ... ... 12557756 X:154874837_A_G X 154874837 G A 0.7478 -0.0064 0.0117 0.5840 191764 -+-+ 9999999 12557757 X:154875192_GTACTC_G X 154875192 GTACTC G 0.2525 0.0071 0.0122 0.5612 191764 +-+- 9999999 12557758 X:154879115_A_G X 154879115 G A 0.7463 -0.0070 0.0122 0.5646 191764 -+-+ 9999999 12557759 X:154880669_T_A X 154880669 T A 0.2558 0.0071 0.0122 0.5618 191764 +-+- 9999999 12557760 X:154880917_C_T X 154880917 C T 0.2558 0.0072 0.0122 0.5570 191764 +-+- 9999999 <p>12557761 rows \u00d7 12 columns</p> <ul> <li>For details on gwaslab Sumstats Object, see: https://cloufield.github.io/gwaslab/SumstatsObject/</li> </ul> <p>The first thing you want to check is probably the Manhattan and Q-Q plots for your sumstats.</p> <p>gwaslab will conduct a minimal QC for sumstats when plotting.</p> In\u00a0[4]: Copied! <pre>mysumstats.plot_mqq()\n</pre> mysumstats.plot_mqq() <pre>Tue Apr 25 14:02:46 2023 Start to plot manhattan/qq plot with the following basic settings:\nTue Apr 25 14:02:46 2023  -Genome-wide significance level is set to 5e-08 ...\nTue Apr 25 14:02:46 2023  -Raw input contains 12557761 variants...\nTue Apr 25 14:02:46 2023  -Plot layout mode is : mqq\nTue Apr 25 14:02:48 2023 Finished loading specified columns from the sumstats.\nTue Apr 25 14:02:48 2023 Start conversion and sanity check:\nTue Apr 25 14:02:48 2023  -Removed 0 variants with nan in CHR or POS column ...\nTue Apr 25 14:02:48 2023  -Removed 0 variants with nan in P column ...\nTue Apr 25 14:02:49 2023  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nTue Apr 25 14:02:49 2023  -sumstats P values are being converted to -log10(P)...\nTue Apr 25 14:02:50 2023  -Sanity check: 0 na/inf/-inf variants will be removed...\nTue Apr 25 14:02:51 2023  -Maximum -log10(P) values is 167.58838029403677 .\nTue Apr 25 14:02:51 2023 Finished data conversion and sanity check.\nTue Apr 25 14:03:07 2023 Start to create manhattan plot with 12557761 variants:\nTue Apr 25 14:03:33 2023  -Found 89 significant variants with a sliding window size of 500 kb...\nTue Apr 25 14:03:33 2023 Finished creating Manhattan plot successfully!\nTue Apr 25 14:03:33 2023  -Skip annotating\nTue Apr 25 14:03:33 2023 Start to create QQ plot with 12557761 variants:\nTue Apr 25 14:03:35 2023  -Calculating lambda GC: 1.2128258399293808\nTue Apr 25 14:03:35 2023 Finished creating QQ plot successfully!\n</pre> Out[4]: <pre>(&lt;Figure size 3000x1000 with 2 Axes&gt;, &lt;gwaslab.Log.Log at 0x7f46449ff6a0&gt;)</pre> <p>Using <code>.plot_mqq()</code>, you can easily plot the Manhattan and QQ plot, but the plots without any manipulations are not really informative in this case, and plotting all points takes a relatively long time. The most significant locus dwarfed other less signicant loci. To adjust the plot, gwaslab provides a wide range of options for customization. For example, we can use <code>skip</code> and <code>cut</code> :</p> <ul> <li>skip : skip variants with MLOG10P &lt; <code>skip</code> for faster plotting speed</li> <li>cut : rescale the MLOG10P values when MLOG10P &gt; <code>cut</code> </li> </ul> In\u00a0[5]: Copied! <pre>mysumstats.plot_mqq(skip=2, cut=20)\n</pre> mysumstats.plot_mqq(skip=2, cut=20) <pre>Tue Apr 25 14:05:16 2023 Start to plot manhattan/qq plot with the following basic settings:\nTue Apr 25 14:05:16 2023  -Genome-wide significance level is set to 5e-08 ...\nTue Apr 25 14:05:16 2023  -Raw input contains 12557761 variants...\nTue Apr 25 14:05:16 2023  -Plot layout mode is : mqq\nTue Apr 25 14:05:18 2023 Finished loading specified columns from the sumstats.\nTue Apr 25 14:05:18 2023 Start conversion and sanity check:\nTue Apr 25 14:05:18 2023  -Removed 0 variants with nan in CHR or POS column ...\nTue Apr 25 14:05:18 2023  -Removed 0 variants with nan in P column ...\nTue Apr 25 14:05:19 2023  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nTue Apr 25 14:05:19 2023  -sumstats P values are being converted to -log10(P)...\nTue Apr 25 14:05:20 2023  -Sanity check: 0 na/inf/-inf variants will be removed...\nTue Apr 25 14:05:21 2023  -Maximum -log10(P) values is 167.58838029403677 .\nTue Apr 25 14:05:21 2023  -Minus log10(P) values above 20 will be shrunk with a shrinkage factor of 10...\nTue Apr 25 14:05:21 2023 Finished data conversion and sanity check.\nTue Apr 25 14:05:21 2023 Start to create manhattan plot with 332882 variants:\nTue Apr 25 14:05:22 2023  -Found 89 significant variants with a sliding window size of 500 kb...\nTue Apr 25 14:05:22 2023 Finished creating Manhattan plot successfully!\nTue Apr 25 14:05:22 2023  -Skip annotating\nTue Apr 25 14:05:22 2023 Start to create QQ plot with 332882 variants:\nTue Apr 25 14:05:22 2023  -Calculating lambda GC: 1.2128258399293808\nTue Apr 25 14:05:22 2023 Finished creating QQ plot successfully!\n</pre> Out[5]: <pre>(&lt;Figure size 3000x1000 with 2 Axes&gt;, &lt;gwaslab.Log.Log at 0x7f46449ff6a0&gt;)</pre> <p>Looks better now. But what if we want to annotate some of the most significant loci (for example, lead variants with MLOG10P&gt;30) and only plot Manhattan plot?</p> In\u00a0[6]: Copied! <pre>mysumstats.plot_mqq(skip=2, cut=20, mode=\"m\", anno=True, sig_level_lead=1e-30)\n</pre> mysumstats.plot_mqq(skip=2, cut=20, mode=\"m\", anno=True, sig_level_lead=1e-30) <pre>Tue Apr 25 14:05:26 2023 Start to plot manhattan/qq plot with the following basic settings:\nTue Apr 25 14:05:26 2023  -Genome-wide significance level is set to 5e-08 ...\nTue Apr 25 14:05:26 2023  -Raw input contains 12557761 variants...\nTue Apr 25 14:05:26 2023  -Plot layout mode is : m\nTue Apr 25 14:05:28 2023 Finished loading specified columns from the sumstats.\nTue Apr 25 14:05:28 2023 Start conversion and sanity check:\nTue Apr 25 14:05:28 2023  -Removed 0 variants with nan in CHR or POS column ...\nTue Apr 25 14:05:28 2023  -Removed 0 variants with nan in P column ...\nTue Apr 25 14:05:29 2023  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nTue Apr 25 14:05:29 2023  -sumstats P values are being converted to -log10(P)...\nTue Apr 25 14:05:30 2023  -Sanity check: 0 na/inf/-inf variants will be removed...\nTue Apr 25 14:05:31 2023  -Maximum -log10(P) values is 167.58838029403677 .\nTue Apr 25 14:05:31 2023  -Minus log10(P) values above 20 will be shrunk with a shrinkage factor of 10...\nTue Apr 25 14:05:31 2023 Finished data conversion and sanity check.\nTue Apr 25 14:05:31 2023 Start to create manhattan plot with 332882 variants:\nTue Apr 25 14:05:32 2023  -Found 9 significant variants with a sliding window size of 500 kb...\nTue Apr 25 14:05:32 2023 Finished creating Manhattan plot successfully!\nTue Apr 25 14:05:32 2023  -Annotating using column CHR:POS...\nTue Apr 25 14:05:32 2023  -Adjusting text positions with repel_force=0.03...\n</pre> Out[6]: <pre>(&lt;Figure size 3000x1000 with 1 Axes&gt;, &lt;gwaslab.Log.Log at 0x7f46449ff6a0&gt;)</pre> <p>gwaslab supports a wide range of customizable options. For details on other options for Manhattan and Q-Q plots, see: https://cloufield.github.io/gwaslab/Visualization/</p> <p>It is needed to check variant ID (SNPID), rsID, chromosome(CHR), basepair position(POS), alleles (EA and NEA) and statistics first before any manipulations or analysis. gwaslab provides a all-in-one function for this, <code>.basic_check()</code>.</p> <p>Note: Sometimes you need do this before plotting if the sumstats are not in a standard format.</p> In\u00a0[7]: Copied! <pre>#check SNPID,rsID,CHR,POS,EA, NEA and statistics\nmysumstats.basic_check()\n</pre> #check SNPID,rsID,CHR,POS,EA, NEA and statistics mysumstats.basic_check() <pre>Tue Apr 25 15:12:32 2023 Start to check IDs...\nTue Apr 25 15:12:32 2023  -Current Dataframe shape : 12557761  x  12\nTue Apr 25 15:12:32 2023  -Checking if SNPID is chr:pos:ref:alt...(separator: - ,: , _)\nTue Apr 25 15:12:41 2023 Finished checking IDs successfully!\nTue Apr 25 15:12:41 2023 Start to fix chromosome notation...\nTue Apr 25 15:12:41 2023  -Current Dataframe shape : 12557761  x  12\nTue Apr 25 15:12:41 2023  -Checking CHR data type...\nTue Apr 25 15:12:45 2023  -Vairants with standardized chromosome notation: 12228970\nTue Apr 25 15:12:47 2023  -Vairants with fixable chromosome notations: 328791\nTue Apr 25 15:12:47 2023  -No unrecognized chromosome notations...\nTue Apr 25 15:12:48 2023  -Identifying non-autosomal chromosomes : X, Y, and MT ...\nTue Apr 25 15:12:49 2023  -Identified  328791  variants on sex chromosomes...\nTue Apr 25 15:12:50 2023  -Standardizing sex chromosome notations: X to 23...\nTue Apr 25 15:13:04 2023 Finished fixing chromosome notation successfully!\nTue Apr 25 15:13:04 2023 Start to fix basepair positions...\nTue Apr 25 15:13:04 2023  -Current Dataframe shape : 12557761  x  12\nTue Apr 25 15:13:04 2023  -Converting to Int64 data type ...\nTue Apr 25 15:13:16 2023  -Position upper_bound is: 250,000,000\nTue Apr 25 15:13:18 2023  -Remove outliers: 0\nTue Apr 25 15:13:20 2023  -Converted all position to datatype Int64.\nTue Apr 25 15:13:20 2023 Finished fixing basepair position successfully!\nTue Apr 25 15:13:20 2023 Start to fix alleles...\nTue Apr 25 15:13:20 2023  -Current Dataframe shape : 12557761  x  12\nTue Apr 25 15:13:20 2023  -Converted all bases to string datatype and UPPERCASE.\nTue Apr 25 15:13:23 2023  -Detected 0 variants with alleles that contain bases other than A/C/T/G .\nTue Apr 25 15:13:42 2023 Finished fixing allele successfully!\nTue Apr 25 15:13:42 2023 Start sanity check for statistics ...\nTue Apr 25 15:13:42 2023  -Current Dataframe shape : 12557761  x  12\nTue Apr 25 15:13:42 2023  -Checking if  0 &lt;=N&lt;= 2147483647  ...\nTue Apr 25 15:13:44 2023  -Removed 0 variants with bad N.\nTue Apr 25 15:13:44 2023  -Checking if  0 &lt;=EAF&lt;= 1  ...\nTue Apr 25 15:13:45 2023  -Removed 0 variants with bad EAF.\nTue Apr 25 15:13:45 2023  -Checking if  0 &lt;=MAC&lt;= inf  ...\nTue Apr 25 15:13:46 2023  -Removed 0 variants with bad MAC.\nTue Apr 25 15:13:46 2023  -Checking if  5e-300 &lt;= P &lt;= 1  ...\nTue Apr 25 15:13:47 2023  -Removed 0 variants with bad P.\nTue Apr 25 15:13:47 2023  -Checking if  -10 &lt;BETA)&lt; 10  ...\nTue Apr 25 15:13:48 2023  -Removed 0 variants with bad BETA.\nTue Apr 25 15:13:48 2023  -Checking if  0 &lt;SE&lt; inf  ...\nTue Apr 25 15:13:49 2023  -Removed 0 variants with bad SE.\nTue Apr 25 15:13:49 2023  -Checking STATUS...\nTue Apr 25 15:13:50 2023  -Coverting STAUTUS to interger.\nTue Apr 25 15:13:50 2023  -Removed 0 variants with bad statistics in total.\nTue Apr 25 15:13:50 2023 Finished sanity check successfully!\nTue Apr 25 15:13:50 2023 Start to normalize variants...\nTue Apr 25 15:13:50 2023  -Current Dataframe shape : 12557761  x  12\nTue Apr 25 15:13:56 2023  -Not normalized allele IDs:X:7151130_TT_TC X:9093382_CTTTT_CTTT X:12292253_ATTT_ATT X:16001576_ATT_ATTT X:33822416_GT_GTT ... \nTue Apr 25 15:13:56 2023  -Not normalized allele:['TT' 'TC']['CTTTT' 'CTTT']['ATTT' 'ATT']['ATTT' 'ATT']['GTT' 'GT']... \nTue Apr 25 15:13:56 2023  -Modified 13 variants according to parsimony and left alignment principal.\nTue Apr 25 15:13:57 2023 Finished normalizing variants successfully!\nTue Apr 25 15:13:57 2023 Start to sort the genome coordinates...\nTue Apr 25 15:13:57 2023  -Current Dataframe shape : 12557761  x  12\nTue Apr 25 15:13:57 2023  -Sorting genome coordinates...\nTue Apr 25 15:14:07 2023 Finished sorting genome coordinates successfully!\nTue Apr 25 15:14:07 2023 Start to reorder the columns...\nTue Apr 25 15:14:07 2023  -Current Dataframe shape : 12557761  x  12\nTue Apr 25 15:14:07 2023  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,P,N,DIRECTION,STATUS\nTue Apr 25 15:14:07 2023 Finished sorting columns successfully!\n</pre> In\u00a0[8]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[8]: SNPID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS 0 1:725932_G_A 1 725932 G A 0.9960 -0.0737 0.1394 0.5970 166718 -?+- 9960099 1 1:725933_A_G 1 725933 G A 0.0040 0.0737 0.1394 0.5973 166718 +?-+ 9960099 2 1:737801_T_C 1 737801 C T 0.0051 0.0490 0.1231 0.6908 166718 +?-+ 9960099 3 1:749963_T_TAA 1 749963 TAA T 0.8374 0.0213 0.0199 0.2846 166718 -?++ 9960399 4 1:751343_T_A 1 751343 T A 0.8593 0.0172 0.0156 0.2705 166718 -?++ 9960099 ... ... ... ... ... ... ... ... ... ... ... ... ... 12557756 X:154874837_A_G 23 154874837 G A 0.7478 -0.0064 0.0117 0.5840 191764 -+-+ 9960099 12557757 X:154875192_GTACTC_G 23 154875192 GTACTC G 0.2525 0.0071 0.0122 0.5612 191764 +-+- 9960399 12557758 X:154879115_A_G 23 154879115 G A 0.7463 -0.0070 0.0122 0.5646 191764 -+-+ 9960099 12557759 X:154880669_T_A 23 154880669 T A 0.2558 0.0071 0.0122 0.5618 191764 +-+- 9960099 12557760 X:154880917_C_T 23 154880917 C T 0.2558 0.0072 0.0122 0.5570 191764 +-+- 9960099 <p>12557761 rows \u00d7 12 columns</p> <p>By checking the log, we can see that the sumstats look good. But we still found several variants that were not normalized. gwaslab fixed the position and alleles for the un-normalizated indels. And gwaslab standardize the notation for chromosome X to 23.</p> <p>In fact, <code>.basic_check()</code> is a wrapper of the following basic functions, you can also use these separately.</p> <ul> <li>mysumstats.fix_ID()</li> <li>mysumstats.fix_chr()</li> <li>mysumstats.fix_pos()</li> <li>mysumstats.fix_allele()</li> <li>mysumstats.check_sanity()</li> <li>mysumstats.normalize_allele()</li> </ul> <p>For other options, see: https://cloufield.github.io/gwaslab/Standardization/</p> <p>Let's extract the lead variants in each significant loci to check our data.</p> <p>The significant loci are detected based on a sliding window (default window size: <code>windowsizekb=500</code> kb)</p> <p>By specifying <code>anno=True</code> , gwaslab will also annotate the lead variant with its nearest gene names and distance.</p> <p>Note: GWASLab default genome build version is <code>build=\"19\"</code> (GRCh37/hg19), you can change it to <code>build=\"38\"</code> (GRCh38/hg38) when needed.</p> <p>Note: GWASLab will donwload reference files when you run it for the first time. In this case, <code>ensembl_hg19_gtf_protein_coding</code> was downloaded and processed automatically.</p> In\u00a0[9]: Copied! <pre>mysumstats.get_lead(anno=True)\n</pre> mysumstats.get_lead(anno=True) <pre>Tue Apr 25 14:07:11 2023 Start to extract lead variants...\nTue Apr 25 14:07:11 2023  -Processing 12557761 variants...\nTue Apr 25 14:07:11 2023  -Significance threshold : 5e-08\nTue Apr 25 14:07:11 2023  -Sliding window size: 500  kb\nTue Apr 25 14:07:13 2023  -Found 9461 significant variants in total...\nTue Apr 25 14:07:13 2023  -Identified 89 lead variants!\nTue Apr 25 14:07:13 2023 Start to annotate variants with nearest gene name(s)...\nTue Apr 25 14:07:13 2023  -Assigning Gene name using ensembl_hg19_gtf for protein coding genes\nTue Apr 25 14:07:13 2023 File not exist.\nTue Apr 25 14:07:13 2023 Start to download  ensembl_hg19_gtf  ...\nTue Apr 25 14:07:13 2023  -Downloading to: /home/yunye/.gwaslab/Homo_sapiens.GRCh37.87.chr.gtf.gz\nTue Apr 25 14:09:05 2023  -Updating record in config file...\nTue Apr 25 14:09:05 2023 Downloaded  ensembl_hg19_gtf  successfully!\nTue Apr 25 14:09:05 2023  - Extracting protein_coding genes from /home/yunye/.gwaslab/Homo_sapiens.GRCh37.87.chr.gtf.gz\n</pre> <pre>INFO:root:Extracted GTF attributes: ['gene_id', 'gene_name', 'gene_biotype']\n</pre> <pre>Tue Apr 25 14:09:40 2023  - Loaded 20327 protein_coding genes.\nTue Apr 25 14:09:53 2023  - Extracted records are saved to : /home/yunye/.gwaslab/Homo_sapiens.GRCh37.87.chr.protein_coding.gtf.gz \n</pre> <pre>INFO:pyensembl.database:Creating database: /home/yunye/.gwaslab/Homo_sapiens.GRCh37.87.chr.protein_coding.gtf.db\nINFO:pyensembl.database:Reading GTF from /home/yunye/.gwaslab/Homo_sapiens.GRCh37.87.chr.protein_coding.gtf.gz\nINFO:root:Extracted GTF attributes: ['gene_id', 'gene_version', 'gene_name', 'gene_biotype', 'transcript_id', 'transcript_version', 'transcript_name', 'transcript_biotype', 'ccds_id', 'exon_number', 'exon_id', 'exon_version', 'protein_id', 'protein_version']\nINFO:datacache.database_helpers:Creating database /home/yunye/.gwaslab/Homo_sapiens.GRCh37.87.chr.protein_coding.gtf.db containing: stop_codon, exon, transcript, start_codon, CDS, gene\nINFO:datacache.database:Running sqlite query: \"CREATE TABLE stop_codon (transcript_id TEXT NOT NULL, end INT NOT NULL, transcript_version TEXT NOT NULL, transcript_biotype TEXT NOT NULL, protein_id TEXT NOT NULL, seqname TEXT NOT NULL, ccds_id TEXT NOT NULL, exon_id TEXT NOT NULL, gene_name TEXT NOT NULL, source TEXT NOT NULL, protein_version TEXT NOT NULL, strand TEXT NOT NULL, feature TEXT NOT NULL, exon_number TEXT NOT NULL, exon_version TEXT NOT NULL, gene_version TEXT NOT NULL, transcript_name TEXT NOT NULL, start INT NOT NULL, gene_id TEXT NOT NULL, gene_biotype TEXT NOT NULL)\"\nINFO:datacache.database:Inserting 75368 rows into table stop_codon\nINFO:datacache.database:Creating index on stop_codon (seqname, start, end)\nINFO:datacache.database:Creating index on stop_codon (gene_name)\nINFO:datacache.database:Creating index on stop_codon (gene_id)\nINFO:datacache.database:Creating index on stop_codon (transcript_id)\nINFO:datacache.database:Creating index on stop_codon (transcript_name)\nINFO:datacache.database:Creating index on stop_codon (exon_id)\nINFO:datacache.database:Creating index on stop_codon (protein_id)\nINFO:datacache.database:Creating index on stop_codon (ccds_id)\nINFO:datacache.database:Running sqlite query: \"CREATE TABLE exon (transcript_id TEXT NOT NULL, end INT NOT NULL, transcript_version TEXT NOT NULL, transcript_biotype TEXT NOT NULL, protein_id TEXT NOT NULL, seqname TEXT NOT NULL, ccds_id TEXT NOT NULL, exon_id TEXT NOT NULL, gene_name TEXT NOT NULL, source TEXT NOT NULL, protein_version TEXT NOT NULL, strand TEXT NOT NULL, feature TEXT NOT NULL, exon_number TEXT NOT NULL, exon_version TEXT NOT NULL, gene_version TEXT NOT NULL, transcript_name TEXT NOT NULL, start INT NOT NULL, gene_id TEXT NOT NULL, gene_biotype TEXT NOT NULL)\"\nINFO:datacache.database:Inserting 1070082 rows into table exon\nINFO:datacache.database:Creating index on exon (seqname, start, end)\nINFO:datacache.database:Creating index on exon (gene_name)\nINFO:datacache.database:Creating index on exon (gene_id)\nINFO:datacache.database:Creating index on exon (transcript_id)\nINFO:datacache.database:Creating index on exon (transcript_name)\nINFO:datacache.database:Creating index on exon (exon_id)\nINFO:datacache.database:Creating index on exon (protein_id)\nINFO:datacache.database:Creating index on exon (ccds_id)\nINFO:datacache.database:Running sqlite query: \"CREATE TABLE transcript (transcript_id TEXT UNIQUE PRIMARY KEY NOT NULL, end INT NOT NULL, transcript_version TEXT NOT NULL, transcript_biotype TEXT NOT NULL, protein_id TEXT NOT NULL, seqname TEXT NOT NULL, ccds_id TEXT NOT NULL, exon_id TEXT NOT NULL, gene_name TEXT NOT NULL, source TEXT NOT NULL, protein_version TEXT NOT NULL, strand TEXT NOT NULL, feature TEXT NOT NULL, exon_number TEXT NOT NULL, exon_version TEXT NOT NULL, gene_version TEXT NOT NULL, transcript_name TEXT NOT NULL, start INT NOT NULL, gene_id TEXT NOT NULL, gene_biotype TEXT NOT NULL)\"\nINFO:datacache.database:Inserting 145531 rows into table transcript\nINFO:datacache.database:Creating index on transcript (seqname, start, end)\nINFO:datacache.database:Creating index on transcript (gene_name)\nINFO:datacache.database:Creating index on transcript (gene_id)\nINFO:datacache.database:Creating index on transcript (transcript_name)\nINFO:datacache.database:Creating index on transcript (exon_id)\nINFO:datacache.database:Creating index on transcript (protein_id)\nINFO:datacache.database:Creating index on transcript (ccds_id)\nINFO:datacache.database:Running sqlite query: \"CREATE TABLE start_codon (transcript_id TEXT NOT NULL, end INT NOT NULL, transcript_version TEXT NOT NULL, transcript_biotype TEXT NOT NULL, protein_id TEXT NOT NULL, seqname TEXT NOT NULL, ccds_id TEXT NOT NULL, exon_id TEXT NOT NULL, gene_name TEXT NOT NULL, source TEXT NOT NULL, protein_version TEXT NOT NULL, strand TEXT NOT NULL, feature TEXT NOT NULL, exon_number TEXT NOT NULL, exon_version TEXT NOT NULL, gene_version TEXT NOT NULL, transcript_name TEXT NOT NULL, start INT NOT NULL, gene_id TEXT NOT NULL, gene_biotype TEXT NOT NULL)\"\nINFO:datacache.database:Inserting 83781 rows into table start_codon\nINFO:datacache.database:Creating index on start_codon (seqname, start, end)\nINFO:datacache.database:Creating index on start_codon (gene_name)\nINFO:datacache.database:Creating index on start_codon (gene_id)\nINFO:datacache.database:Creating index on start_codon (transcript_id)\nINFO:datacache.database:Creating index on start_codon (transcript_name)\nINFO:datacache.database:Creating index on start_codon (exon_id)\nINFO:datacache.database:Creating index on start_codon (protein_id)\nINFO:datacache.database:Creating index on start_codon (ccds_id)\nINFO:datacache.database:Running sqlite query: \"CREATE TABLE CDS (transcript_id TEXT NOT NULL, end INT NOT NULL, transcript_version TEXT NOT NULL, transcript_biotype TEXT NOT NULL, protein_id TEXT NOT NULL, seqname TEXT NOT NULL, ccds_id TEXT NOT NULL, exon_id TEXT NOT NULL, gene_name TEXT NOT NULL, source TEXT NOT NULL, protein_version TEXT NOT NULL, strand TEXT NOT NULL, feature TEXT NOT NULL, exon_number TEXT NOT NULL, exon_version TEXT NOT NULL, gene_version TEXT NOT NULL, transcript_name TEXT NOT NULL, start INT NOT NULL, gene_id TEXT NOT NULL, gene_biotype TEXT NOT NULL)\"\nINFO:datacache.database:Inserting 721572 rows into table CDS\nINFO:datacache.database:Creating index on CDS (seqname, start, end)\nINFO:datacache.database:Creating index on CDS (gene_name)\nINFO:datacache.database:Creating index on CDS (gene_id)\nINFO:datacache.database:Creating index on CDS (transcript_id)\nINFO:datacache.database:Creating index on CDS (transcript_name)\nINFO:datacache.database:Creating index on CDS (exon_id)\nINFO:datacache.database:Creating index on CDS (protein_id)\nINFO:datacache.database:Creating index on CDS (ccds_id)\nINFO:datacache.database:Running sqlite query: \"CREATE TABLE gene (transcript_id TEXT NOT NULL, end INT NOT NULL, transcript_version TEXT NOT NULL, transcript_biotype TEXT NOT NULL, protein_id TEXT NOT NULL, seqname TEXT NOT NULL, ccds_id TEXT NOT NULL, exon_id TEXT NOT NULL, gene_name TEXT NOT NULL, source TEXT NOT NULL, protein_version TEXT NOT NULL, strand TEXT NOT NULL, feature TEXT NOT NULL, exon_number TEXT NOT NULL, exon_version TEXT NOT NULL, gene_version TEXT NOT NULL, transcript_name TEXT NOT NULL, start INT NOT NULL, gene_id TEXT UNIQUE PRIMARY KEY NOT NULL, gene_biotype TEXT NOT NULL)\"\nINFO:datacache.database:Inserting 20327 rows into table gene\nINFO:datacache.database:Creating index on gene (seqname, start, end)\nINFO:datacache.database:Creating index on gene (gene_name)\nINFO:datacache.database:Creating index on gene (transcript_id)\nINFO:datacache.database:Creating index on gene (transcript_name)\nINFO:datacache.database:Creating index on gene (exon_id)\nINFO:datacache.database:Creating index on gene (protein_id)\nINFO:datacache.database:Creating index on gene (ccds_id)\nINFO:datacache.database:Running sqlite query: \"CREATE TABLE _datacache_metadata (version INT)\"\nINFO:datacache.database:Running sqlite query: \"INSERT INTO _datacache_metadata VALUES (3)\"\n</pre> <pre>Tue Apr 25 14:11:25 2023 Finished annotating variants with nearest gene name(s) successfully!\nTue Apr 25 14:11:25 2023 Finished extracting lead variants successfully!\n</pre> Out[9]: SNPID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS LOCATION GENE 96739 1:22068326_A_G 1 22068326 G A 0.7550 0.0621 0.0103 1.629000e-09 191764 ++++ 9960099 0 USP48 213860 1:51103268_T_C 1 51103268 C T 0.7953 -0.0802 0.0120 2.519000e-11 191764 ---- 9960099 0 FAF1 534095 1:154309595_TA_T 1 154309595 TA T 0.0947 -0.0915 0.0166 3.289000e-08 191764 ---- 9960399 0 ATP8B2 969974 2:640986_CACAT_C 2 640986 C CACAT 0.9006 -0.0946 0.0150 2.665000e-10 191764 ---- 9960399 26349 TMEM18 1091807 2:27734972_G_A 2 27734972 G A 0.5605 0.0691 0.0088 3.897000e-15 191764 ++++ 9960099 0 GCKR ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 12272930 X:21569920_A_G 23 21569920 G A 0.3190 0.0423 0.0076 2.616000e-08 191764 ++++ 9960099 0 CNKSR2 12341406 X:48724648_CAA_C 23 48724648 C CAA 0.6260 -0.0602 0.0103 4.576000e-09 191764 ---- 9960399 26082 TIMM17B 12350767 X:57170781_A_AT 23 57170781 AT A 0.3003 -0.0447 0.0076 4.583000e-09 191764 ---- 9960399 -6723 SPIN2A 12469290 X:117915163_T_TA 23 117915163 TA T 0.5560 0.0548 0.0071 9.818000e-15 191764 ++++ 9960399 0 IL13RA1 12554976 X:152908887_G_A 23 152908887 G A 0.6792 -0.1235 0.0077 9.197000e-58 191764 ---- 9960099 0 DUSP9 <p>89 rows \u00d7 14 columns</p> <p>We extracted a total of 89 lead variants with a sliding window size of 500kb!</p> <p>For other options, see: https://cloufield.github.io/gwaslab/ExtractLead/</p> <p>GWASLab can create much more complicated Manhattan plots.</p> <p>For example,</p> <ul> <li>annotate the lead variants with closest gene names (threshold for annotation p&lt;1e-20)</li> <li>annotate selected variants with user-provided texts </li> <li>pinpoint some variants</li> <li>highlight some loci</li> <li>MAF-stratified Q-Q plot</li> <li>save as my_first_mqq_plot.png with {\"dpi\":400,\"facecolor\":\"white\"}</li> </ul> In\u00a0[10]: Copied! <pre>mysumstats.plot_mqq(mode=\"mqq\",\n                    cut=20,\n                    skip=2,\n                    anno=\"GENENAME\",\n                    sig_level_lead=1e-20,\n                    anno_alias={\"9:22132729_A_G\":\"some annotations\"},\n                    anno_style=\"expand\",\n                    xpad=0.01,\n                    pinpoint=[\"9:22132729_A_G\",\"5:176513896_C_A\"], \n                    pinpoint_color=\"green\",\n                    highlight=[\"7:127253550_C_T\",\"19:46166604_C_T\"],\n                    highlight_windowkb =1000,\n                    stratified=True,\n                    jagged=True,\n                    marker_size=(5,5),\n                    figargs={\"figsize\":(15,5),\"dpi\":300},\n                    save=\"my_first_mqq_plot.png\", \n                    save_args={\"dpi\":400,\"facecolor\":\"white\"})\n</pre> mysumstats.plot_mqq(mode=\"mqq\",                     cut=20,                     skip=2,                     anno=\"GENENAME\",                     sig_level_lead=1e-20,                     anno_alias={\"9:22132729_A_G\":\"some annotations\"},                     anno_style=\"expand\",                     xpad=0.01,                     pinpoint=[\"9:22132729_A_G\",\"5:176513896_C_A\"],                      pinpoint_color=\"green\",                     highlight=[\"7:127253550_C_T\",\"19:46166604_C_T\"],                     highlight_windowkb =1000,                     stratified=True,                     jagged=True,                     marker_size=(5,5),                     figargs={\"figsize\":(15,5),\"dpi\":300},                     save=\"my_first_mqq_plot.png\",                      save_args={\"dpi\":400,\"facecolor\":\"white\"}) <pre>Tue Apr 25 14:11:25 2023 Start to plot manhattan/qq plot with the following basic settings:\nTue Apr 25 14:11:25 2023  -Genome-wide significance level is set to 5e-08 ...\nTue Apr 25 14:11:25 2023  -Raw input contains 12557761 variants...\nTue Apr 25 14:11:25 2023  -Plot layout mode is : mqq\nTue Apr 25 14:11:25 2023  -Loci to highlight : 7:127253550_C_T,19:46166604_C_T\nTue Apr 25 14:11:25 2023   -Highlight_window is set to:  1000  kb\nTue Apr 25 14:11:25 2023  -Variants to pinpoint : 9:22132729_A_G,5:176513896_C_A\nTue Apr 25 14:11:29 2023 Finished loading specified columns from the sumstats.\nTue Apr 25 14:11:29 2023 Start conversion and sanity check:\nTue Apr 25 14:11:30 2023  -Removed 0 variants with nan in CHR or POS column ...\nTue Apr 25 14:11:30 2023  -Removed 0 variants with nan in EAF column ...\nTue Apr 25 14:11:31 2023  -Removed 0 variants with nan in P column ...\nTue Apr 25 14:11:32 2023  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nTue Apr 25 14:11:32 2023  -sumstats P values are being converted to -log10(P)...\nTue Apr 25 14:11:33 2023  -Sanity check: 0 na/inf/-inf variants will be removed...\nTue Apr 25 14:11:34 2023  -Maximum -log10(P) values is 167.58838029403677 .\nTue Apr 25 14:11:34 2023  -Minus log10(P) values above 20 will be shrunk with a shrinkage factor of 10...\nTue Apr 25 14:11:34 2023 Finished data conversion and sanity check.\nTue Apr 25 14:11:34 2023 Start to create manhattan plot with 332882 variants:\nTue Apr 25 14:11:35 2023  -Highlighting target loci...\nTue Apr 25 14:11:35 2023  -Pinpointing target vairants...\nTue Apr 25 14:11:35 2023  -Found 16 significant variants with a sliding window size of 500 kb...\nTue Apr 25 14:11:35 2023 Start to annotate variants with nearest gene name(s)...\nTue Apr 25 14:11:35 2023  -Assigning Gene name using ensembl_hg19_gtf for protein coding genes\nTue Apr 25 14:11:35 2023 Finished annotating variants with nearest gene name(s) successfully!\nTue Apr 25 14:11:35 2023 Finished creating Manhattan plot successfully!\nTue Apr 25 14:11:35 2023  -Annotating using column GENENAME...\nTue Apr 25 14:11:35 2023  -Adjusting text positions with repel_force=0.03...\nTue Apr 25 14:11:35 2023  -Too many variants to annotate; maybe it is better to reduce the number of variants\nTue Apr 25 14:11:35 2023 Start to create QQ plot with 332882 variants:\nTue Apr 25 14:11:36 2023  -Calculating lambda GC: 1.2128258399293808\nTue Apr 25 14:11:36 2023 Finished creating QQ plot successfully!\nTue Apr 25 14:11:36 2023 Saving plot:\nTue Apr 25 14:11:41 2023  -Saved to my_first_mqq_plot.png successfully!\n</pre> Out[10]: <pre>(&lt;Figure size 4500x1500 with 2 Axes&gt;, &lt;gwaslab.Log.Log at 0x7f46449ff6a0&gt;)</pre> <p>For details, see: https://cloufield.github.io/gwaslab/Visualization/</p> <p>gwaslab can also plot regional plots with or with out LD reference files.</p> <p>For details, see: https://cloufield.github.io/gwaslab/RegionalPlot/</p> <p>We first create a regional plot without references by specifying <code>mode</code> and <code>region</code>.</p> In\u00a0[11]: Copied! <pre>mysumstats.plot_mqq(mode=\"r\",skip=2,cut=20, region=(7,126253550,128253550),region_grid=True)\n</pre> mysumstats.plot_mqq(mode=\"r\",skip=2,cut=20, region=(7,126253550,128253550),region_grid=True) <pre>Tue Apr 25 14:11:46 2023 Start to plot manhattan/qq plot with the following basic settings:\nTue Apr 25 14:11:46 2023  -Genome-wide significance level is set to 5e-08 ...\nTue Apr 25 14:11:46 2023  -Raw input contains 12557761 variants...\nTue Apr 25 14:11:46 2023  -Plot layout mode is : r\nTue Apr 25 14:11:46 2023  -Region to plot : chr7:126253550-128253550.\nTue Apr 25 14:11:47 2023  -Extract SNPs in region : chr7:126253550-128253550...\nTue Apr 25 14:11:49 2023  -Extract SNPs in specified regions: 8087\nTue Apr 25 14:11:50 2023 Finished loading specified columns from the sumstats.\nTue Apr 25 14:11:50 2023 Start conversion and sanity check:\nTue Apr 25 14:11:50 2023  -Removed 0 variants with nan in CHR or POS column ...\nTue Apr 25 14:11:50 2023  -Removed 0 variants with nan in P column ...\nTue Apr 25 14:11:50 2023  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nTue Apr 25 14:11:50 2023  -sumstats P values are being converted to -log10(P)...\nTue Apr 25 14:11:50 2023  -Sanity check: 0 na/inf/-inf variants will be removed...\nTue Apr 25 14:11:50 2023  -Maximum -log10(P) values is 73.38711023071251 .\nTue Apr 25 14:11:50 2023  -Minus log10(P) values above 20 will be shrunk with a shrinkage factor of 10...\nTue Apr 25 14:11:50 2023 Finished data conversion and sanity check.\nTue Apr 25 14:11:50 2023 Start to create manhattan plot with 1600 variants:\nTue Apr 25 14:11:50 2023 Start to download  recombination_hg19  ...\nTue Apr 25 14:11:50 2023  -Downloading to: /home/yunye/.gwaslab/recombination/hg19/recombination_hg19.tar.gz\nTue Apr 25 14:13:12 2023  -Updating record in config file...\nTue Apr 25 14:13:12 2023 Downloaded  recombination_hg19  successfully!\nTue Apr 25 14:13:13 2023  -Loading gtf files from:default\n</pre> <pre>INFO:root:Extracted GTF attributes: ['gene_id', 'gene_name', 'gene_biotype']\n</pre> <pre>Tue Apr 25 14:13:50 2023  -plotting gene track..\nTue Apr 25 14:13:50 2023  -Finished plotting gene track..\nTue Apr 25 14:13:50 2023  -Found 1 significant variants with a sliding window size of 500 kb...\nTue Apr 25 14:13:50 2023 Finished creating Manhattan plot successfully!\nTue Apr 25 14:13:50 2023  -Skip annotating\n</pre> Out[11]: <pre>(&lt;Figure size 3000x2000 with 3 Axes&gt;, &lt;gwaslab.Log.Log at 0x7f46449ff6a0&gt;)</pre> <p>Full regional plot will require user-provided vcf or preprocessed vcf files: (e.g 1000 Genomes project, see Reference: https://cloufield.github.io/gwaslab/Reference/)</p> <p>gwaslab also provide pre-processed 1KG datasets.</p> <p>Update the available reference list first if needed</p> In\u00a0[12]: Copied! <pre># gl.update_available_ref()\n</pre> # gl.update_available_ref() In\u00a0[13]: Copied! <pre>gl.check_available_ref()\n</pre> gl.check_available_ref() <pre>Tue Apr 25 14:13:51 2023 Start to check available reference files...\nTue Apr 25 14:13:51 2023  - 1kg_eas_hg19  :  https://www.dropbox.com/s/lztaxqhy2o6dpxw/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz?dl=1\nTue Apr 25 14:13:51 2023  - 1kg_eas_hg19_md5  :  c8c97434843c0da3113fc06879ead472\nTue Apr 25 14:13:51 2023  - 1kg_eas_hg19_tbi  :  https://www.dropbox.com/s/k9klefl8m9fcfo1/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz.tbi?dl=1\nTue Apr 25 14:13:51 2023  - 1kg_eur_hg19  :  https://www.dropbox.com/s/1nbgqshknevseks/EUR.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz?dl=1\nTue Apr 25 14:13:51 2023  - 1kg_eur_hg19_md5  :  734069d895009d38c2f962bfbb6fab52\nTue Apr 25 14:13:51 2023  - 1kg_eur_hg19_tbi  :  https://www.dropbox.com/s/vscvkrflh6fc5a0/EUR.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz.tbi?dl=1\nTue Apr 25 14:13:51 2023  - 1kg_eas_hg38  :  https://www.dropbox.com/s/3dstbbb1el9r3au/EAS.ALL.split_norm_af.1kg_30x.hg38.vcf.gz?dl=1\nTue Apr 25 14:13:51 2023  - 1kg_eas_hg38_md5  :  f45e80bca9ef7b29e6b1832e6ac15375\nTue Apr 25 14:13:51 2023  - 1kg_eas_hg38_tbi  :  https://www.dropbox.com/s/vwnp5vd8dcqksn4/EAS.ALL.split_norm_af.1kg_30x.hg38.vcf.gz.tbi?dl=1\nTue Apr 25 14:13:51 2023  - 1kg_eur_hg38  :  https://www.dropbox.com/s/z0mkehg17lryapv/EUR.ALL.split_norm_af.1kg_30x.hg38.vcf.gz?dl=1\nTue Apr 25 14:13:51 2023  - 1kg_eur_hg38_md5  :  228d3285fa99132cc6321e2925e0768d\nTue Apr 25 14:13:51 2023  - 1kg_eur_hg38_tbi  :  https://www.dropbox.com/s/ze8g58x75x9qbf0/EUR.ALL.split_norm_af.1kg_30x.hg38.vcf.gz.tbi?dl=1\nTue Apr 25 14:13:51 2023  - dbsnp_v151_hg19  :  https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz\nTue Apr 25 14:13:51 2023  - dbsnp_v151_hg38  :  https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh38p7/VCF/00-All.vcf.gz\nTue Apr 25 14:13:51 2023  - ucsc_genome_hg19  :  http://hgdownload.cse.ucsc.edu/goldenpath/hg19/bigZips/hg19.fa.gz\nTue Apr 25 14:13:51 2023  - ucsc_genome_hg38  :  https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\nTue Apr 25 14:13:51 2023  - 1kg_dbsnp151_hg19_auto  :  https://www.dropbox.com/s/37p2u1xwmux4gwo/1kg_dbsnp151_hg19_auto.txt.gz?dl=1\nTue Apr 25 14:13:51 2023  - 1kg_dbsnp151_hg19_auto_md5  :  7d1e7624fb6e4df7a2f6f05558d436b4\nTue Apr 25 14:13:51 2023  - 1kg_dbsnp151_hg38_auto  :  https://www.dropbox.com/s/ouf60n7gdz6cm0g/1kg_dbsnp151_hg38_auto.txt.gz?dl=1\nTue Apr 25 14:13:51 2023  - 1kg_dbsnp151_hg38_auto_md5  :  4c7ef2d2415c18c286219e970fdda972\nTue Apr 25 14:13:51 2023  - recombination_hg19  :  https://www.dropbox.com/s/wbesl8haxknonuc/recombination_hg19.tar.gz?dl=1\nTue Apr 25 14:13:51 2023  - recombination_hg38  :  https://www.dropbox.com/s/vuo8mvqx0fpibzj/recombination_hg38.tar.gz?dl=1\nTue Apr 25 14:13:51 2023  - ensembl_hg19_gtf  :  https://ftp.ensembl.org/pub/grch37/current/gtf/homo_sapiens/Homo_sapiens.GRCh37.87.chr.gtf.gz\nTue Apr 25 14:13:51 2023  - ensembl_hg38_gtf  :  https://ftp.ensembl.org/pub/release-109/gtf/homo_sapiens//Homo_sapiens.GRCh38.109.chr.gtf.gz\nTue Apr 25 14:13:51 2023  - refseq_hg19_gtf  :  https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh37_latest/refseq_identifiers/GRCh37_latest_genomic.gtf.gz\nTue Apr 25 14:13:51 2023  - refseq_hg38_gtf  :  https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh38_latest/refseq_identifiers/GRCh38_latest_genomic.gtf.gz\nTue Apr 25 14:13:51 2023  - testlink  :  https://www.dropbox.com/s/8u7capwge0ihshu/EAS.chr22.split_norm_af.1kgp3v5.vcf.gz?dl=1\nTue Apr 25 14:13:51 2023  - testlink_tbi  :  https://www.dropbox.com/s/hdneg53t6u1j6ib/EAS.chr22.split_norm_af.1kgp3v5.vcf.gz.tbi?dl=1\n</pre> Out[13]: <pre>{'1kg_eas_hg19': 'https://www.dropbox.com/s/lztaxqhy2o6dpxw/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz?dl=1',\n '1kg_eas_hg19_md5': 'c8c97434843c0da3113fc06879ead472',\n '1kg_eas_hg19_tbi': 'https://www.dropbox.com/s/k9klefl8m9fcfo1/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz.tbi?dl=1',\n '1kg_eur_hg19': 'https://www.dropbox.com/s/1nbgqshknevseks/EUR.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz?dl=1',\n '1kg_eur_hg19_md5': '734069d895009d38c2f962bfbb6fab52',\n '1kg_eur_hg19_tbi': 'https://www.dropbox.com/s/vscvkrflh6fc5a0/EUR.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz.tbi?dl=1',\n '1kg_eas_hg38': 'https://www.dropbox.com/s/3dstbbb1el9r3au/EAS.ALL.split_norm_af.1kg_30x.hg38.vcf.gz?dl=1',\n '1kg_eas_hg38_md5': 'f45e80bca9ef7b29e6b1832e6ac15375',\n '1kg_eas_hg38_tbi': 'https://www.dropbox.com/s/vwnp5vd8dcqksn4/EAS.ALL.split_norm_af.1kg_30x.hg38.vcf.gz.tbi?dl=1',\n '1kg_eur_hg38': 'https://www.dropbox.com/s/z0mkehg17lryapv/EUR.ALL.split_norm_af.1kg_30x.hg38.vcf.gz?dl=1',\n '1kg_eur_hg38_md5': '228d3285fa99132cc6321e2925e0768d',\n '1kg_eur_hg38_tbi': 'https://www.dropbox.com/s/ze8g58x75x9qbf0/EUR.ALL.split_norm_af.1kg_30x.hg38.vcf.gz.tbi?dl=1',\n 'dbsnp_v151_hg19': 'https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz',\n 'dbsnp_v151_hg38': 'https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh38p7/VCF/00-All.vcf.gz',\n 'ucsc_genome_hg19': 'http://hgdownload.cse.ucsc.edu/goldenpath/hg19/bigZips/hg19.fa.gz',\n 'ucsc_genome_hg38': 'https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz',\n '1kg_dbsnp151_hg19_auto': 'https://www.dropbox.com/s/37p2u1xwmux4gwo/1kg_dbsnp151_hg19_auto.txt.gz?dl=1',\n '1kg_dbsnp151_hg19_auto_md5': '7d1e7624fb6e4df7a2f6f05558d436b4',\n '1kg_dbsnp151_hg38_auto': 'https://www.dropbox.com/s/ouf60n7gdz6cm0g/1kg_dbsnp151_hg38_auto.txt.gz?dl=1',\n '1kg_dbsnp151_hg38_auto_md5': '4c7ef2d2415c18c286219e970fdda972',\n 'recombination_hg19': 'https://www.dropbox.com/s/wbesl8haxknonuc/recombination_hg19.tar.gz?dl=1',\n 'recombination_hg38': 'https://www.dropbox.com/s/vuo8mvqx0fpibzj/recombination_hg38.tar.gz?dl=1',\n 'ensembl_hg19_gtf': 'https://ftp.ensembl.org/pub/grch37/current/gtf/homo_sapiens/Homo_sapiens.GRCh37.87.chr.gtf.gz',\n 'ensembl_hg38_gtf': 'https://ftp.ensembl.org/pub/release-109/gtf/homo_sapiens//Homo_sapiens.GRCh38.109.chr.gtf.gz',\n 'refseq_hg19_gtf': 'https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh37_latest/refseq_identifiers/GRCh37_latest_genomic.gtf.gz',\n 'refseq_hg38_gtf': 'https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh38_latest/refseq_identifiers/GRCh38_latest_genomic.gtf.gz',\n 'testlink': 'https://www.dropbox.com/s/8u7capwge0ihshu/EAS.chr22.split_norm_af.1kgp3v5.vcf.gz?dl=1',\n 'testlink_tbi': 'https://www.dropbox.com/s/hdneg53t6u1j6ib/EAS.chr22.split_norm_af.1kgp3v5.vcf.gz.tbi?dl=1'}</pre> <p>You can see the current available reference files (from the original source or pre-processed by gwaslab).</p> <p>Select the keyword and use <code>download_ref</code> to download the files. The downloaded files will be placed in <code>~/.gwasalb</code> by default.</p> <ul> <li><code>1kg_eas_hg19</code> : processed 1000 Genomes Project EAS samples dataset(hg19; ~2.8GB) It may take several minutes to download.</li> </ul> In\u00a0[14]: Copied! <pre># ~2.8GB\ngl.download_ref(\"1kg_eas_hg19\")\n</pre> # ~2.8GB gl.download_ref(\"1kg_eas_hg19\") <pre>Tue Apr 25 14:13:51 2023 Start to download  1kg_eas_hg19  ...\nTue Apr 25 14:13:51 2023  -Downloading to: /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\nTue Apr 25 14:15:41 2023  -File path: /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\nTue Apr 25 14:15:41 2023  -MD5 check: c8c97434843c0da3113fc06879ead472\nTue Apr 25 14:15:41 2023  -MD5 verified.\nTue Apr 25 14:15:41 2023  -Updating record in config file...\nTue Apr 25 14:15:43 2023  -Updating record in config file...\nTue Apr 25 14:15:43 2023  -Downloading to: /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz.tbi\nTue Apr 25 14:15:43 2023 Downloaded  1kg_eas_hg19  successfully!\n</pre> In\u00a0[15]: Copied! <pre>gl.check_downloaded_ref()\n</pre> gl.check_downloaded_ref() <pre>Tue Apr 25 14:15:43 2023 Start to check downloaded reference files...\nTue Apr 25 14:15:43 2023  -Checking the config file:/home/yunye/work/gwaslab/src/gwaslab/data/config.json\nTue Apr 25 14:15:43 2023  -Config file exists.\nTue Apr 25 14:15:43 2023  -Updating config.json...\nTue Apr 25 14:15:43 2023   - ensembl_hg19_gtf  :  /home/yunye/.gwaslab/Homo_sapiens.GRCh37.87.chr.gtf.gz\nTue Apr 25 14:15:43 2023   - recombination_hg19  :  /home/yunye/.gwaslab/recombination/hg19/recombination_hg19.tar.gz\nTue Apr 25 14:15:43 2023   - 1kg_eas_hg19  :  /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\nTue Apr 25 14:15:43 2023   - 1kg_eas_hg19_tbi  :  /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz.tbi\n</pre> Out[15]: <pre>{'ensembl_hg19_gtf': '/home/yunye/.gwaslab/Homo_sapiens.GRCh37.87.chr.gtf.gz',\n 'recombination_hg19': '/home/yunye/.gwaslab/recombination/hg19/recombination_hg19.tar.gz',\n '1kg_eas_hg19': '/home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz',\n '1kg_eas_hg19_tbi': '/home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz.tbi'}</pre> <p>After downloading, use <code>get_path</code> to obtain the file path by specifying the keyword.</p> <p>Note:</p> <ul> <li>If <code>tabix</code> is available in PATH, the speed will be  will greatly improved. Otherwise, vcf files will be loaded from the head. </li> <li>tabix: http://www.htslib.org/download/</li> </ul> In\u00a0[16]: Copied! <pre>mysumstats.plot_mqq(mode=\"r\",\n                    region=(7,126253550,128253550),\n                    region_grid=True,\n                    anno=True,\n                    anno_args={\"rotation\":0,\"fontsize\":12},\n                    vcf_path=gl.get_path(\"1kg_eas_hg19\"))\n</pre> mysumstats.plot_mqq(mode=\"r\",                     region=(7,126253550,128253550),                     region_grid=True,                     anno=True,                     anno_args={\"rotation\":0,\"fontsize\":12},                     vcf_path=gl.get_path(\"1kg_eas_hg19\")) <pre>Tue Apr 25 14:15:43 2023 Start to plot manhattan/qq plot with the following basic settings:\nTue Apr 25 14:15:43 2023  -Genome-wide significance level is set to 5e-08 ...\nTue Apr 25 14:15:43 2023  -Raw input contains 12557761 variants...\nTue Apr 25 14:15:43 2023  -Plot layout mode is : r\nTue Apr 25 14:15:43 2023  -Region to plot : chr7:126253550-128253550.\nTue Apr 25 14:15:44 2023  -Extract SNPs in region : chr7:126253550-128253550...\nTue Apr 25 14:15:47 2023  -Extract SNPs in specified regions: 8087\nTue Apr 25 14:15:47 2023 Finished loading specified columns from the sumstats.\nTue Apr 25 14:15:47 2023 Start conversion and sanity check:\nTue Apr 25 14:15:47 2023  -Removed 0 variants with nan in CHR or POS column ...\nTue Apr 25 14:15:47 2023  -Removed 0 variants with nan in P column ...\nTue Apr 25 14:15:47 2023  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nTue Apr 25 14:15:47 2023  -sumstats P values are being converted to -log10(P)...\nTue Apr 25 14:15:47 2023  -Sanity check: 0 na/inf/-inf variants will be removed...\nTue Apr 25 14:15:47 2023  -Maximum -log10(P) values is 73.38711023071251 .\nTue Apr 25 14:15:47 2023 Finished data conversion and sanity check.\nTue Apr 25 14:15:47 2023 Start to load reference genotype...\nTue Apr 25 14:15:47 2023  -reference vcf path : /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\nTue Apr 25 14:15:48 2023  -Retrieving index...\nTue Apr 25 14:15:48 2023  -Ref variants in the region: 54234\nTue Apr 25 14:15:48 2023  -Matching variants using POS, NEA, EA ...\nTue Apr 25 14:15:49 2023  -Calculating Rsq...\nTue Apr 25 14:15:49 2023 Finished loading reference genotype successfully!\nTue Apr 25 14:15:49 2023 Start to create manhattan plot with 8087 variants:\nTue Apr 25 14:15:49 2023  -Loading gtf files from:default\n</pre> <pre>INFO:root:Extracted GTF attributes: ['gene_id', 'gene_name', 'gene_biotype']\n</pre> <pre>Tue Apr 25 14:16:27 2023  -plotting gene track..\nTue Apr 25 14:16:27 2023  -Finished plotting gene track..\nTue Apr 25 14:16:27 2023  -Found 1 significant variants with a sliding window size of 500 kb...\nTue Apr 25 14:16:27 2023 Finished creating Manhattan plot successfully!\nTue Apr 25 14:16:27 2023  -Annotating using column CHR:POS...\nTue Apr 25 14:16:27 2023  -Adjusting text positions with repel_force=0.03...\n</pre> Out[16]: <pre>(&lt;Figure size 3000x2000 with 4 Axes&gt;, &lt;gwaslab.Log.Log at 0x7f46449ff6a0&gt;)</pre> <p>Or you can provide your own vcf files for <code>vcf_path</code>.</p> In\u00a0[\u00a0]: Copied! <pre># mysumstats.plot_mqq(mode=\"r\",\n#                     region=(7,156538803,157538803),\n#                     region_grid=True,\n#                     anno=True,\n#                     vcf_path=\"/home/yunye/mydata/d_disk/eas_1kg_af/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\")\n</pre> # mysumstats.plot_mqq(mode=\"r\", #                     region=(7,156538803,157538803), #                     region_grid=True, #                     anno=True, #                     vcf_path=\"/home/yunye/mydata/d_disk/eas_1kg_af/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\") <p>Note: gwaslab default genome build version is <code>build=\"19\"</code> (GRCh37/hg19), you can change it to <code>build=\"38\"</code> (GRCh38/hg38) when needed. For gene tracks, default is <code>gtf_path=\"ensembl\"</code> , you can also use <code>gtf_path=\"refseq\"</code> (NCBA RefSeq)</p> <p>There are more than 10 million variants in the original sumstats and it will take some time to process the entrie dataset. Let's just randomly sample 100K variants for this tutorial.</p> In\u00a0[17]: Copied! <pre>mysumstats.random_variants(n=100000,inplace=True,random_state=1234)\n</pre> mysumstats.random_variants(n=100000,inplace=True,random_state=1234) <pre>Tue Apr 25 15:14:07 2023 Start to randomly select variants from the sumstats...\nTue Apr 25 15:14:07 2023  -Number of variants selected from the sumstats: 100000\nTue Apr 25 15:14:07 2023  -Random state (seed): 1234\nTue Apr 25 15:14:07 2023 Finished sampling...\n</pre> <p>In case you don't know the genome build of the sumstats</p> <p>For details, see: https://cloufield.github.io/gwaslab/InferBuild/</p> In\u00a0[18]: Copied! <pre>mysumstats.infer_build()\n</pre> mysumstats.infer_build() <pre>Tue Apr 25 15:14:08 2023 Start to infer genome build version using hapmap3 SNPs...\nTue Apr 25 15:14:08 2023  -Loading Hapmap3 variants data...\nTue Apr 25 15:14:09 2023  -CHR:POS will be used for matching...\nTue Apr 25 15:14:10 2023  -Matching variants for hg19: num_hg19 =  8671\nTue Apr 25 15:14:10 2023  -Matching variants for hg38: num_hg38 =  145\nTue Apr 25 15:14:10 2023  -Warning: please be cautious due to the limited number of variants.\nTue Apr 25 15:14:10 2023  -Since num_hg19 &gt;&gt; num_hg38, assigning genome build hg19...\n</pre> <p>You may notice that the SNPID is in <code>CHR:POS_REF_ALT</code> format. We want SNPID to be in a stadardized format <code>CHR:POS:REF:ALT</code>, we can use fix_id for this:</p> <p>For other options of standardization, see: https://cloufield.github.io/gwaslab/Standardization/</p> In\u00a0[19]: Copied! <pre>#fixsep : fix ID separator\nmysumstats.fix_id(fixsep=True)\n</pre> #fixsep : fix ID separator mysumstats.fix_id(fixsep=True) <pre>Tue Apr 25 15:14:11 2023 Start to check IDs...\nTue Apr 25 15:14:11 2023  -Current Dataframe shape : 100000  x  12\nTue Apr 25 15:14:11 2023  -Checking if SNPID is chr:pos:ref:alt...(separator: - ,: , _)\nTue Apr 25 15:14:11 2023  -Replacing [_-] in SNPID with \":\" ...\nTue Apr 25 15:14:11 2023 Finished checking IDs successfully!\n</pre> In\u00a0[20]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[20]: SNPID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS 1736173 2:180784768:G:T 2 180784768 G T 0.9978 0.0797 0.1141 0.4850 191764 -+++ 1960099 258841 1:61108984:G:C 1 61108984 G C 0.4847 -0.0095 0.0087 0.2767 191764 +--+ 1960099 89268 1:20294687:G:A 1 20294687 G A 0.7936 0.0161 0.0111 0.1484 191764 0++- 1960099 10697866 16:86560264:T:C 16 86560264 C T 0.3114 -0.0016 0.0095 0.8663 191764 --+- 1960099 6068219 7:152311067:G:A 7 152311067 G A 0.9977 0.1369 0.1433 0.3395 166718 +?++ 1960099 ... ... ... ... ... ... ... ... ... ... ... ... ... 3376277 4:105613391:C:T 4 105613391 C T 0.9966 0.1211 0.0939 0.1974 191764 ++++ 1960099 5598990 7:38184549:A:T 7 38184549 T A 0.6533 -0.0000 0.0095 0.9982 191764 +-+- 1960099 7580034 10:58897803:A:G 10 58897803 G A 0.0096 -0.0339 0.0623 0.5860 191764 ++-- 1960099 10546104 16:58355232:G:A 16 58355232 G A 0.6904 0.0083 0.0108 0.4401 191764 +-++ 1960099 9937711 14:94630415:G:A 14 94630415 G A 0.7970 0.0174 0.0113 0.1221 191764 ++++ 1960099 <p>100000 rows \u00d7 12 columns</p> <p>rsID is assigned using two types of reference file:</p> <ul> <li>ref_rsid_tsv : tsv file for annotation of commonly used variants</li> <li>ref_rsid_vcf : vcf file for annotation of other variants</li> </ul> <p>GWASLab provides preprocessed tsv files for 1KG varaints (~80M), we can download the file using <code>.download_ref</code> with key words. This time we will use <code>1kg_dbsnp151_hg19_auto</code>, which is the SNPID-rsID conversion table for autosomal variants in 1KG project (hg19). This will take around a few minutes to dowadload.</p> In\u00a0[21]: Copied! <pre># 961M\ngl.download_ref(\"1kg_dbsnp151_hg19_auto\")\n</pre> # 961M gl.download_ref(\"1kg_dbsnp151_hg19_auto\") <pre>Tue Apr 25 14:16:32 2023 Start to download  1kg_dbsnp151_hg19_auto  ...\nTue Apr 25 14:16:32 2023  -Downloading to: /home/yunye/.gwaslab/1kg_dbsnp151_hg19_auto.txt.gz\nTue Apr 25 14:17:08 2023  -File path: /home/yunye/.gwaslab/1kg_dbsnp151_hg19_auto.txt.gz\nTue Apr 25 14:17:08 2023  -MD5 check: 7d1e7624fb6e4df7a2f6f05558d436b4\nTue Apr 25 14:17:08 2023  -MD5 verified.\nTue Apr 25 14:17:08 2023  -Updating record in config file...\nTue Apr 25 14:17:08 2023 Downloaded  1kg_dbsnp151_hg19_auto  successfully!\n</pre> In\u00a0[22]: Copied! <pre>mysumstats.assign_rsid(ref_rsid_tsv= gl.get_path(\"1kg_dbsnp151_hg19_auto\"))\n</pre> mysumstats.assign_rsid(ref_rsid_tsv= gl.get_path(\"1kg_dbsnp151_hg19_auto\")) <pre>Tue Apr 25 15:14:11 2023 Start to annotate rsID based on chromosome and position information...\nTue Apr 25 15:14:11 2023  -Current Dataframe shape : 100000  x  12\nTue Apr 25 15:14:11 2023  -SNPID-rsID text file: /home/yunye/.gwaslab/1kg_dbsnp151_hg19_auto.txt.gz\nTue Apr 25 15:14:11 2023  -100000 rsID could be possibly fixed...\nTue Apr 25 15:14:11 2023  -Setting block size:  5000000\nTue Apr 25 15:14:11 2023  -Loading block: 0   1   2   3   4   5   6   7   8   9   10   11   12   13   14   15   \nTue Apr 25 15:18:13 2023  -rsID Annotation for 3266 need to be fixed!\nTue Apr 25 15:18:13 2023  -Annotated 96734 rsID successfully!\n</pre> <ul> <li>We annotated 96734  (96734 /100000 = 96.7%) variants using the conversion table.</li> <li>For the annotation of other variants (3.3%), we may need the dbSNP reference vcf.</li> </ul> <p>For the annotation of not-so-common variants, we can use vcf files downloaded form NCBI dbsnp (https://ftp.ncbi.nih.gov/snp/latest_release/VCF/).</p> <p>Note:</p> <ul> <li>The file size is huge (&gt;20GB) and it might take several hours to download. (we can skip this step in this tutorial. )</li> <li>Specify <code>chr_dict</code> to match the chromosome notations in sumstats and in vcf files.</li> </ul> <p>Parameters :</p> <ul> <li><code>ref_rsid_vcf</code>: the path to the reference rsID vcf file</li> <li><code>n_cores</code> : number of threads to use</li> </ul> In\u00a0[23]: Copied! <pre>mysumstats.assign_rsid(n_cores=1,\n                       ref_rsid_vcf= \"/home/yunye/CommonData/Reference/ncbi_dbsnp/ncbi_dbsnp/db155/GCF_000001405.25.gz\",\n                       chr_dict = gl.get_number_to_NC(build=\"19\") )\n</pre> mysumstats.assign_rsid(n_cores=1,                        ref_rsid_vcf= \"/home/yunye/CommonData/Reference/ncbi_dbsnp/ncbi_dbsnp/db155/GCF_000001405.25.gz\",                        chr_dict = gl.get_number_to_NC(build=\"19\") ) <pre>Tue Apr 25 15:18:13 2023 Start to assign rsID using vcf...\nTue Apr 25 15:18:13 2023  -Current Dataframe shape : 100000  x  13\nTue Apr 25 15:18:13 2023  -CPU Cores to use : 1\nTue Apr 25 15:18:13 2023  -Reference VCF file: /home/yunye/CommonData/Reference/ncbi_dbsnp/ncbi_dbsnp/db155/GCF_000001405.25.gz\nTue Apr 25 15:18:13 2023  -Assigning rsID based on chr:pos and ref:alt/alt:ref...\nTue Apr 25 15:18:19 2023  -rsID Annotation for 122 need to be fixed!\nTue Apr 25 15:18:19 2023  -Annotated 3144 rsID successfully!\n</pre> <p>After this, only 122 variants were not annotated. (122/100000 = 0.122%), mostly indels.</p> In\u00a0[24]: Copied! <pre>mysumstats.data.loc[mysumstats.data[\"rsID\"].isna(),:]\n</pre> mysumstats.data.loc[mysumstats.data[\"rsID\"].isna(),:] Out[24]: SNPID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS rsID 248 2:175894098:G:AA 2 175894098 G AA 0.6600 -0.0029 0.0095 0.76090 191764 ++-- 1960399 &lt;NA&gt; 269 X:95972533:A:AT 23 95972533 AT A 0.2461 0.0175 0.0096 0.06804 191764 +-++ 1960399 &lt;NA&gt; 1455 X:120283097:A:AT 23 120283097 AT A 0.1279 -0.0144 0.0110 0.18910 191764 ---+ 1960399 &lt;NA&gt; 1803 2:153147115:C:AA 2 153147115 C AA 0.5061 -0.0005 0.0103 0.96120 191764 -++- 1960399 &lt;NA&gt; 1985 X:113620243:CAAA:C 23 113620243 C CAAA 0.2933 0.0053 0.0082 0.52150 191764 -+++ 1960399 &lt;NA&gt; ... ... ... ... ... ... ... ... ... ... ... ... ... ... 93825 3:104431873:C:AA 3 104431873 C AA 0.0417 -0.0328 0.0221 0.13830 191764 ++-- 1960399 &lt;NA&gt; 93840 X:18195379:CTT:C 23 18195379 C CTT 0.1204 0.0260 0.0131 0.04715 191764 ++++ 1960399 &lt;NA&gt; 94793 8:69844929:CAAACAAAACA:C 8 69844929 C CAAACAAAACA 0.0300 0.0332 0.0368 0.36610 191764 ++++ 1960399 &lt;NA&gt; 98581 X:97528779:TTTG:T 23 97528779 TTTG T 0.1536 0.0007 0.0097 0.93880 191764 -++- 1960399 &lt;NA&gt; 98879 X:14442356:G:GAC 23 14442356 GAC G 0.0828 -0.0036 0.0145 0.80530 191764 --+- 1960399 &lt;NA&gt; <p>122 rows \u00d7 13 columns</p> <p>Tips : The two steps can be run in a single one.</p> In\u00a0[24]: Copied! <pre>#mysumstats.assign_rsid(n_cores=3,\n#                       ref_rsid_tsv= gl.get_path(\"1kg_dbsnp151_hg19_auto\"),\n#                       ref_rsid_vcf= \"/home/yunye/CommonData/Reference/ncbi_dbsnp/ncbi_dbsnp/db155/GCF_000001405.25.gz\",\n#                       chr_dict = gl.get_number_to_NC(build=\"19\") )\n</pre> #mysumstats.assign_rsid(n_cores=3, #                       ref_rsid_tsv= gl.get_path(\"1kg_dbsnp151_hg19_auto\"), #                       ref_rsid_vcf= \"/home/yunye/CommonData/Reference/ncbi_dbsnp/ncbi_dbsnp/db155/GCF_000001405.25.gz\", #                       chr_dict = gl.get_number_to_NC(build=\"19\") ) <p>gwaslab can harmonize the sumstats based on reference files.</p> <ul> <li>ref_seq : reference genome fasta file for allele alignment</li> <li>ref_infer : vcf file with allele frequency information for inferring strand and comparing allele frequency </li> <li>ref_alt_freq : field in INFO of vcf file for alternative allele frequency</li> </ul> <p>For details see: https://cloufield.github.io/gwaslab/Harmonization/</p> <p>For reference data, see: https://cloufield.github.io/gwaslab/Reference/</p> <p>We can use the refernce genome from 1000 genomes.</p> <p>http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.gz http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.fai</p> <p>When calling <code>.harmonize()</code>, <code>.basic_check()</code> will be called first to make sure the dataset is ready for harmonization. Since we have already performed basic_check, we set <code>basic_check=False</code> here. For <code>ref_infer</code>, we pass the downloaded vcf files for 1KG EAS and specify the field for alternative allele frequency to AF by <code>ref_alt_freq= \"AF\"</code>.</p> In\u00a0[25]: Copied! <pre>mysumstats.harmonize(basic_check=False,\n                     n_cores=3,\n                     ref_seq     = \"/home/yunye/CommonData/Reference/genome/humanG1Kv37/human_g1k_v37.fasta\",\n                     ref_infer   = gl.get_path(\"1kg_eas_hg19\"),\n                     ref_alt_freq= \"AF\")\n</pre> mysumstats.harmonize(basic_check=False,                      n_cores=3,                      ref_seq     = \"/home/yunye/CommonData/Reference/genome/humanG1Kv37/human_g1k_v37.fasta\",                      ref_infer   = gl.get_path(\"1kg_eas_hg19\"),                      ref_alt_freq= \"AF\") <pre>Tue Apr 25 15:18:19 2023 Start to check if NEA is aligned with reference sequence...\nTue Apr 25 15:18:19 2023  -Current Dataframe shape : 100000  x  13\nTue Apr 25 15:18:19 2023  -Reference genome fasta file: /home/yunye/CommonData/Reference/genome/humanG1Kv37/human_g1k_v37.fasta\nTue Apr 25 15:18:19 2023  -Checking records: 1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  X  Y  MT  \nTue Apr 25 15:18:35 2023  -Variants allele on given reference sequence :  41528\nTue Apr 25 15:18:35 2023  -Variants flipped :  50055\nTue Apr 25 15:18:35 2023   -Raw Matching rate :  91.58%\nTue Apr 25 15:18:35 2023  -Variants inferred reverse_complement :  0\nTue Apr 25 15:18:35 2023  -Variants inferred reverse_complement_flipped :  0\nTue Apr 25 15:18:35 2023  -Both allele on genome + unable to distinguish :  8417\nTue Apr 25 15:18:35 2023  -Variants not on given reference sequence :  0\nTue Apr 25 15:18:35 2023  -Current Dataframe shape : 100000  x  13\nTue Apr 25 15:18:35 2023 Start to flip allele-specific stats for SNPs with status xxxxx[35]x: alt-&gt;ea , ref-&gt;nea ... \nTue Apr 25 15:18:35 2023  -Flipping 50055 variants...\nTue Apr 25 15:18:35 2023  -Swapping column: NEA &lt;=&gt; EA...\nTue Apr 25 15:18:35 2023  -Flipping column: BETA = - BETA...\nTue Apr 25 15:18:35 2023  -Flipping column: EAF = 1 - EAF...\nTue Apr 25 15:18:35 2023  -Flipping column: DIRECTION +-? &lt;=&gt; -+? ...\nTue Apr 25 15:18:35 2023  -Changed the status for flipped variants : xxxxx[35]x -&gt; xxxxx[12]x\nTue Apr 25 15:18:35 2023 Finished converting successfully!\nTue Apr 25 15:18:35 2023 Start to infer strand for palindromic SNPs...\nTue Apr 25 15:18:35 2023  -Current Dataframe shape : 100000  x  13\nTue Apr 25 15:18:35 2023  -Reference vcf file: /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\nTue Apr 25 15:18:35 2023  -Alternative allele frequency in INFO: AF\nTue Apr 25 15:18:35 2023  -Identified  14174  palindromic SNPs...\nTue Apr 25 15:18:35 2023  -After filtering by MAF&lt;  0.4  , the strand of  12937  palindromic SNPs will be inferred...\nTue Apr 25 15:18:40 2023   -Non-palindromic :  76650\nTue Apr 25 15:18:40 2023   -Palindromic SNPs on + strand:  12566\nTue Apr 25 15:18:40 2023   -Palindromic SNPs on - strand and need to be flipped: 17\nTue Apr 25 15:18:40 2023   -Palindromic SNPs with maf not availble to infer :  1237\nTue Apr 25 15:18:40 2023   -Palindromic SNPs with no macthes or no information :  181\nTue Apr 25 15:18:40 2023  -Identified  8417  indistinguishable Indels...\nTue Apr 25 15:18:40 2023  -Indistinguishable Indels will be inferred from reference vcf ref and alt...\nTue Apr 25 15:18:49 2023   -Indels ea/nea match reference :  3659\nTue Apr 25 15:18:49 2023   -Indels ea/nea need to be flipped :  4484\nTue Apr 25 15:18:49 2023   -Indels with no macthes or no information :  274\nTue Apr 25 15:18:49 2023  -Current Dataframe shape : 100000  x  13\nTue Apr 25 15:18:49 2023 Start to flip allele-specific stats for standardized indels with status xxxx[123][67][6]: alt-&gt;ea , ref-&gt;nea ... \nTue Apr 25 15:18:49 2023  -Flipping 4484 variants...\nTue Apr 25 15:18:49 2023  -Swapping column: NEA &lt;=&gt; EA...\nTue Apr 25 15:18:49 2023  -Flipping column: BETA = - BETA...\nTue Apr 25 15:18:49 2023  -Flipping column: EAF = 1 - EAF...\nTue Apr 25 15:18:49 2023  -Flipping column: DIRECTION +-? &lt;=&gt; -+? ...\nTue Apr 25 15:18:49 2023  -Changed the status for flipped variants xxxx[123][67]6 -&gt; xxxx[123][67]4\nTue Apr 25 15:18:49 2023 Start to flip allele-specific stats for palindromic SNPs with status xxxxx[12]5: (-)strand &lt;=&gt; (+)strand ... \nTue Apr 25 15:18:49 2023  -Flipping 17 variants...\nTue Apr 25 15:18:49 2023  -Flipping column: BETA = - BETA...\nTue Apr 25 15:18:49 2023  -Flipping column: EAF = 1 - EAF...\nTue Apr 25 15:18:49 2023  -Flipping column: DIRECTION +-? &lt;=&gt; -+? ...\nTue Apr 25 15:18:49 2023  -Changed the status for flipped variants:  xxxxx[012]5: -&gt;  xxxxx[012]2\nTue Apr 25 15:18:49 2023 Finished converting successfully!\nTue Apr 25 15:18:49 2023 Start to sort the genome coordinates...\nTue Apr 25 15:18:49 2023  -Current Dataframe shape : 100000  x  13\nTue Apr 25 15:18:49 2023  -Sorting genome coordinates...\nTue Apr 25 15:18:49 2023 Finished sorting genome coordinates successfully!\nTue Apr 25 15:18:49 2023 Start to reorder the columns...\nTue Apr 25 15:18:49 2023  -Current Dataframe shape : 100000  x  13\nTue Apr 25 15:18:49 2023  -Reordering columns to    : SNPID,rsID,CHR,POS,EA,NEA,EAF,BETA,SE,P,N,DIRECTION,STATUS\nTue Apr 25 15:18:49 2023 Finished sorting columns successfully!\n</pre> Out[25]: <pre>&lt;gwaslab.Sumstats.Sumstats at 0x7f26bc3e3b20&gt;</pre> <p>Check the data again. Looks good!</p> In\u00a0[26]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[26]: SNPID rsID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS 0 1:875643:C:G rs7411115 1 875643 G C 0.7290 0.0147 0.0130 0.258600 166718 +?+- 1960001 1 1:928416:G:A rs111754459 1 928416 A G 0.1363 0.0113 0.0142 0.423300 191764 --+- 1960010 2 1:933045:C:T rs189213898 1 933045 T C 0.0087 0.0008 0.0704 0.991500 166718 -?+- 1960010 3 1:1019158:G:A rs142369888 1 1019158 A G 0.0110 0.1189 0.0613 0.052510 166718 +?++ 1960010 4 1:1023310:T:C rs11260589 1 1023310 C T 0.0854 0.0202 0.0182 0.265600 191764 +++- 1960000 ... ... ... ... ... ... ... ... ... ... ... ... ... ... 99995 X:153882706:C:T rs3829775 23 153882706 T C 0.0125 -0.0017 0.0526 0.973600 166718 +?-- 1960010 99996 X:154087726:C:T rs112922881 23 154087726 T C 0.0743 0.0414 0.0151 0.006171 191764 +-+- 1960010 99997 X:154126990:T:C rs28370221 23 154126990 C T 0.0763 -0.0085 0.0132 0.519500 191764 +--- 1960000 99998 X:154140146:T:G rs28895719 23 154140146 G T 0.1707 0.0043 0.0096 0.652700 191764 +-+- 1960000 99999 X:154278797:T:C rs114209171 23 154278797 C T 0.1738 0.0025 0.0091 0.785500 191764 +-+- 1960000 <p>100000 rows \u00d7 13 columns</p> <p>Check the summary of the currrent sumstats (see: https://cloufield.github.io/gwaslab/StatusCode/):</p> In\u00a0[27]: Copied! <pre>mysumstats.summary()\n</pre> mysumstats.summary() Out[27]: Values Percentage Category Items META Row_num 100000 NaN Column_num 13 NaN Column_names SNPID,rsID,CHR,POS,EA,NEA,EAF,BETA,SE,P,N,DIRE... NaN Last_checked_time Tue Apr 25 15:18:49 2023 NaN MISSING Missing_total 122 0.12 Missing_rsID 122 0.12 MAF Common 50983 50.98 Low_frequency 16809 16.81 Rare 32157 32.16 P Minimum 1.1900000000000001e-77 0.00 Significant 86 0.09 Suggestive 166 0.17 STATUS 1960010 42815 42.82 1960000 33835 33.84 1960001 6329 6.33 1960011 6237 6.24 1960364 4484 4.48 1960363 3659 3.66 1960007 621 0.62 1960017 616 0.62 1960309 563 0.56 1960368 274 0.27 1960319 196 0.20 1960018 181 0.18 1960008 173 0.17 1960012 10 0.01 1960002 7 0.01 <p>Check the details of harmonization results <code>.lookup_status()</code></p> In\u00a0[28]: Copied! <pre>mysumstats.lookup_status()\n</pre> mysumstats.lookup_status() Out[28]: Genome_Build rsID&amp;SNPID CHR&amp;POS Stadardize&amp;Normalize Align Panlidromic_SNP&amp;Indel Count Percentage(%) 1960000 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Match: NEA=REF Not_palindromic_SNPs 33835 33.84 1960001 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Match: NEA=REF Palindromic+strand 6329 6.33 1960002 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Match: NEA=REF Palindromic-strand_fixed 7 0.01 1960007 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Match: NEA=REF Indistinguishable 621 0.62 1960008 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Match: NEA=REF No_matching_or_no_info 173 0.17 1960010 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Flipped_fixed Not_palindromic_SNPs 42815 42.82 1960011 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Flipped_fixed Palindromic+strand 6237 6.24 1960012 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Flipped_fixed Palindromic-strand_fixed 10 0.01 1960017 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Flipped_fixed Indistinguishable 616 0.62 1960018 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized SNP Flipped_fixed No_matching_or_no_info 181 0.18 1960309 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized &amp; normalized indel Match: NEA=REF Unchecked 563 0.56 1960319 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized &amp; normalized indel Flipped_fixed Unchecked 196 0.2 1960363 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized &amp; normalized indel Both_alleles_on_ref+indistinguishable Indel_match 3659 3.66 1960364 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized &amp; normalized indel Both_alleles_on_ref+indistinguishable Indel_flipped_fixed 4484 4.48 1960368 hg19 rsid unknown &amp; SNPID valid CHR valid &amp; POS valid standardized &amp; normalized indel Both_alleles_on_ref+indistinguishable No_matching_or_no_info 274 0.27 <p>You can easily format the processed sumstats and save it. For details, see: https://cloufield.github.io/gwaslab/Format/</p> <p>Let's export the sumstats as the default format used in LDSC.</p> In\u00a0[29]: Copied! <pre>mysumstats.to_format(\"clean_sumstats\",fmt=\"ldsc\")\n</pre> mysumstats.to_format(\"clean_sumstats\",fmt=\"ldsc\") <pre>Tue Apr 25 15:18:50 2023 Start to format the output sumstats in:  ldsc  format\nTue Apr 25 15:18:50 2023  -Formatting statistics ...\nTue Apr 25 15:18:50 2023  - Float statistics formats:\nTue Apr 25 15:18:50 2023   - Columns: ['EAF', 'BETA', 'SE', 'P']\nTue Apr 25 15:18:50 2023   - Output formats: ['{:.4g}', '{:.4f}', '{:.4f}', '{:.4e}']\nTue Apr 25 15:18:50 2023  - Start outputting sumstats in ldsc format...\nTue Apr 25 15:18:50 2023  -ldsc format will be loaded...\nTue Apr 25 15:18:50 2023  -ldsc format meta info:\nTue Apr 25 15:18:50 2023   - format_name  :  ldsc\nTue Apr 25 15:18:50 2023   - format_source  :  https://github.com/bulik/ldsc/wiki/Summary-Statistics-File-Format\nTue Apr 25 15:18:50 2023   - format_source2  :  https://github.com/bulik/ldsc/blob/master/munge_sumstats.py\nTue Apr 25 15:18:50 2023   - format_version  :  20150306\nTue Apr 25 15:18:50 2023  -gwaslab to ldsc format dictionary:\nTue Apr 25 15:18:50 2023   - gwaslab keys: rsID,NEA,EA,EAF,N,BETA,P,Z,INFO,OR,CHR,POS\nTue Apr 25 15:18:50 2023   - ldsc values: SNP,A2,A1,Frq,N,Beta,P,Z,INFO,OR,CHR,POS\nTue Apr 25 15:18:50 2023  -Output columns: SNP,CHR,POS,A1,A2,Frq,Beta,P,N\nTue Apr 25 15:18:50 2023  -Output path: clean_sumstats.ldsc.tsv.gz\nTue Apr 25 15:18:51 2023  -Saving log file: clean_sumstats.ldsc.log\nTue Apr 25 15:18:51 2023 Finished outputting successfully!\n</pre> <p>Sometimes we only need to export part of the sumstats. For example,</p> <ul> <li>we can specify <code>hapmap3=True</code> to export only hapmap3 variants; </li> <li>specify <code>exclude_hla=True</code> to exclude variants in HLA region when exporting; </li> <li>specify <code>md5sum=True</code> to calculate the md5sum value for the exported sumstats.</li> </ul> In\u00a0[30]: Copied! <pre>mysumstats.to_format(\"clean_sumstats\",fmt=\"ldsc\",hapmap3=True,exclude_hla=True,md5sum=True)\n</pre> mysumstats.to_format(\"clean_sumstats\",fmt=\"ldsc\",hapmap3=True,exclude_hla=True,md5sum=True) <pre>Tue Apr 25 15:18:51 2023 Start to format the output sumstats in:  ldsc  format\nTue Apr 25 15:18:51 2023  -Excluding variants in HLA region ...\nTue Apr 25 15:18:51 2023  -Exclude 609 variants in HLA region.\nTue Apr 25 15:18:51 2023  -Processing 99391 raw variants...\nTue Apr 25 15:18:51 2023  -Loading Hapmap3 variants data...\nTue Apr 25 15:18:52 2023  -Extract 8644 variants in Hapmap3 datasets for build 19.\nTue Apr 25 15:18:52 2023  -Formatting statistics ...\nTue Apr 25 15:18:52 2023  - Float statistics formats:\nTue Apr 25 15:18:52 2023   - Columns: ['EAF', 'BETA', 'SE', 'P']\nTue Apr 25 15:18:52 2023   - Output formats: ['{:.4g}', '{:.4f}', '{:.4f}', '{:.4e}']\nTue Apr 25 15:18:52 2023  - Start outputting sumstats in ldsc format...\nTue Apr 25 15:18:52 2023  -ldsc format will be loaded...\nTue Apr 25 15:18:52 2023  -ldsc format meta info:\nTue Apr 25 15:18:52 2023   - format_name  :  ldsc\nTue Apr 25 15:18:52 2023   - format_source  :  https://github.com/bulik/ldsc/wiki/Summary-Statistics-File-Format\nTue Apr 25 15:18:52 2023   - format_source2  :  https://github.com/bulik/ldsc/blob/master/munge_sumstats.py\nTue Apr 25 15:18:52 2023   - format_version  :  20150306\nTue Apr 25 15:18:52 2023  -gwaslab to ldsc format dictionary:\nTue Apr 25 15:18:52 2023   - gwaslab keys: rsID,NEA,EA,EAF,N,BETA,P,Z,INFO,OR,CHR,POS\nTue Apr 25 15:18:52 2023   - ldsc values: SNP,A2,A1,Frq,N,Beta,P,Z,INFO,OR,CHR,POS\nTue Apr 25 15:18:52 2023  -Output columns: SNP,CHR,POS,A1,A2,Frq,Beta,P,N\nTue Apr 25 15:18:52 2023  -Output path: clean_sumstats.hapmap3.noMHC.ldsc.tsv.gz\nTue Apr 25 15:18:52 2023  -md5sum hashing for the file: clean_sumstats.hapmap3.noMHC.ldsc.tsv.gz\nTue Apr 25 15:18:52 2023  -md5sum path: clean_sumstats.hapmap3.noMHC.ldsc.tsv.gz.md5sum\nTue Apr 25 15:18:52 2023  -Saving log file: clean_sumstats.hapmap3.noMHC.ldsc.log\nTue Apr 25 15:18:52 2023 Finished outputting successfully!\n</pre> <p>Output in GWAS-SSF format</p> In\u00a0[31]: Copied! <pre>mysumstats.to_format(\"clean_sumstats\",fmt=\"ssf\",md5sum=True)\n</pre> mysumstats.to_format(\"clean_sumstats\",fmt=\"ssf\",md5sum=True) <pre>Thu Apr 27 11:45:41 2023 Start to format the output sumstats in:  ssf  format\nThu Apr 27 11:45:41 2023  -Formatting statistics ...\nThu Apr 27 11:45:52 2023  - Float statistics formats:\nThu Apr 27 11:45:52 2023   - Columns: ['EAF', 'BETA', 'SE', 'P']\nThu Apr 27 11:45:52 2023   - Output formats: ['{:.4g}', '{:.4f}', '{:.4f}', '{:.4e}']\nThu Apr 27 11:45:52 2023  - Replacing separator from \":\" to \"_\"...\nThu Apr 27 11:45:54 2023  - Start outputting sumstats in ssf format...\nThu Apr 27 11:45:55 2023  -ssf format will be loaded...\nThu Apr 27 11:45:55 2023  -ssf format meta info:\nThu Apr 27 11:45:55 2023   - format_name  :  ssf\nThu Apr 27 11:45:55 2023   - format_source  :  https://www.biorxiv.org/content/10.1101/2022.07.15.500230v1.full\nThu Apr 27 11:45:55 2023   - format_version  :  20220726\nThu Apr 27 11:45:55 2023  -gwaslab to ssf format dictionary:\nThu Apr 27 11:45:55 2023   - gwaslab keys: SNPID,rsID,CHR,POS,NEA,EA,N,BETA,SE,P,INFO,OR,OR_95L,OR_95U\nThu Apr 27 11:45:55 2023   - ssf values: variant_id,rsid,chromosome,base_pair_location,other_allele,effect_allele,n,beta,standard_error,p_value,info,odds_ratio,ci_lower,ci_upper\nThu Apr 27 11:45:57 2023  -Output columns: variant_id,chromosome,base_pair_location,effect_allele,other_allele,beta,standard_error,p_value,n\nThu Apr 27 11:45:57 2023  -Output path: clean_sumstats.ssf.tsv.gz\nThu Apr 27 11:47:35 2023  -md5sum hashing for the file: clean_sumstats.ssf.tsv.gz\nThu Apr 27 11:47:35 2023  -md5sum path: clean_sumstats.ssf.tsv.gz.md5sum\nThu Apr 27 11:47:35 2023  -Saving log file: clean_sumstats.ssf.log\nThu Apr 27 11:47:35 2023 Finished outputting successfully!\n</pre> <p>gwaslab can perform liftover for base pair positions.</p> <p>Note: GWASLab only liftover CHR and POS, and when lifted, the last two digits status code will be rolled back to 99. Since for different reference genome, the reference allele or strand might be reverse, so it is needed to harmonize again after liftover.</p> In\u00a0[31]: Copied! <pre>mysumstats.liftover(n_cores=1, from_build=\"19\", to_build=\"38\")\n</pre> mysumstats.liftover(n_cores=1, from_build=\"19\", to_build=\"38\") <pre>Tue Apr 25 15:18:52 2023 Start to perform liftover...\nTue Apr 25 15:18:52 2023  -Current Dataframe shape : 100000  x  13\nTue Apr 25 15:18:52 2023  -CPU Cores to use : 1\nTue Apr 25 15:18:52 2023  -Performing liftover ...\nTue Apr 25 15:18:52 2023  -Creating converter : hg19 to hg38\nTue Apr 25 15:18:53 2023  -Converting variants with status code xxx0xxx :100000...\nTue Apr 25 15:19:12 2023  -Removed unmapped variants: 57\nTue Apr 25 15:19:13 2023 Finished liftover successfully!\n</pre> In\u00a0[32]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[32]: SNPID rsID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS 0 1:875643:C:G rs7411115 1 940263 G C 0.7290 0.0147 0.0130 0.258600 166718 +?+- 3860099 1 1:928416:G:A rs111754459 1 993036 A G 0.1363 0.0113 0.0142 0.423300 191764 --+- 3860099 2 1:933045:C:T rs189213898 1 997665 T C 0.0087 0.0008 0.0704 0.991500 166718 -?+- 3860099 3 1:1019158:G:A rs142369888 1 1083778 A G 0.0110 0.1189 0.0613 0.052510 166718 +?++ 3860099 4 1:1023310:T:C rs11260589 1 1087930 C T 0.0854 0.0202 0.0182 0.265600 191764 +++- 3860099 ... ... ... ... ... ... ... ... ... ... ... ... ... ... 99995 X:153882706:C:T rs3829775 23 154654432 T C 0.0125 -0.0017 0.0526 0.973600 166718 +?-- 3860099 99996 X:154087726:C:T rs112922881 23 154859451 T C 0.0743 0.0414 0.0151 0.006171 191764 +-+- 3860099 99997 X:154126990:T:C rs28370221 23 154898715 C T 0.0763 -0.0085 0.0132 0.519500 191764 +--- 3860099 99998 X:154140146:T:G rs28895719 23 154911871 G T 0.1707 0.0043 0.0096 0.652700 191764 +-+- 3860099 99999 X:154278797:T:C rs114209171 23 155050522 C T 0.1738 0.0025 0.0091 0.785500 191764 +-+- 3860099 <p>99943 rows \u00d7 13 columns</p> <p>For details, see https://cloufield.github.io/gwaslab/LiftOver/</p>"},{"location":"tutorial_3.4/#tutorial-for-gwaslab","title":"Tutorial for gwaslab\u00b6","text":""},{"location":"tutorial_3.4/#download-sample-data","title":"Download sample data\u00b6","text":""},{"location":"tutorial_3.4/#import-gwaslab-package","title":"Import gwaslab package\u00b6","text":""},{"location":"tutorial_3.4/#loading-data-into-gwaslab-sumstats","title":"Loading data into gwaslab Sumstats\u00b6","text":""},{"location":"tutorial_3.4/#create-manhattan-plots-and-q-q-plots","title":"Create Manhattan plots and Q-Q plots\u00b6","text":""},{"location":"tutorial_3.4/#standardization-qc-basic_check","title":"Standardization &amp; QC : <code>.basic_check()</code>\u00b6","text":""},{"location":"tutorial_3.4/#extract-lead-variants-get_lead","title":"Extract lead variants : get_lead()\u00b6","text":""},{"location":"tutorial_3.4/#use-the-snpid-to-create-some-highly-customized-mqq-plot","title":"Use the SNPID to create some highly customized mqq plot\u00b6","text":""},{"location":"tutorial_3.4/#quick-regional-plot-without-ld-information","title":"Quick regional plot without LD-information\u00b6","text":""},{"location":"tutorial_3.4/#reference-file-downloading","title":"Reference file downloading\u00b6","text":""},{"location":"tutorial_3.4/#check-available-reference-from-gwaslab","title":"check available reference from gwaslab\u00b6","text":""},{"location":"tutorial_3.4/#download-reference-using-gwaslab","title":"download reference using gwaslab\u00b6","text":""},{"location":"tutorial_3.4/#sampling","title":"Sampling\u00b6","text":""},{"location":"tutorial_3.4/#infer-genome-build","title":"Infer genome build\u00b6","text":""},{"location":"tutorial_3.4/#fix-snpid","title":"Fix SNPID\u00b6","text":""},{"location":"tutorial_3.4/#annotate-rsid","title":"Annotate rsID\u00b6","text":""},{"location":"tutorial_3.4/#maximize-the-annotation","title":"Maximize the annotation\u00b6","text":""},{"location":"tutorial_3.4/#harmonization","title":"Harmonization\u00b6","text":""},{"location":"tutorial_3.4/#sumstats-summary","title":"Sumstats Summary\u00b6","text":""},{"location":"tutorial_3.4/#formatting-and-saving-to_format","title":"Formatting and saving : to_format()\u00b6","text":""},{"location":"tutorial_3.4/#liftover","title":"Liftover\u00b6","text":""},{"location":"utility_data_conversion/","title":"Data conversion","text":"In\u00a0[1]: Copied! <pre>import gwaslab as gl\n</pre> import gwaslab as gl In\u00a0[2]: Copied! <pre>mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNP\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             ea=\"ALT\",\n             nea=\"REF\",\n             neaf=\"Frq\",\n             beta=\"BETA\",\n             se=\"SE\",nrows=5,verbose=False)\nmysumstats.basic_check(verbose=False)\nmysumstats.data\n</pre> mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",              snpid=\"SNP\",              chrom=\"CHR\",              pos=\"POS\",              ea=\"ALT\",              nea=\"REF\",              neaf=\"Frq\",              beta=\"BETA\",              se=\"SE\",nrows=5,verbose=False) mysumstats.basic_check(verbose=False) mysumstats.data Out[2]: SNPID CHR POS EA NEA EAF BETA SE STATUS 0 1:725932_G_A 1 725932 G A 0.9960 -0.0737 0.1394 9960099 1 1:725933_A_G 1 725933 G A 0.0040 0.0737 0.1394 9960099 2 1:737801_T_C 1 737801 C T 0.0051 0.0490 0.1231 9960099 3 1:749963_T_TAA 1 749963 TAA T 0.8374 0.0213 0.0199 9960399 4 1:751343_T_A 1 751343 T A 0.8593 0.0172 0.0156 9960099 In\u00a0[3]: Copied! <pre>mysumstats.fill_data(to_fill=[\"OR\"])\n</pre> mysumstats.fill_data(to_fill=[\"OR\"]) <pre>Sat Feb  3 00:27:49 2024 Start filling data using existing columns...v3.4.38\nSat Feb  3 00:27:49 2024  -Column  : SNPID  CHR   POS   EA       NEA      EAF     BETA    SE      STATUS  \nSat Feb  3 00:27:49 2024  -DType   : string Int64 Int64 category category float32 float64 float64 category\nSat Feb  3 00:27:49 2024  -Verified: T      T     T     T        T        T       T       T       T       \nSat Feb  3 00:27:49 2024  -Overwrite mode:  False\nSat Feb  3 00:27:49 2024   -Skipping columns:  []\nSat Feb  3 00:27:49 2024  -Filling columns:  ['OR']\nSat Feb  3 00:27:49 2024   - Filling Columns iteratively...\nSat Feb  3 00:27:49 2024   - Filling OR using BETA column...\nSat Feb  3 00:27:49 2024   - Filling OR_95L/OR_95U using BETA/SE columns...\nSat Feb  3 00:27:49 2024 Finished filling data using existing columns.\nSat Feb  3 00:27:49 2024 Start to reorder the columns...v3.4.38\nSat Feb  3 00:27:49 2024  -Current Dataframe shape : 5 x 12 ; Memory usage: 19.94 MB\nSat Feb  3 00:27:49 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,OR,OR_95L,OR_95U,STATUS\nSat Feb  3 00:27:49 2024 Finished reordering the columns.\n</pre> In\u00a0[4]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[4]: SNPID CHR POS EA NEA EAF BETA SE OR OR_95L OR_95U STATUS 0 1:725932_G_A 1 725932 G A 0.9960 -0.0737 0.1394 0.928950 0.706863 1.220815 9960099 1 1:725933_A_G 1 725933 G A 0.0040 0.0737 0.1394 1.076484 0.819125 1.414702 9960099 2 1:737801_T_C 1 737801 C T 0.0051 0.0490 0.1231 1.050220 0.825083 1.336790 9960099 3 1:749963_T_TAA 1 749963 TAA T 0.8374 0.0213 0.0199 1.021528 0.982452 1.062159 9960399 4 1:751343_T_A 1 751343 T A 0.8593 0.0172 0.0156 1.017349 0.986714 1.048935 9960099 In\u00a0[5]: Copied! <pre>mysumstats.data.drop(labels=[\"BETA\",\"SE\"],axis=1,inplace=True)\n</pre> mysumstats.data.drop(labels=[\"BETA\",\"SE\"],axis=1,inplace=True) In\u00a0[6]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[6]: SNPID CHR POS EA NEA EAF OR OR_95L OR_95U STATUS 0 1:725932_G_A 1 725932 G A 0.9960 0.928950 0.706863 1.220815 9960099 1 1:725933_A_G 1 725933 G A 0.0040 1.076484 0.819125 1.414702 9960099 2 1:737801_T_C 1 737801 C T 0.0051 1.050220 0.825083 1.336790 9960099 3 1:749963_T_TAA 1 749963 TAA T 0.8374 1.021528 0.982452 1.062159 9960399 4 1:751343_T_A 1 751343 T A 0.8593 1.017349 0.986714 1.048935 9960099 In\u00a0[7]: Copied! <pre>mysumstats.fill_data(to_fill=[\"BETA\",\"SE\"])\n</pre> mysumstats.fill_data(to_fill=[\"BETA\",\"SE\"]) <pre>Sat Feb  3 00:27:49 2024 Start filling data using existing columns...v3.4.38\nSat Feb  3 00:27:49 2024  -Column  : SNPID  CHR   POS   EA       NEA      EAF     OR      OR_95L  OR_95U  STATUS  \nSat Feb  3 00:27:49 2024  -DType   : string Int64 Int64 category category float32 float64 float64 float64 category\nSat Feb  3 00:27:49 2024  -Verified: T      T     T     T        T        T       T       T       T       T       \nSat Feb  3 00:27:49 2024  -Overwrite mode:  False\nSat Feb  3 00:27:49 2024   -Skipping columns:  []\nSat Feb  3 00:27:49 2024  -Filling columns:  ['BETA', 'SE']\nSat Feb  3 00:27:49 2024   - Filling Columns iteratively...\nSat Feb  3 00:27:49 2024   - Filling BETA value using OR column...\nSat Feb  3 00:27:49 2024   - Filling SE value using OR/OR_95U column...\nSat Feb  3 00:27:49 2024 Finished filling data using existing columns.\nSat Feb  3 00:27:49 2024 Start to reorder the columns...v3.4.38\nSat Feb  3 00:27:49 2024  -Current Dataframe shape : 5 x 12 ; Memory usage: 19.94 MB\nSat Feb  3 00:27:49 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,OR,OR_95L,OR_95U,STATUS\nSat Feb  3 00:27:49 2024 Finished reordering the columns.\n</pre> In\u00a0[8]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[8]: SNPID CHR POS EA NEA EAF BETA SE OR OR_95L OR_95U STATUS 0 1:725932_G_A 1 725932 G A 0.9960 -0.0737 0.1394 0.928950 0.706863 1.220815 9960099 1 1:725933_A_G 1 725933 G A 0.0040 0.0737 0.1394 1.076484 0.819125 1.414702 9960099 2 1:737801_T_C 1 737801 C T 0.0051 0.0490 0.1231 1.050220 0.825083 1.336790 9960099 3 1:749963_T_TAA 1 749963 TAA T 0.8374 0.0213 0.0199 1.021528 0.982452 1.062159 9960399 4 1:751343_T_A 1 751343 T A 0.8593 0.0172 0.0156 1.017349 0.986714 1.048935 9960099 In\u00a0[9]: Copied! <pre>mysumstats.fill_data(to_fill=[\"Z\"])\n</pre> mysumstats.fill_data(to_fill=[\"Z\"]) <pre>Sat Feb  3 00:27:49 2024 Start filling data using existing columns...v3.4.38\nSat Feb  3 00:27:49 2024  -Column  : SNPID  CHR   POS   EA       NEA      EAF     BETA    SE      OR      OR_95L  OR_95U  STATUS  \nSat Feb  3 00:27:49 2024  -DType   : string Int64 Int64 category category float32 float64 float64 float64 float64 float64 category\nSat Feb  3 00:27:49 2024  -Verified: T      T     T     T        T        T       T       T       T       T       T       T       \nSat Feb  3 00:27:49 2024  -Overwrite mode:  False\nSat Feb  3 00:27:49 2024   -Skipping columns:  []\nSat Feb  3 00:27:49 2024  -Filling columns:  ['Z']\nSat Feb  3 00:27:49 2024   - Filling Columns iteratively...\nSat Feb  3 00:27:49 2024   - Filling Z using BETA/SE column...\nSat Feb  3 00:27:49 2024 Finished filling data using existing columns.\nSat Feb  3 00:27:49 2024 Start to reorder the columns...v3.4.38\nSat Feb  3 00:27:49 2024  -Current Dataframe shape : 5 x 13 ; Memory usage: 19.94 MB\nSat Feb  3 00:27:49 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,Z,OR,OR_95L,OR_95U,STATUS\nSat Feb  3 00:27:49 2024 Finished reordering the columns.\n</pre> In\u00a0[10]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[10]: SNPID CHR POS EA NEA EAF BETA SE Z OR OR_95L OR_95U STATUS 0 1:725932_G_A 1 725932 G A 0.9960 -0.0737 0.1394 -0.528694 0.928950 0.706863 1.220815 9960099 1 1:725933_A_G 1 725933 G A 0.0040 0.0737 0.1394 0.528694 1.076484 0.819125 1.414702 9960099 2 1:737801_T_C 1 737801 C T 0.0051 0.0490 0.1231 0.398050 1.050220 0.825083 1.336790 9960099 3 1:749963_T_TAA 1 749963 TAA T 0.8374 0.0213 0.0199 1.070352 1.021528 0.982452 1.062159 9960399 4 1:751343_T_A 1 751343 T A 0.8593 0.0172 0.0156 1.102564 1.017349 0.986714 1.048935 9960099 In\u00a0[11]: Copied! <pre>mysumstats.fill_data(to_fill=[\"MLOG10P\"])\n</pre> mysumstats.fill_data(to_fill=[\"MLOG10P\"]) <pre>Sat Feb  3 00:27:50 2024 Start filling data using existing columns...v3.4.38\nSat Feb  3 00:27:50 2024  -Column  : SNPID  CHR   POS   EA       NEA      EAF     BETA    SE      Z       OR      OR_95L  OR_95U  STATUS  \nSat Feb  3 00:27:50 2024  -DType   : string Int64 Int64 category category float32 float64 float64 float64 float64 float64 float64 category\nSat Feb  3 00:27:50 2024  -Verified: T      T     T     T        T        T       T       T       T       T       T       T       T       \nSat Feb  3 00:27:50 2024  -Overwrite mode:  False\nSat Feb  3 00:27:50 2024   -Skipping columns:  []\nSat Feb  3 00:27:50 2024  -Filling columns:  ['MLOG10P']\nSat Feb  3 00:27:50 2024   - Filling Columns iteratively...\nSat Feb  3 00:27:50 2024   - Filling P value using Z column...\nSat Feb  3 00:27:50 2024   - Filling MLOG10P using P column...\nSat Feb  3 00:27:50 2024 Finished filling data using existing columns.\nSat Feb  3 00:27:50 2024 Start to reorder the columns...v3.4.38\nSat Feb  3 00:27:50 2024  -Current Dataframe shape : 5 x 15 ; Memory usage: 19.94 MB\nSat Feb  3 00:27:50 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,Z,P,MLOG10P,OR,OR_95L,OR_95U,STATUS\nSat Feb  3 00:27:50 2024 Finished reordering the columns.\n</pre> In\u00a0[12]: Copied! <pre>mysumstats.fill_data(to_fill=[\"P\"])\n</pre> mysumstats.fill_data(to_fill=[\"P\"]) <pre>Sat Feb  3 00:27:50 2024 Start filling data using existing columns...v3.4.38\nSat Feb  3 00:27:50 2024  -Column  : SNPID  CHR   POS   EA       NEA      EAF     BETA    SE      Z       P       MLOG10P OR      OR_95L  OR_95U  STATUS  \nSat Feb  3 00:27:50 2024  -DType   : string Int64 Int64 category category float32 float64 float64 float64 float64 float64 float64 float64 float64 category\nSat Feb  3 00:27:50 2024  -Verified: T      T     T     T        T        T       T       T       T       T       T       T       T       T       T       \nSat Feb  3 00:27:50 2024  -Overwrite mode:  False\nSat Feb  3 00:27:50 2024   -Skipping columns:  ['P']\nSat Feb  3 00:27:50 2024  -No available columns to fill. Skipping.\nSat Feb  3 00:27:50 2024 Finished filling data using existing columns.\nSat Feb  3 00:27:50 2024 Start to reorder the columns...v3.4.38\nSat Feb  3 00:27:50 2024  -Current Dataframe shape : 5 x 15 ; Memory usage: 19.94 MB\nSat Feb  3 00:27:50 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,Z,P,MLOG10P,OR,OR_95L,OR_95U,STATUS\nSat Feb  3 00:27:50 2024 Finished reordering the columns.\n</pre> In\u00a0[13]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[13]: SNPID CHR POS EA NEA EAF BETA SE Z P MLOG10P OR OR_95L OR_95U STATUS 0 1:725932_G_A 1 725932 G A 0.9960 -0.0737 0.1394 -0.528694 0.597017 0.224013 0.928950 0.706863 1.220815 9960099 1 1:725933_A_G 1 725933 G A 0.0040 0.0737 0.1394 0.528694 0.597017 0.224013 1.076484 0.819125 1.414702 9960099 2 1:737801_T_C 1 737801 C T 0.0051 0.0490 0.1231 0.398050 0.690593 0.160778 1.050220 0.825083 1.336790 9960099 3 1:749963_T_TAA 1 749963 TAA T 0.8374 0.0213 0.0199 1.070352 0.284461 0.545977 1.021528 0.982452 1.062159 9960399 4 1:751343_T_A 1 751343 T A 0.8593 0.0172 0.0156 1.102564 0.270217 0.568288 1.017349 0.986714 1.048935 9960099 In\u00a0[14]: Copied! <pre>mysumstats.fill_data(to_fill=[\"MAF\"])\n</pre> mysumstats.fill_data(to_fill=[\"MAF\"]) <pre>Sat Feb  3 00:27:50 2024 Start filling data using existing columns...v3.4.38\nSat Feb  3 00:27:50 2024  -Column  : SNPID  CHR   POS   EA       NEA      EAF     BETA    SE      Z       P       MLOG10P OR      OR_95L  OR_95U  STATUS  \nSat Feb  3 00:27:50 2024  -DType   : string Int64 Int64 category category float32 float64 float64 float64 float64 float64 float64 float64 float64 category\nSat Feb  3 00:27:50 2024  -Verified: T      T     T     T        T        T       T       T       T       T       T       T       T       T       T       \nSat Feb  3 00:27:50 2024  -Overwrite mode:  False\nSat Feb  3 00:27:50 2024   -Skipping columns:  []\nSat Feb  3 00:27:50 2024  -Filling columns:  ['MAF']\nSat Feb  3 00:27:50 2024   - Filling Columns iteratively...\nSat Feb  3 00:27:50 2024   - Filling MAF using EAF column...\nSat Feb  3 00:27:50 2024 Finished filling data using existing columns.\nSat Feb  3 00:27:50 2024 Start to reorder the columns...v3.4.38\nSat Feb  3 00:27:50 2024  -Current Dataframe shape : 5 x 16 ; Memory usage: 19.94 MB\nSat Feb  3 00:27:50 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,MAF,BETA,SE,Z,P,MLOG10P,OR,OR_95L,OR_95U,STATUS\nSat Feb  3 00:27:50 2024 Finished reordering the columns.\n</pre> In\u00a0[15]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[15]: SNPID CHR POS EA NEA EAF MAF BETA SE Z P MLOG10P OR OR_95L OR_95U STATUS 0 1:725932_G_A 1 725932 G A 0.9960 0.0040 -0.0737 0.1394 -0.528694 0.597017 0.224013 0.928950 0.706863 1.220815 9960099 1 1:725933_A_G 1 725933 G A 0.0040 0.0040 0.0737 0.1394 0.528694 0.597017 0.224013 1.076484 0.819125 1.414702 9960099 2 1:737801_T_C 1 737801 C T 0.0051 0.0051 0.0490 0.1231 0.398050 0.690593 0.160778 1.050220 0.825083 1.336790 9960099 3 1:749963_T_TAA 1 749963 TAA T 0.8374 0.1626 0.0213 0.0199 1.070352 0.284461 0.545977 1.021528 0.982452 1.062159 9960399 4 1:751343_T_A 1 751343 T A 0.8593 0.1407 0.0172 0.0156 1.102564 0.270217 0.568288 1.017349 0.986714 1.048935 9960099 In\u00a0[16]: Copied! <pre>mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNP\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             beta=\"BETA\",\n             se=\"SE\",nrows=5, verbose=False)\n# simulate some extreme P values by shrinking the SE\nmysumstats.data[\"SE\"] = mysumstats.data[\"SE\"]/100\nmysumstats.data\n</pre> mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",              snpid=\"SNP\",              chrom=\"CHR\",              pos=\"POS\",              beta=\"BETA\",              se=\"SE\",nrows=5, verbose=False) # simulate some extreme P values by shrinking the SE mysumstats.data[\"SE\"] = mysumstats.data[\"SE\"]/100 mysumstats.data Out[16]: SNPID CHR POS BETA SE STATUS 0 1:725932_G_A 1 725932 -0.0737 0.001394 9999999 1 1:725933_A_G 1 725933 0.0737 0.001394 9999999 2 1:737801_T_C 1 737801 0.0490 0.001231 9999999 3 1:749963_T_TAA 1 749963 0.0213 0.000199 9999999 4 1:751343_T_A 1 751343 0.0172 0.000156 9999999 <p>For P &lt; 1e-308, they become 0 due to limnited precision of float64</p> In\u00a0[17]: Copied! <pre>mysumstats.fill_data(to_fill=[\"Z\",\"P\"])\n</pre> mysumstats.fill_data(to_fill=[\"Z\",\"P\"]) <pre>Sat Feb  3 00:27:50 2024 Start filling data using existing columns...v3.4.38\nSat Feb  3 00:27:50 2024  -Column  : SNPID  CHR    POS   BETA    SE      STATUS  \nSat Feb  3 00:27:50 2024  -DType   : object string int64 float64 float64 category\nSat Feb  3 00:27:50 2024  -Verified: T      F      T     T       T       T       \nSat Feb  3 00:27:50 2024  #WARNING! Columns with possibly incompatable dtypes: CHR\nSat Feb  3 00:27:50 2024  -Overwrite mode:  False\nSat Feb  3 00:27:50 2024   -Skipping columns:  []\nSat Feb  3 00:27:50 2024  -Filling columns:  ['Z', 'P']\nSat Feb  3 00:27:50 2024   - Filling Columns iteratively...\nSat Feb  3 00:27:50 2024   - Filling Z using BETA/SE column...\nSat Feb  3 00:27:50 2024   - Filling P value using Z column...\nSat Feb  3 00:27:50 2024 Finished filling data using existing columns.\nSat Feb  3 00:27:50 2024 Start to reorder the columns...v3.4.38\nSat Feb  3 00:27:50 2024  -Current Dataframe shape : 5 x 8 ; Memory usage: 19.94 MB\nSat Feb  3 00:27:50 2024  -Reordering columns to    : SNPID,CHR,POS,BETA,SE,Z,P,STATUS\nSat Feb  3 00:27:50 2024 Finished reordering the columns.\n</pre> In\u00a0[18]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[18]: SNPID CHR POS BETA SE Z P STATUS 0 1:725932_G_A 1 725932 -0.0737 0.001394 -52.869440 0.0 9999999 1 1:725933_A_G 1 725933 0.0737 0.001394 52.869440 0.0 9999999 2 1:737801_T_C 1 737801 0.0490 0.001231 39.805037 0.0 9999999 3 1:749963_T_TAA 1 749963 0.0213 0.000199 107.035176 0.0 9999999 4 1:751343_T_A 1 751343 0.0172 0.000156 110.256410 0.0 9999999 In\u00a0[19]: Copied! <pre>mysumstats.fill_data(to_fill=[\"MLOG10P\"],extreme=True)\n</pre> mysumstats.fill_data(to_fill=[\"MLOG10P\"],extreme=True) <pre>Sat Feb  3 00:27:51 2024 Start filling data using existing columns...v3.4.38\nSat Feb  3 00:27:51 2024  -Column  : SNPID  CHR    POS   BETA    SE      Z       P       STATUS  \nSat Feb  3 00:27:51 2024  -DType   : object string int64 float64 float64 float64 float64 category\nSat Feb  3 00:27:51 2024  -Verified: T      F      T     T       T       T       T       T       \nSat Feb  3 00:27:51 2024  #WARNING! Columns with possibly incompatable dtypes: CHR\nSat Feb  3 00:27:51 2024  -Overwrite mode:  False\nSat Feb  3 00:27:51 2024   -Skipping columns:  []\nSat Feb  3 00:27:51 2024  -Filling columns:  ['MLOG10P']\nSat Feb  3 00:27:51 2024   - Filling Columns iteratively...\nSat Feb  3 00:27:51 2024   - Filling MLOG10P using Z column...\nSat Feb  3 00:27:51 2024 Finished filling data using existing columns.\nSat Feb  3 00:27:51 2024 Start to reorder the columns...v3.4.38\nSat Feb  3 00:27:51 2024  -Current Dataframe shape : 5 x 11 ; Memory usage: 19.94 MB\nSat Feb  3 00:27:51 2024  -Reordering columns to    : SNPID,CHR,POS,BETA,SE,Z,P,MLOG10P,STATUS,P_MANTISSA,P_EXPONENT\nSat Feb  3 00:27:51 2024 Finished reordering the columns.\n</pre> In\u00a0[20]: Copied! <pre>mysumstats.data\n</pre> mysumstats.data Out[20]: SNPID CHR POS BETA SE Z P MLOG10P STATUS P_MANTISSA P_EXPONENT 0 1:725932_G_A 1 725932 -0.0737 0.001394 -52.869440 0.0 608.786553 9999999 1.634734 -609.0 1 1:725933_A_G 1 725933 0.0737 0.001394 52.869440 0.0 608.786553 9999999 1.634734 -609.0 2 1:737801_T_C 1 737801 0.0490 0.001231 39.805037 0.0 345.755249 9999999 1.756915 -346.0 3 1:749963_T_TAA 1 749963 0.0213 0.000199 107.035176 0.0 2489.881261 9999999 1.314436 -2490.0 4 1:751343_T_A 1 751343 0.0172 0.000156 110.256410 0.0 2641.885723 9999999 1.300999 -2642.0"},{"location":"utility_data_conversion/#data-conversion","title":"Data conversion\u00b6","text":""},{"location":"utility_data_conversion/#loading-sample-data","title":"Loading sample data\u00b6","text":""},{"location":"utility_data_conversion/#beta-or","title":"BETA -&gt; OR\u00b6","text":""},{"location":"utility_data_conversion/#or-beta","title":"OR -&gt; BETA\u00b6","text":""},{"location":"utility_data_conversion/#betase-z","title":"BETA/SE -&gt; Z\u00b6","text":""},{"location":"utility_data_conversion/#p-mlog10p","title":"P -&gt; MLOG10P\u00b6","text":""},{"location":"utility_data_conversion/#mlog10p-p","title":"MLOG10P -&gt; P\u00b6","text":""},{"location":"utility_data_conversion/#eaf-maf","title":"EAF -&gt; MAF\u00b6","text":""},{"location":"utility_data_conversion/#simulation-of-extreme-p-values","title":"Simulation of extreme P values\u00b6","text":""},{"location":"utility_data_conversion/#limited-precision-of-float64","title":"Limited precision of float64\u00b6","text":""},{"location":"utility_data_conversion/#recalculate-mlog10p-with-extreme-p-value-mode","title":"Recalculate MLOG10P with extreme P value mode\u00b6","text":""},{"location":"visualization_miami2/","title":"Miami plot","text":"In\u00a0[\u00a0]: Copied! <pre>!wget -O bmi_male_bbj.txt.gz http://jenger.riken.jp/2analysisresult_qtl_download/\n!wget -O bmi_female_bbj.txt.gz http://jenger.riken.jp/4analysisresult_qtl_download/\n</pre> !wget -O bmi_male_bbj.txt.gz http://jenger.riken.jp/2analysisresult_qtl_download/ !wget -O bmi_female_bbj.txt.gz http://jenger.riken.jp/4analysisresult_qtl_download/ In\u00a0[1]: Copied! <pre>import sys \nsys.path.insert(0,\"/home/yunye/work/gwaslab/src\")\nimport gwaslab as gl\n</pre> import sys  sys.path.insert(0,\"/home/yunye/work/gwaslab/src\") import gwaslab as gl In\u00a0[2]: Copied! <pre>gl1 = gl.Sumstats(\"bbj_bmi_female.txt.gz\",fmt=\"gwaslab\",snpid=\"SNP\",ea=\"REF\",nea=\"ALT\",sep=\"\\t\",build=\"19\",verbose=False)\ngl2 = gl.Sumstats(\"bbj_bmi_male.txt.gz\",fmt=\"gwaslab\",snpid=\"SNP\",ea=\"REF\",nea=\"ALT\",sep=\"\\t\",build=\"19\",verbose=False)\n</pre> gl1 = gl.Sumstats(\"bbj_bmi_female.txt.gz\",fmt=\"gwaslab\",snpid=\"SNP\",ea=\"REF\",nea=\"ALT\",sep=\"\\t\",build=\"19\",verbose=False) gl2 = gl.Sumstats(\"bbj_bmi_male.txt.gz\",fmt=\"gwaslab\",snpid=\"SNP\",ea=\"REF\",nea=\"ALT\",sep=\"\\t\",build=\"19\",verbose=False) In\u00a0[3]: Copied! <pre>gl1.get_lead()\n</pre> gl1.get_lead() <pre>Fri Feb  2 18:01:59 2024 Start to extract lead variants...v3.4.38\nFri Feb  2 18:01:59 2024  -Current Dataframe shape : 5961600 x 9 ; Memory usage: 326.95 MB\nFri Feb  2 18:01:59 2024  -Processing 5961600 variants...\nFri Feb  2 18:01:59 2024  -Significance threshold : 5e-08\nFri Feb  2 18:01:59 2024  -Sliding window size: 500  kb\nFri Feb  2 18:02:02 2024  -Using P for extracting lead variants...\nFri Feb  2 18:02:02 2024  -Found 948 significant variants in total...\nFri Feb  2 18:02:02 2024  -Identified 20 lead variants!\nFri Feb  2 18:02:02 2024 Finished extracting lead variants.\n</pre> Out[3]: SNPID CHR POS EA NEA BETA SE P STATUS 5629059 rs860295 1 155767708 A G 0.04005 0.006973 9.221000e-09 1999999 3574382 rs532504 1 177878933 G A 0.06024 0.006294 1.062000e-21 1999999 5726357 rs939584 2 621558 C T 0.05446 0.008828 6.897000e-10 1999999 4443132 rs713586 2 25158008 T C 0.03073 0.005345 9.015000e-09 1999999 2166247 rs1846974 5 87969927 G A 0.02988 0.005307 1.808000e-08 1999999 2629989 rs261966 5 95849587 T C 0.03216 0.005361 1.991000e-09 1999999 32091 rs10061263 5 124289158 G C 0.02870 0.005244 4.443000e-08 1999999 3386429 rs4712523 6 20657564 A G -0.03863 0.005296 3.016000e-13 1999999 3108709 rs3798519 6 50788778 A C 0.03638 0.005857 5.218000e-10 1999999 958518 rs11981973 7 69445341 A G 0.03594 0.006569 4.460000e-08 1999999 265445 rs10811658 9 22128600 G A 0.03117 0.005283 3.613000e-09 1999999 2436673 rs2237897 11 2858546 C T 0.03657 0.005451 1.953000e-11 1999999 1777942 rs1491850 11 27749725 T C -0.04251 0.005376 2.635000e-15 1999999 5422141 rs7933262 11 28666538 C T -0.03033 0.005457 2.727000e-08 1999999 689872 rs11602339 11 47761471 C T 0.03414 0.005790 3.728000e-09 1999999 4952305 rs75766425 14 52511911 G C 0.05405 0.008145 3.222000e-11 1999999 718615 rs11642015 16 53802494 C T 0.07912 0.006551 1.375000e-33 1999999 5590983 rs8098510 18 40773435 A C -0.03211 0.005647 1.296000e-08 1999999 4126646 rs6567160 18 57829135 T C 0.05420 0.006344 1.299000e-17 1999999 3024448 rs35560038 19 46175046 A T -0.05872 0.005473 7.421000e-27 1999999 In\u00a0[5]: Copied! <pre>a = gl.plot_miami2(path1= gl1,\n                   path2= gl2)\n</pre> a = gl.plot_miami2(path1= gl1,                    path2= gl2) <pre>Fri Feb  2 18:02:48 2024 Start to create miami plot v3.4.38:\nFri Feb  2 18:02:48 2024  -Obtaining Sumstats1 CHR, POS, P and annotation from: ['CHR', 'POS', 'P']\nFri Feb  2 18:02:48 2024  -Loading Sumstats1 from gwaslab.Sumstats Object\nFri Feb  2 18:02:48 2024  -Obtaining Sumstats2 CHR, POS, P and annotation from: ['CHR', 'POS', 'P']\nFri Feb  2 18:02:48 2024  -Loading Sumstats2 from gwaslab.Sumstats Object\nFri Feb  2 18:02:49 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 18:02:49 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 18:02:50 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 18:02:51 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 18:02:51 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 18:02:51 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 18:02:52 2024  -Merging sumstats using chr and pos...\nFri Feb  2 18:02:59 2024  -Columns in merged sumstats: P_1,scaled_P_1,TCHR+POS,P_2,scaled_P_2,CHR,POS,_ADD,i\nFri Feb  2 18:02:59 2024 Start to create Manhattan plot for sumstats1...\nFri Feb  2 18:02:59 2024 Start to create MQQ plot...v3.4.38:\nFri Feb  2 18:02:59 2024  -Genomic coordinates version: 19...\nFri Feb  2 18:02:59 2024  -Genome-wide significance level to plot is set to 5e-08 ...\nFri Feb  2 18:02:59 2024  -Raw input contains 5961600 variants...\nFri Feb  2 18:02:59 2024  -MQQ plot layout mode is : m\nFri Feb  2 18:02:59 2024 Finished loading specified columns from the sumstats.\nFri Feb  2 18:02:59 2024 Start data conversion and sanity check:\nFri Feb  2 18:02:59 2024  -Sanity check will be skipped.\nFri Feb  2 18:02:59 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 18:02:59 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 18:03:00 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 18:03:00 2024  -Converting data above cut line...\nFri Feb  2 18:03:00 2024  -Maximum -log10(P) value is 32.86169730183372 .\nFri Feb  2 18:03:00 2024 Finished data conversion and sanity check.\nFri Feb  2 18:03:00 2024 Start to create MQQ plot with 5961600 variants...\nFri Feb  2 18:03:01 2024  -Creating background plot...\nFri Feb  2 18:03:11 2024 Finished creating MQQ plot successfully!\nFri Feb  2 18:03:11 2024 Start to extract variants for annotation...\nFri Feb  2 18:03:11 2024  -Found 20 significant variants with a sliding window size of 500 kb...\nFri Feb  2 18:03:11 2024 Finished extracting variants for annotation...\nFri Feb  2 18:03:11 2024 Start to process figure arts.\nFri Feb  2 18:03:11 2024  -Processing X ticks...\nFri Feb  2 18:03:11 2024  -Processing X labels...\nFri Feb  2 18:03:11 2024  -Processing Y labels...\nFri Feb  2 18:03:11 2024  -Processing Y tick lables...\nFri Feb  2 18:03:11 2024  -Processing Y labels...\nFri Feb  2 18:03:11 2024  -Processing lines...\nFri Feb  2 18:03:11 2024 Finished processing figure arts.\nFri Feb  2 18:03:11 2024 Start to annotate variants...\nFri Feb  2 18:03:11 2024  -Skip annotating\nFri Feb  2 18:03:11 2024 Finished annotating variants.\nFri Feb  2 18:03:11 2024 Start to save figure...\nFri Feb  2 18:03:11 2024  -Skip saving figure!\nFri Feb  2 18:03:11 2024 Finished saving figure...\nFri Feb  2 18:03:11 2024 Finished creating plot successfully!\nFri Feb  2 18:03:11 2024 Finished creating Manhattan plot for sumstats1\nFri Feb  2 18:03:11 2024 Start to create Manhattan plot for sumstats2...\nFri Feb  2 18:03:11 2024 Start to create MQQ plot...v3.4.38:\nFri Feb  2 18:03:11 2024  -Genomic coordinates version: 19...\nFri Feb  2 18:03:11 2024  -Genome-wide significance level to plot is set to 5e-08 ...\nFri Feb  2 18:03:11 2024  -Raw input contains 5961600 variants...\nFri Feb  2 18:03:11 2024  -MQQ plot layout mode is : m\nFri Feb  2 18:03:11 2024 Finished loading specified columns from the sumstats.\nFri Feb  2 18:03:11 2024 Start data conversion and sanity check:\nFri Feb  2 18:03:11 2024  -Sanity check will be skipped.\nFri Feb  2 18:03:11 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 18:03:11 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 18:03:12 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 18:03:12 2024  -Converting data above cut line...\nFri Feb  2 18:03:12 2024  -Maximum -log10(P) value is 40.59842715432355 .\nFri Feb  2 18:03:12 2024 Finished data conversion and sanity check.\nFri Feb  2 18:03:12 2024 Start to create MQQ plot with 5961600 variants...\nFri Feb  2 18:03:13 2024  -Creating background plot...\nFri Feb  2 18:03:23 2024 Finished creating MQQ plot successfully!\nFri Feb  2 18:03:23 2024 Start to extract variants for annotation...\nFri Feb  2 18:03:23 2024  -Found 28 significant variants with a sliding window size of 500 kb...\nFri Feb  2 18:03:23 2024 Finished extracting variants for annotation...\nFri Feb  2 18:03:23 2024 Start to process figure arts.\nFri Feb  2 18:03:23 2024  -Processing X ticks...\nFri Feb  2 18:03:23 2024  -Processing X labels...\nFri Feb  2 18:03:23 2024  -Processing Y labels...\nFri Feb  2 18:03:23 2024  -Processing Y tick lables...\nFri Feb  2 18:03:23 2024  -Processing Y labels...\nFri Feb  2 18:03:23 2024  -Processing lines...\nFri Feb  2 18:03:23 2024 Finished processing figure arts.\nFri Feb  2 18:03:23 2024 Start to annotate variants...\nFri Feb  2 18:03:23 2024  -Skip annotating\nFri Feb  2 18:03:23 2024 Finished annotating variants.\nFri Feb  2 18:03:23 2024 Start to save figure...\nFri Feb  2 18:03:23 2024  -Skip saving figure!\nFri Feb  2 18:03:23 2024 Finished saving figure...\nFri Feb  2 18:03:23 2024 Finished creating plot successfully!\nFri Feb  2 18:03:23 2024 Finished creating Manhattan plot for sumstats2\nFri Feb  2 18:03:23 2024 Start to save figure...\nFri Feb  2 18:03:23 2024  -Skip saving figure!\nFri Feb  2 18:03:23 2024 Finished saving figure...\nFri Feb  2 18:03:23 2024 Finished creating miami plot successfully\n</pre> <p>Most options in plot_mqq() are available for plot_miami2()</p> <p>Simply add 1 or 2 after the option for plot_mqq() to customize the top or bottom figure in miami plot. If no prefix, the parameter will be passed to both plots.</p> In\u00a0[7]: Copied! <pre>a = gl.plot_miami2(path1= gl1,\n                   path2= gl2,\n                   skip=2,\n                   cut1=20,\n                   cut2=15,\n                   id1=\"SNPID\",\n                   id2=\"SNPID\",\n                   anno1=True,\n                   anno2=\"GENENAME\",\n                   additional_line1=[1e-14],\n                   anno_set1=[\"rs3798519\"],\n                   pinpoint1=[[\"rs3798519\",\"rs35560038\"],[\"rs7933262\",\"rs8098510\"]],\n                   pinpoint_color1=[\"purple\",\"black\"],\n                   highlight1=[\"rs8098510\"],\n                   highlight2=[[\"rs8098510\",\"rs3798519\"], [\"rs1491850\"]],\n                   highlight_color2=[\"red\",\"yellow\"],\n                   jagged=True,\n                   verbose1=False,\n                   verbose2=False\n)\n</pre> a = gl.plot_miami2(path1= gl1,                    path2= gl2,                    skip=2,                    cut1=20,                    cut2=15,                    id1=\"SNPID\",                    id2=\"SNPID\",                    anno1=True,                    anno2=\"GENENAME\",                    additional_line1=[1e-14],                    anno_set1=[\"rs3798519\"],                    pinpoint1=[[\"rs3798519\",\"rs35560038\"],[\"rs7933262\",\"rs8098510\"]],                    pinpoint_color1=[\"purple\",\"black\"],                    highlight1=[\"rs8098510\"],                    highlight2=[[\"rs8098510\",\"rs3798519\"], [\"rs1491850\"]],                    highlight_color2=[\"red\",\"yellow\"],                    jagged=True,                    verbose1=False,                    verbose2=False ) <pre>Fri Feb  2 18:06:01 2024 Start to create miami plot v3.4.38:\nFri Feb  2 18:06:01 2024  -Obtaining Sumstats1 CHR, POS, P and annotation from: ['CHR', 'POS', 'P', 'SNPID']\nFri Feb  2 18:06:01 2024  -Loading Sumstats1 from gwaslab.Sumstats Object\nFri Feb  2 18:06:01 2024  -Obtaining Sumstats2 CHR, POS, P and annotation from: ['CHR', 'POS', 'P', 'SNPID']\nFri Feb  2 18:06:01 2024  -Loading Sumstats2 from gwaslab.Sumstats Object\nFri Feb  2 18:06:02 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 18:06:03 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 18:06:03 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 18:06:04 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 18:06:04 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 18:06:05 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 18:06:06 2024  -Merging sumstats using chr and pos...\nFri Feb  2 18:06:15 2024  -Columns in merged sumstats: P_1,SNPID_1,scaled_P_1,TCHR+POS,P_2,SNPID_2,scaled_P_2,CHR,POS,_ADD,i\nFri Feb  2 18:06:15 2024 Start to create Manhattan plot for sumstats1...\nFri Feb  2 18:06:18 2024  -Processing jagged Y axis...\nFri Feb  2 18:06:18 2024 Finished creating Manhattan plot for sumstats1\nFri Feb  2 18:06:18 2024 Start to create Manhattan plot for sumstats2...\nFri Feb  2 18:06:23 2024  -Processing jagged Y axis...\nFri Feb  2 18:06:23 2024 Finished creating Manhattan plot for sumstats2\nFri Feb  2 18:06:23 2024 Start to save figure...\nFri Feb  2 18:06:23 2024  -Skip saving figure!\nFri Feb  2 18:06:23 2024 Finished saving figure...\nFri Feb  2 18:06:23 2024 Finished creating miami plot successfully\n</pre>"},{"location":"visualization_miami2/#miami-plot","title":"Miami plot\u00b6","text":""},{"location":"visualization_miami2/#load-gwaslab-and-sample-sumstats","title":"Load gwaslab and sample sumstats\u00b6","text":""},{"location":"visualization_miami2/#check-lead-variants-in-sumstast1","title":"check lead variants in sumstast1\u00b6","text":""},{"location":"visualization_miami2/#create-miami-plot-by-iteratively-calling-plot_mqq","title":"Create Miami plot by iteratively calling plot_mqq()\u00b6","text":""},{"location":"visualization_miami2/#create-customized-miami-plot","title":"Create customized Miami plot\u00b6","text":""},{"location":"visualization_regional/","title":"Regional plot","text":"In\u00a0[1]: Copied! <pre>import sys\nsys.path.insert(0,\"/home/yunye/work/gwaslab/src\")\nimport gwaslab as gl\n</pre> import sys sys.path.insert(0,\"/home/yunye/work/gwaslab/src\") import gwaslab as gl In\u00a0[2]: Copied! <pre>#!wget -O t2d_bbj.txt.gz http://jenger.riken.jp/14/\n</pre> #!wget -O t2d_bbj.txt.gz http://jenger.riken.jp/14/ In\u00a0[3]: Copied! <pre>mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",\n             snpid=\"SNP\",\n             chrom=\"CHR\",\n             pos=\"POS\",\n             ea=\"ALT\",\n             nea=\"REF\",\n             neaf=\"Frq\",\n             beta=\"BETA\",\n             se=\"SE\",\n             p=\"P\",\n             direction=\"Dir\",\n             build=\"19\",\n             n=\"N\")\nmysumstats.filter_value('CHR ==\"7\"',inplace=True)\nmysumstats.basic_check(verbose = False)\n</pre> mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\",              snpid=\"SNP\",              chrom=\"CHR\",              pos=\"POS\",              ea=\"ALT\",              nea=\"REF\",              neaf=\"Frq\",              beta=\"BETA\",              se=\"SE\",              p=\"P\",              direction=\"Dir\",              build=\"19\",              n=\"N\") mysumstats.filter_value('CHR ==\"7\"',inplace=True) mysumstats.basic_check(verbose = False) <pre>Fri Feb  2 17:20:48 2024 GWASLab v3.4.38 https://cloufield.github.io/gwaslab/\nFri Feb  2 17:20:48 2024 (C) 2022-2024, Yunye He, Kamatani Lab, MIT License, gwaslab@gmail.com\nFri Feb  2 17:20:48 2024 Start to initialize gl.Sumstats from file :t2d_bbj.txt.gz\nFri Feb  2 17:21:03 2024  -Reading columns          : SE,Dir,ALT,REF,POS,SNP,CHR,Frq,BETA,P,N\nFri Feb  2 17:21:03 2024  -Renaming columns to      : SE,DIRECTION,EA,NEA,POS,SNPID,CHR,EAF,BETA,P,N\nFri Feb  2 17:21:03 2024  -Current Dataframe shape : 12557761  x  11\nFri Feb  2 17:21:04 2024  -Initiating a status column: STATUS ...\nFri Feb  2 17:21:04 2024  -Genomic coordinates are based on GRCh37/hg19...\nFri Feb  2 17:21:05 2024  -NEAF is specified...\nFri Feb  2 17:21:05 2024  -Checking if 0&lt;= NEAF &lt;=1 ...\nFri Feb  2 17:21:06 2024  -Converted NEAF to EAF.\nFri Feb  2 17:21:06 2024  -Removed 0 variants with bad NEAF.\nFri Feb  2 17:21:06 2024 Start to reorder the columns...v3.4.38\nFri Feb  2 17:21:06 2024  -Current Dataframe shape : 12557761 x 12 ; Memory usage: 1100.88 MB\nFri Feb  2 17:21:06 2024  -Reordering columns to    : SNPID,CHR,POS,EA,NEA,EAF,BETA,SE,P,N,DIRECTION,STATUS\nFri Feb  2 17:21:06 2024 Finished reordering the columns.\nFri Feb  2 17:21:06 2024  -Column  : SNPID  CHR    POS   EA       NEA      EAF     BETA    SE      P       N     DIRECTION STATUS  \nFri Feb  2 17:21:06 2024  -DType   : object string int64 category category float64 float64 float64 float64 int64 object    category\nFri Feb  2 17:21:06 2024  -Verified: T      F      T     T        T        T       T       T       T       T     T         T       \nFri Feb  2 17:21:06 2024  #WARNING! Columns with possibly incompatable dtypes: CHR\nFri Feb  2 17:21:06 2024  -Current Dataframe memory usage: 1100.88 MB\nFri Feb  2 17:21:06 2024 Finished loading data successfully!\nFri Feb  2 17:21:07 2024 Start filtering values by condition: CHR ==\"7\"\nFri Feb  2 17:21:07 2024  -Removing 11849981 variants not meeting the conditions: CHR ==\"7\"\nFri Feb  2 17:21:07 2024 Finished filtering values.\n</pre> In\u00a0[4]: Copied! <pre>mysumstats.plot_mqq(mode=\"m\",anno=\"GENENAME\",anno_source=\"ensembl\")\n</pre> mysumstats.plot_mqq(mode=\"m\",anno=\"GENENAME\",anno_source=\"ensembl\") <pre>Fri Feb  2 17:21:14 2024 Start to create MQQ plot...v3.4.38:\nFri Feb  2 17:21:14 2024  -Genomic coordinates version: 19...\nFri Feb  2 17:21:14 2024  -Genome-wide significance level to plot is set to 5e-08 ...\nFri Feb  2 17:21:14 2024  -Raw input contains 707780 variants...\nFri Feb  2 17:21:14 2024  -MQQ plot layout mode is : m\nFri Feb  2 17:21:14 2024 Finished loading specified columns from the sumstats.\nFri Feb  2 17:21:14 2024 Start data conversion and sanity check:\nFri Feb  2 17:21:14 2024  -Removed 0 variants with nan in CHR or POS column ...\nFri Feb  2 17:21:14 2024  -Removed 0 variants with CHR &lt;=0...\nFri Feb  2 17:21:14 2024  -Removed 0 variants with nan in P column ...\nFri Feb  2 17:21:14 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 17:21:14 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 17:21:14 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 17:21:14 2024  -Converting data above cut line...\nFri Feb  2 17:21:14 2024  -Maximum -log10(P) value is 73.38711023071251 .\nFri Feb  2 17:21:14 2024 Finished data conversion and sanity check.\nFri Feb  2 17:21:14 2024 Start to create MQQ plot with 707780 variants...\nFri Feb  2 17:21:14 2024  -Creating background plot...\nFri Feb  2 17:21:16 2024 Finished creating MQQ plot successfully!\nFri Feb  2 17:21:16 2024 Start to extract variants for annotation...\nFri Feb  2 17:21:16 2024  -Found 7 significant variants with a sliding window size of 500 kb...\nFri Feb  2 17:21:16 2024 Start to annotate variants with nearest gene name(s)...\nFri Feb  2 17:21:16 2024  -Assigning Gene name using ensembl_hg19_gtf for protein coding genes\nFri Feb  2 17:21:16 2024 Finished annotating variants with nearest gene name(s) successfully!\nFri Feb  2 17:21:16 2024 Finished extracting variants for annotation...\nFri Feb  2 17:21:16 2024 Start to process figure arts.\nFri Feb  2 17:21:16 2024  -Processing X ticks...\nFri Feb  2 17:21:16 2024  -Processing X labels...\nFri Feb  2 17:21:16 2024  -Processing Y labels...\nFri Feb  2 17:21:16 2024  -Processing Y tick lables...\nFri Feb  2 17:21:16 2024  -Processing Y labels...\nFri Feb  2 17:21:16 2024  -Processing lines...\nFri Feb  2 17:21:16 2024 Finished processing figure arts.\nFri Feb  2 17:21:16 2024 Start to annotate variants...\nFri Feb  2 17:21:16 2024  -Annotating using column GENENAME...\nFri Feb  2 17:21:16 2024  -Adjusting text positions with repel_force=0.03...\nFri Feb  2 17:21:16 2024 Finished annotating variants.\nFri Feb  2 17:21:16 2024 Start to save figure...\nFri Feb  2 17:21:16 2024  -Skip saving figure!\nFri Feb  2 17:21:16 2024 Finished saving figure...\nFri Feb  2 17:21:16 2024 Finished creating plot successfully!\n</pre> Out[4]: <pre>(&lt;Figure size 3000x1000 with 1 Axes&gt;, &lt;gwaslab.g_Log.Log at 0x7fd43c674190&gt;)</pre> In\u00a0[5]: Copied! <pre>mysumstats.get_lead()\n</pre> mysumstats.get_lead() <pre>Fri Feb  2 17:21:20 2024 Start to extract lead variants...v3.4.38\nFri Feb  2 17:21:20 2024  -Current Dataframe shape : 707780 x 12 ; Memory usage: 73.87 MB\nFri Feb  2 17:21:20 2024  -Processing 707780 variants...\nFri Feb  2 17:21:20 2024  -Significance threshold : 5e-08\nFri Feb  2 17:21:20 2024  -Sliding window size: 500  kb\nFri Feb  2 17:21:20 2024  -Using P for extracting lead variants...\nFri Feb  2 17:21:20 2024  -Found 1077 significant variants in total...\nFri Feb  2 17:21:20 2024  -Identified 7 lead variants!\nFri Feb  2 17:21:20 2024 Finished extracting lead variants.\n</pre> Out[5]: SNPID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS 77576 7:13888699_G_C 7 13888699 G C 0.5680 0.0562 0.0094 2.507000e-09 191764 ++++ 1960099 83154 7:14898282_C_T 7 14898282 C T 0.6012 0.0617 0.0088 2.336000e-12 191764 ++++ 1960099 229433 7:44174857_T_G 7 44174857 G T 0.5985 -0.0640 0.0093 5.325000e-12 191764 ---- 1960099 335366 7:69406661_A_T 7 69406661 T A 0.1981 -0.0900 0.0111 4.871000e-16 191764 ---- 1960099 568451 7:127253550_C_T 7 127253550 C T 0.9081 0.2761 0.0152 4.101000e-74 191764 ++++ 1960099 579917 7:130025713_G_A 7 130025713 G A 0.9530 -0.1365 0.0230 3.068000e-09 191764 ---- 1960099 695434 7:157038803_A_G 7 157038803 G A 0.4626 -0.0502 0.0088 1.127000e-08 191764 ---- 1960099 In\u00a0[6]: Copied! <pre>mysumstats.plot_mqq(region=(7,156538803,157538803))\n</pre> mysumstats.plot_mqq(region=(7,156538803,157538803)) <pre>Fri Feb  2 17:21:20 2024 Start to create MQQ plot...v3.4.38:\nFri Feb  2 17:21:20 2024  -Genomic coordinates version: 19...\nFri Feb  2 17:21:20 2024  -Genome-wide significance level to plot is set to 5e-08 ...\nFri Feb  2 17:21:20 2024  -Raw input contains 707780 variants...\nFri Feb  2 17:21:20 2024  -MQQ plot layout mode is : mqq\nFri Feb  2 17:21:20 2024  -Region to plot : chr7:156538803-157538803.\nFri Feb  2 17:21:20 2024  -Extract SNPs in region : chr7:156538803-157538803...\nFri Feb  2 17:21:20 2024  -Extract SNPs in specified regions: 5831\nFri Feb  2 17:21:20 2024 Finished loading specified columns from the sumstats.\nFri Feb  2 17:21:20 2024 Start data conversion and sanity check:\nFri Feb  2 17:21:20 2024  -Removed 0 variants with nan in CHR or POS column ...\nFri Feb  2 17:21:20 2024  -Removed 0 variants with CHR &lt;=0...\nFri Feb  2 17:21:20 2024  -Removed 0 variants with nan in P column ...\nFri Feb  2 17:21:20 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 17:21:20 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 17:21:20 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 17:21:20 2024  -Converting data above cut line...\nFri Feb  2 17:21:20 2024  -Maximum -log10(P) value is 7.948076083953893 .\nFri Feb  2 17:21:20 2024 Finished data conversion and sanity check.\nFri Feb  2 17:21:20 2024 Start to create MQQ plot with 5831 variants...\nFri Feb  2 17:21:20 2024  -Creating background plot...\nFri Feb  2 17:21:20 2024 Finished creating MQQ plot successfully!\nFri Feb  2 17:21:20 2024 Start to extract variants for annotation...\nFri Feb  2 17:21:20 2024  -Found 1 significant variants with a sliding window size of 500 kb...\nFri Feb  2 17:21:20 2024 Finished extracting variants for annotation...\nFri Feb  2 17:21:20 2024 Start to process figure arts.\nFri Feb  2 17:21:20 2024  -Processing X labels...\nFri Feb  2 17:21:20 2024  -Processing Y labels...\nFri Feb  2 17:21:20 2024  -Processing Y tick lables...\nFri Feb  2 17:21:20 2024  -Processing Y labels...\nFri Feb  2 17:21:20 2024  -Processing lines...\nFri Feb  2 17:21:20 2024 Finished processing figure arts.\nFri Feb  2 17:21:20 2024 Start to annotate variants...\nFri Feb  2 17:21:20 2024  -Skip annotating\nFri Feb  2 17:21:20 2024 Finished annotating variants.\nFri Feb  2 17:21:20 2024 Start to create QQ plot with 5831 variants:\nFri Feb  2 17:21:20 2024  -Plotting all variants...\nFri Feb  2 17:21:20 2024  -Expected range of P: (0,1.0)\nFri Feb  2 17:21:20 2024  -Lambda GC (MLOG10P mode) at 0.5 is   1.71914\nFri Feb  2 17:21:20 2024  -Processing Y tick lables...\nFri Feb  2 17:21:20 2024 Finished creating QQ plot successfully!\nFri Feb  2 17:21:20 2024 Start to save figure...\nFri Feb  2 17:21:20 2024  -Skip saving figure!\nFri Feb  2 17:21:20 2024 Finished saving figure...\nFri Feb  2 17:21:20 2024 Finished creating plot successfully!\n</pre> Out[6]: <pre>(&lt;Figure size 3000x1000 with 2 Axes&gt;, &lt;gwaslab.g_Log.Log at 0x7fd43c674190&gt;)</pre> In\u00a0[7]: Copied! <pre>mysumstats.plot_mqq(mode=\"r\",region=(7,156538803,157538803))\n</pre> mysumstats.plot_mqq(mode=\"r\",region=(7,156538803,157538803)) <pre>Fri Feb  2 17:21:21 2024 Start to create MQQ plot...v3.4.38:\nFri Feb  2 17:21:21 2024  -Genomic coordinates version: 19...\nFri Feb  2 17:21:21 2024  -Genome-wide significance level to plot is set to 5e-08 ...\nFri Feb  2 17:21:21 2024  -Raw input contains 707780 variants...\nFri Feb  2 17:21:21 2024  -MQQ plot layout mode is : r\nFri Feb  2 17:21:21 2024  -Region to plot : chr7:156538803-157538803.\nFri Feb  2 17:21:21 2024  -Extract SNPs in region : chr7:156538803-157538803...\nFri Feb  2 17:21:21 2024  -Extract SNPs in specified regions: 5831\nFri Feb  2 17:21:21 2024 Finished loading specified columns from the sumstats.\nFri Feb  2 17:21:21 2024 Start data conversion and sanity check:\nFri Feb  2 17:21:21 2024  -Removed 0 variants with nan in CHR or POS column ...\nFri Feb  2 17:21:21 2024  -Removed 0 variants with CHR &lt;=0...\nFri Feb  2 17:21:21 2024  -Removed 0 variants with nan in P column ...\nFri Feb  2 17:21:21 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 17:21:21 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 17:21:21 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 17:21:21 2024  -Converting data above cut line...\nFri Feb  2 17:21:21 2024  -Maximum -log10(P) value is 7.948076083953893 .\nFri Feb  2 17:21:21 2024 Finished data conversion and sanity check.\nFri Feb  2 17:21:21 2024 Start to create MQQ plot with 5831 variants...\nFri Feb  2 17:21:21 2024  -Creating background plot...\nFri Feb  2 17:21:21 2024  -Extracting lead variant...\nFri Feb  2 17:21:21 2024  -Loading gtf files from:default\n</pre> <pre>INFO:root:Extracted GTF attributes: ['gene_id', 'gene_name', 'gene_biotype']\n</pre> <pre>Fri Feb  2 17:21:49 2024  -plotting gene track..\nFri Feb  2 17:21:49 2024  -Finished plotting gene track..\nFri Feb  2 17:21:49 2024 Finished creating MQQ plot successfully!\nFri Feb  2 17:21:49 2024 Start to extract variants for annotation...\nFri Feb  2 17:21:50 2024  -Found 1 significant variants with a sliding window size of 500 kb...\nFri Feb  2 17:21:50 2024 Finished extracting variants for annotation...\nFri Feb  2 17:21:50 2024 Start to process figure arts.\nFri Feb  2 17:21:50 2024  -Processing X labels...\nFri Feb  2 17:21:50 2024  -Processing Y labels...\nFri Feb  2 17:21:50 2024  -Processing Y tick lables...\nFri Feb  2 17:21:50 2024  -Processing Y labels...\nFri Feb  2 17:21:50 2024  -Processing lines...\nFri Feb  2 17:21:50 2024 Finished processing figure arts.\nFri Feb  2 17:21:50 2024 Start to annotate variants...\nFri Feb  2 17:21:50 2024  -Skip annotating\nFri Feb  2 17:21:50 2024 Finished annotating variants.\nFri Feb  2 17:21:50 2024 Start to save figure...\nFri Feb  2 17:21:50 2024  -Skip saving figure!\nFri Feb  2 17:21:50 2024 Finished saving figure...\nFri Feb  2 17:21:50 2024 Finished creating plot successfully!\n</pre> Out[7]: <pre>(&lt;Figure size 3000x2000 with 3 Axes&gt;, &lt;gwaslab.g_Log.Log at 0x7fd43c674190&gt;)</pre> In\u00a0[8]: Copied! <pre>mysumstats.plot_mqq(mode=\"r\",\n                    region=(7,156538803,157538803),                    \n                    vcf_path=gl.get_path(\"1kg_eas_hg19\")\n                   )\n</pre> mysumstats.plot_mqq(mode=\"r\",                     region=(7,156538803,157538803),                                         vcf_path=gl.get_path(\"1kg_eas_hg19\")                    ) <pre>Fri Feb  2 17:21:50 2024 Start to create MQQ plot...v3.4.38:\nFri Feb  2 17:21:50 2024  -Genomic coordinates version: 19...\nFri Feb  2 17:21:50 2024  -Genome-wide significance level to plot is set to 5e-08 ...\nFri Feb  2 17:21:50 2024  -Raw input contains 707780 variants...\nFri Feb  2 17:21:50 2024  -MQQ plot layout mode is : r\nFri Feb  2 17:21:50 2024  -Region to plot : chr7:156538803-157538803.\nFri Feb  2 17:21:50 2024  -Checking prefix for chromosomes in vcf files...\nFri Feb  2 17:21:50 2024  -No prefix for chromosomes in the VCF files.\nFri Feb  2 17:21:50 2024  -Extract SNPs in region : chr7:156538803-157538803...\nFri Feb  2 17:21:50 2024  -Extract SNPs in specified regions: 5831\nFri Feb  2 17:21:50 2024 Finished loading specified columns from the sumstats.\nFri Feb  2 17:21:50 2024 Start data conversion and sanity check:\nFri Feb  2 17:21:50 2024  -Removed 0 variants with nan in CHR or POS column ...\nFri Feb  2 17:21:50 2024  -Removed 0 variants with CHR &lt;=0...\nFri Feb  2 17:21:50 2024  -Removed 0 variants with nan in P column ...\nFri Feb  2 17:21:50 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 17:21:50 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 17:21:50 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 17:21:50 2024  -Converting data above cut line...\nFri Feb  2 17:21:50 2024  -Maximum -log10(P) value is 7.948076083953893 .\nFri Feb  2 17:21:50 2024 Finished data conversion and sanity check.\nFri Feb  2 17:21:50 2024 Start to create MQQ plot with 5831 variants...\nFri Feb  2 17:21:50 2024  -tabix will be used: /home/yunye/tools/bin/tabix\nFri Feb  2 17:21:50 2024 Start to load reference genotype...\nFri Feb  2 17:21:50 2024  -reference vcf path : /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\nFri Feb  2 17:21:52 2024  -Retrieving index...\nFri Feb  2 17:21:52 2024  -Ref variants in the region: 35278\nFri Feb  2 17:21:52 2024  -Matching variants using POS, NEA, EA ...\nFri Feb  2 17:21:52 2024  -Calculating Rsq...\nFri Feb  2 17:21:52 2024 Finished loading reference genotype successfully!\nFri Feb  2 17:21:52 2024  -Creating background plot...\nFri Feb  2 17:21:52 2024  -Extracting lead variant...\nFri Feb  2 17:21:52 2024  -Loading gtf files from:default\n</pre> <pre>INFO:root:Extracted GTF attributes: ['gene_id', 'gene_name', 'gene_biotype']\n</pre> <pre>Fri Feb  2 17:22:21 2024  -plotting gene track..\nFri Feb  2 17:22:21 2024  -Finished plotting gene track..\nFri Feb  2 17:22:21 2024 Finished creating MQQ plot successfully!\nFri Feb  2 17:22:21 2024 Start to extract variants for annotation...\nFri Feb  2 17:22:21 2024  -Found 1 significant variants with a sliding window size of 500 kb...\nFri Feb  2 17:22:21 2024 Finished extracting variants for annotation...\nFri Feb  2 17:22:21 2024 Start to process figure arts.\nFri Feb  2 17:22:21 2024  -Processing X labels...\nFri Feb  2 17:22:21 2024  -Processing Y labels...\nFri Feb  2 17:22:21 2024  -Processing Y tick lables...\nFri Feb  2 17:22:21 2024  -Processing Y labels...\nFri Feb  2 17:22:21 2024  -Processing color bar...\nFri Feb  2 17:22:21 2024  -Processing lines...\nFri Feb  2 17:22:21 2024 Finished processing figure arts.\nFri Feb  2 17:22:21 2024 Start to annotate variants...\nFri Feb  2 17:22:21 2024  -Skip annotating\nFri Feb  2 17:22:21 2024 Finished annotating variants.\nFri Feb  2 17:22:21 2024 Start to save figure...\nFri Feb  2 17:22:21 2024  -Skip saving figure!\nFri Feb  2 17:22:21 2024 Finished saving figure...\nFri Feb  2 17:22:21 2024 Finished creating plot successfully!\n</pre> Out[8]: <pre>(&lt;Figure size 3000x2000 with 4 Axes&gt;, &lt;gwaslab.g_Log.Log at 0x7fd43c674190&gt;)</pre> In\u00a0[9]: Copied! <pre>mysumstats.filter_flanking_by_chrpos([(7,156738803)],windowsizekb=100).get_lead(sig_level=1e-5)\n</pre> mysumstats.filter_flanking_by_chrpos([(7,156738803)],windowsizekb=100).get_lead(sig_level=1e-5) <pre>Fri Feb  2 17:22:22 2024 Start to extract variants in the flanking regions using CHR and POS...\nFri Feb  2 17:22:22 2024  - Central positions: [(7, 156738803)]\nFri Feb  2 17:22:22 2024  - Flanking windowsize in kb: 100\nFri Feb  2 17:22:22 2024  - Variants in flanking region 7:156638803-156838803 : 1119\nFri Feb  2 17:22:22 2024  - Extracted 1119 variants in the regions.\nFri Feb  2 17:22:22 2024 Finished extracting variants in the flanking regions.\nFri Feb  2 17:22:22 2024 Start to extract lead variants...v3.4.38\nFri Feb  2 17:22:22 2024  -Current Dataframe shape : 1119 x 12 ; Memory usage: 20.64 MB\nFri Feb  2 17:22:22 2024  -Processing 1119 variants...\nFri Feb  2 17:22:22 2024  -Significance threshold : 1e-05\nFri Feb  2 17:22:22 2024  -Sliding window size: 500  kb\nFri Feb  2 17:22:22 2024  -Using P for extracting lead variants...\nFri Feb  2 17:22:22 2024  -Found 4 significant variants in total...\nFri Feb  2 17:22:22 2024  -Identified 1 lead variants!\nFri Feb  2 17:22:22 2024 Finished extracting lead variants.\n</pre> Out[9]: SNPID CHR POS EA NEA EAF BETA SE P N DIRECTION STATUS 694190 7:156793450_G_GA 7 156793450 GA G 0.1168 0.0838 0.0167 5.686000e-07 191764 ++++ 1960399 In\u00a0[10]: Copied! <pre>mysumstats.plot_mqq(mode=\"r\",\n                    region=(7,156538803,157538803),      \n                    region_ref2 = \"7:156793450_G_GA\", \n                    vcf_path=gl.get_path(\"1kg_eas_hg19\"),\n                    anno=True,\n                    anno_set=[\"7:156793450_G_GA\",\"7:157038803_A_G\"]\n                   )\n</pre> mysumstats.plot_mqq(mode=\"r\",                     region=(7,156538803,157538803),                           region_ref2 = \"7:156793450_G_GA\",                      vcf_path=gl.get_path(\"1kg_eas_hg19\"),                     anno=True,                     anno_set=[\"7:156793450_G_GA\",\"7:157038803_A_G\"]                    ) <pre>Fri Feb  2 17:22:22 2024 Start to create MQQ plot...v3.4.38:\nFri Feb  2 17:22:22 2024  -Genomic coordinates version: 19...\nFri Feb  2 17:22:22 2024  -Genome-wide significance level to plot is set to 5e-08 ...\nFri Feb  2 17:22:22 2024  -Raw input contains 707780 variants...\nFri Feb  2 17:22:22 2024  -MQQ plot layout mode is : r\nFri Feb  2 17:22:22 2024  -Region to plot : chr7:156538803-157538803.\nFri Feb  2 17:22:22 2024  -Checking prefix for chromosomes in vcf files...\nFri Feb  2 17:22:22 2024  -No prefix for chromosomes in the VCF files.\nFri Feb  2 17:22:22 2024  -Extract SNPs in region : chr7:156538803-157538803...\nFri Feb  2 17:22:23 2024  -Extract SNPs in specified regions: 5831\nFri Feb  2 17:22:23 2024 Finished loading specified columns from the sumstats.\nFri Feb  2 17:22:23 2024 Start data conversion and sanity check:\nFri Feb  2 17:22:23 2024  -Removed 0 variants with nan in CHR or POS column ...\nFri Feb  2 17:22:23 2024  -Removed 0 variants with CHR &lt;=0...\nFri Feb  2 17:22:23 2024  -Removed 0 variants with nan in P column ...\nFri Feb  2 17:22:23 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 17:22:23 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 17:22:23 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 17:22:23 2024  -Converting data above cut line...\nFri Feb  2 17:22:23 2024  -Maximum -log10(P) value is 7.948076083953893 .\nFri Feb  2 17:22:23 2024 Finished data conversion and sanity check.\nFri Feb  2 17:22:23 2024 Start to create MQQ plot with 5831 variants...\nFri Feb  2 17:22:23 2024  -tabix will be used: /home/yunye/tools/bin/tabix\nFri Feb  2 17:22:23 2024 Start to load reference genotype...\nFri Feb  2 17:22:23 2024  -reference vcf path : /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\nFri Feb  2 17:22:24 2024  -Retrieving index...\nFri Feb  2 17:22:24 2024  -Ref variants in the region: 35278\nFri Feb  2 17:22:24 2024  -Matching variants using POS, NEA, EA ...\nFri Feb  2 17:22:25 2024  -Calculating Rsq...\nFri Feb  2 17:22:25 2024  -Reference variant ID: 7:156793450_G_GA - 694190\nFri Feb  2 17:22:25 2024  -Calculating Rsq...\nFri Feb  2 17:22:25 2024 Finished loading reference genotype successfully!\nFri Feb  2 17:22:25 2024  -Creating background plot...\nFri Feb  2 17:22:25 2024  -Extracting lead variant...\nFri Feb  2 17:22:25 2024  -Reference variant ID: 7:156793450_G_GA - 1364\nFri Feb  2 17:22:25 2024  -Loading gtf files from:default\n</pre> <pre>INFO:root:Extracted GTF attributes: ['gene_id', 'gene_name', 'gene_biotype']\n</pre> <pre>Fri Feb  2 17:22:53 2024  -plotting gene track..\nFri Feb  2 17:22:53 2024  -Finished plotting gene track..\nFri Feb  2 17:22:53 2024 Finished creating MQQ plot successfully!\nFri Feb  2 17:22:53 2024 Start to extract variants for annotation...\nFri Feb  2 17:22:53 2024  -Found 2 specified variants to annotate...\nFri Feb  2 17:22:53 2024 Finished extracting variants for annotation...\nFri Feb  2 17:22:53 2024 Start to process figure arts.\nFri Feb  2 17:22:53 2024  -Processing X labels...\nFri Feb  2 17:22:53 2024  -Processing Y labels...\nFri Feb  2 17:22:53 2024  -Processing Y tick lables...\nFri Feb  2 17:22:53 2024  -Processing Y labels...\nFri Feb  2 17:22:53 2024  -Processing color bar...\nFri Feb  2 17:22:53 2024  -Processing lines...\nFri Feb  2 17:22:53 2024 Finished processing figure arts.\nFri Feb  2 17:22:53 2024 Start to annotate variants...\nFri Feb  2 17:22:53 2024  -Annotating using column CHR:POS...\nFri Feb  2 17:22:53 2024  -Adjusting text positions with repel_force=0.03...\nFri Feb  2 17:22:53 2024 Finished annotating variants.\nFri Feb  2 17:22:53 2024 Start to save figure...\nFri Feb  2 17:22:53 2024  -Skip saving figure!\nFri Feb  2 17:22:53 2024 Finished saving figure...\nFri Feb  2 17:22:53 2024 Finished creating plot successfully!\n</pre> Out[10]: <pre>(&lt;Figure size 3000x2000 with 5 Axes&gt;, &lt;gwaslab.g_Log.Log at 0x7fd43c674190&gt;)</pre> In\u00a0[13]: Copied! <pre>gl.plot_stacked_mqq(objects=[mysumstats,mysumstats],\n                    vcfs=[gl.get_path(\"1kg_eas_hg19\"),gl.get_path(\"1kg_eur_hg19\")],\n                    region=(7,156538803,157538803), \n                    mode=\"r\",\n                    build=\"19\",\n                    anno=True,\n                    anno_style=\"tight\",\n                    anno_set=[\"7:156793450_G_GA\",\"7:157038803_A_G\"],\n                    titles=[\"EAS\",\"EUR\"],\n                    title_args={\"size\":20},\n                    anno_args={\"rotation\":0})\n</pre> gl.plot_stacked_mqq(objects=[mysumstats,mysumstats],                     vcfs=[gl.get_path(\"1kg_eas_hg19\"),gl.get_path(\"1kg_eur_hg19\")],                     region=(7,156538803,157538803),                      mode=\"r\",                     build=\"19\",                     anno=True,                     anno_style=\"tight\",                     anno_set=[\"7:156793450_G_GA\",\"7:157038803_A_G\"],                     titles=[\"EAS\",\"EUR\"],                     title_args={\"size\":20},                     anno_args={\"rotation\":0}) <pre>Fri Feb  2 17:32:40 2024 Start to create stacked mqq plot by iteratively calling plot_mqq:\nFri Feb  2 17:32:40 2024 Start to create MQQ plot...v3.4.38:\nFri Feb  2 17:32:40 2024  -Genomic coordinates version: 19...\nFri Feb  2 17:32:40 2024  -Genome-wide significance level to plot is set to 5e-08 ...\nFri Feb  2 17:32:40 2024  -Raw input contains 707780 variants...\nFri Feb  2 17:32:40 2024  -MQQ plot layout mode is : r\nFri Feb  2 17:32:40 2024  -Region to plot : chr7:156538803-157538803.\nFri Feb  2 17:32:40 2024  -Checking prefix for chromosomes in vcf files...\nFri Feb  2 17:32:40 2024  -No prefix for chromosomes in the VCF files.\nFri Feb  2 17:32:40 2024  -Extract SNPs in region : chr7:156538803-157538803...\nFri Feb  2 17:32:40 2024  -Extract SNPs in specified regions: 5831\nFri Feb  2 17:32:40 2024 Finished loading specified columns from the sumstats.\nFri Feb  2 17:32:40 2024 Start data conversion and sanity check:\nFri Feb  2 17:32:40 2024  -Sanity check will be skipped.\nFri Feb  2 17:32:40 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 17:32:40 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 17:32:40 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 17:32:41 2024  -Converting data above cut line...\nFri Feb  2 17:32:41 2024  -Maximum -log10(P) value is 7.948076083953893 .\nFri Feb  2 17:32:41 2024 Finished data conversion and sanity check.\nFri Feb  2 17:32:41 2024 Start to create MQQ plot with 5831 variants...\nFri Feb  2 17:32:41 2024  -tabix will be used: /home/yunye/tools/bin/tabix\nFri Feb  2 17:32:41 2024 Start to load reference genotype...\nFri Feb  2 17:32:41 2024  -reference vcf path : /home/yunye/.gwaslab/EAS.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\nFri Feb  2 17:32:42 2024  -Retrieving index...\nFri Feb  2 17:32:42 2024  -Ref variants in the region: 35278\nFri Feb  2 17:32:42 2024  -Matching variants using POS, NEA, EA ...\nFri Feb  2 17:32:43 2024  -Calculating Rsq...\nFri Feb  2 17:32:43 2024 Finished loading reference genotype successfully!\nFri Feb  2 17:32:43 2024  -Creating background plot...\nFri Feb  2 17:32:43 2024  -Extracting lead variant...\nFri Feb  2 17:32:43 2024  -Loading gtf files from:default\n</pre> <pre>INFO:root:Extracted GTF attributes: ['gene_id', 'gene_name', 'gene_biotype']\n</pre> <pre>Fri Feb  2 17:33:12 2024  -plotting gene track..\nFri Feb  2 17:33:12 2024  -Finished plotting gene track..\nFri Feb  2 17:33:13 2024 Finished creating MQQ plot successfully!\nFri Feb  2 17:33:13 2024 Start to extract variants for annotation...\nFri Feb  2 17:33:13 2024  -Found 2 specified variants to annotate...\nFri Feb  2 17:33:13 2024 Finished extracting variants for annotation...\nFri Feb  2 17:33:13 2024 Start to process figure arts.\nFri Feb  2 17:33:13 2024  -Processing X labels...\nFri Feb  2 17:33:13 2024  -Processing Y labels...\nFri Feb  2 17:33:13 2024  -Processing Y tick lables...\nFri Feb  2 17:33:13 2024  -Processing Y labels...\nFri Feb  2 17:33:13 2024  -Processing color bar...\nFri Feb  2 17:33:13 2024  -Processing lines...\nFri Feb  2 17:33:13 2024 Finished processing figure arts.\nFri Feb  2 17:33:13 2024 Start to annotate variants...\nFri Feb  2 17:33:13 2024  -Annotating using column CHR:POS...\nFri Feb  2 17:33:13 2024  -Adjusting text positions with repel_force=0.03...\nFri Feb  2 17:33:13 2024  -Auto-adjusting text positions...\nFri Feb  2 17:33:13 2024 Finished annotating variants.\nFri Feb  2 17:33:13 2024 Start to save figure...\nFri Feb  2 17:33:13 2024  -Skip saving figure!\nFri Feb  2 17:33:13 2024 Finished saving figure...\nFri Feb  2 17:33:13 2024 Start to create MQQ plot...v3.4.38:\nFri Feb  2 17:33:13 2024  -Genomic coordinates version: 19...\nFri Feb  2 17:33:13 2024  -Genome-wide significance level to plot is set to 5e-08 ...\nFri Feb  2 17:33:13 2024  -Raw input contains 707780 variants...\nFri Feb  2 17:33:13 2024  -MQQ plot layout mode is : r\nFri Feb  2 17:33:13 2024  -Region to plot : chr7:156538803-157538803.\nFri Feb  2 17:33:13 2024  -Checking prefix for chromosomes in vcf files...\nFri Feb  2 17:33:13 2024  -No prefix for chromosomes in the VCF files.\nFri Feb  2 17:33:13 2024  -Extract SNPs in region : chr7:156538803-157538803...\nFri Feb  2 17:33:13 2024  -Extract SNPs in specified regions: 5831\nFri Feb  2 17:33:13 2024 Finished loading specified columns from the sumstats.\nFri Feb  2 17:33:13 2024 Start data conversion and sanity check:\nFri Feb  2 17:33:13 2024  -Sanity check will be skipped.\nFri Feb  2 17:33:13 2024  -Sanity check after conversion: 0 variants with P value outside of (0,1] will be removed...\nFri Feb  2 17:33:13 2024  -Sumstats P values are being converted to -log10(P)...\nFri Feb  2 17:33:13 2024  -Sanity check: 0 na/inf/-inf variants will be removed...\nFri Feb  2 17:33:13 2024  -Converting data above cut line...\nFri Feb  2 17:33:13 2024  -Maximum -log10(P) value is 7.948076083953893 .\nFri Feb  2 17:33:13 2024 Finished data conversion and sanity check.\nFri Feb  2 17:33:13 2024 Start to create MQQ plot with 5831 variants...\nFri Feb  2 17:33:13 2024  -tabix will be used: /home/yunye/tools/bin/tabix\nFri Feb  2 17:33:13 2024 Start to load reference genotype...\nFri Feb  2 17:33:13 2024  -reference vcf path : /home/yunye/.gwaslab/EUR.ALL.split_norm_af.1kgp3v5.hg19.vcf.gz\nFri Feb  2 17:33:15 2024  -Retrieving index...\nFri Feb  2 17:33:15 2024  -Ref variants in the region: 35278\nFri Feb  2 17:33:15 2024  -Matching variants using POS, NEA, EA ...\nFri Feb  2 17:33:15 2024  -Calculating Rsq...\nFri Feb  2 17:33:15 2024 Finished loading reference genotype successfully!\nFri Feb  2 17:33:15 2024  -Creating background plot...\nFri Feb  2 17:33:15 2024  -Extracting lead variant...\nFri Feb  2 17:33:15 2024 Finished creating MQQ plot successfully!\nFri Feb  2 17:33:15 2024 Start to extract variants for annotation...\nFri Feb  2 17:33:15 2024  -Found 2 specified variants to annotate...\nFri Feb  2 17:33:15 2024 Finished extracting variants for annotation...\nFri Feb  2 17:33:15 2024 Start to process figure arts.\nFri Feb  2 17:33:15 2024  -Processing X labels...\nFri Feb  2 17:33:15 2024  -Processing Y labels...\nFri Feb  2 17:33:15 2024  -Processing Y tick lables...\nFri Feb  2 17:33:15 2024  -Processing Y labels...\nFri Feb  2 17:33:15 2024  -Processing lines...\nFri Feb  2 17:33:15 2024 Finished processing figure arts.\nFri Feb  2 17:33:15 2024 Start to annotate variants...\nFri Feb  2 17:33:15 2024  -Annotating using column CHR:POS...\nFri Feb  2 17:33:15 2024  -Adjusting text positions with repel_force=0.03...\nFri Feb  2 17:33:15 2024  -Auto-adjusting text positions...\nFri Feb  2 17:33:16 2024 Finished annotating variants.\nFri Feb  2 17:33:16 2024 Start to save figure...\nFri Feb  2 17:33:16 2024  -Skip saving figure!\nFri Feb  2 17:33:16 2024 Finished saving figure...\nFri Feb  2 17:33:16 2024 Start to save figure...\nFri Feb  2 17:33:16 2024  -Skip saving figure!\nFri Feb  2 17:33:16 2024 Finished saving figure...\nFri Feb  2 17:33:16 2024 Finished creating stacked mqq plot by iteratively calling plot_mqq.\n</pre> Out[13]: <pre>(&lt;Figure size 3200x2400 with 6 Axes&gt;, &lt;gwaslab.g_Log.Log at 0x7fd4394ed490&gt;)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"visualization_regional/#regional-plot","title":"Regional plot\u00b6","text":""},{"location":"visualization_regional/#import-gwaslab","title":"Import gwaslab\u00b6","text":""},{"location":"visualization_regional/#download-sample-data","title":"Download sample data\u00b6","text":""},{"location":"visualization_regional/#load-sumstats-into-gwaslabsumstats","title":"Load sumstats into gwaslab.Sumstats\u00b6","text":""},{"location":"visualization_regional/#create-manhattan-plot-with-sumstats-on-a-single-chromosome","title":"Create Manhattan plot with sumstats on a single chromosome\u00b6","text":""},{"location":"visualization_regional/#check-lead-variants","title":"Check lead variants\u00b6","text":""},{"location":"visualization_regional/#create-a-regional-plot-with-no-additional-information","title":"Create a regional plot with no additional information\u00b6","text":""},{"location":"visualization_regional/#create-a-regional-plot-with-gene-track","title":"Create a regional plot with gene track\u00b6","text":""},{"location":"visualization_regional/#create-regional-plot-with-gene-track-and-ld-information","title":"Create regional plot with gene track and LD information\u00b6","text":""},{"location":"visualization_regional/#create-regional-plot-with-two-reference-variants","title":"Create regional plot with two reference variants\u00b6","text":""},{"location":"visualization_regional/#create-stacked-regional-plot","title":"Create stacked regional plot\u00b6","text":""}]}