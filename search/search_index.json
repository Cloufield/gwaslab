{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"GWASLAB Gwaslab : a simple python package for handling GWAS sumstats. Each process is modularized and can be customized to your needs. Most manipulations are designed as methods of python object, gwaslab.Sumstats . import gwaslab as gl mysumstats = gl.Sumstats(path) mysumstats.plot_mqq() ... Functions Standardization, Normalization & Harmonization CHR and POS notation standardization Variant POS and allele normalization Genome build : Liftover Reference allele alignment using a reference genome sequence rsID assignment based on CHR, POS, REF and ALT CHR POS assignment based on rsID using a reference VCF Palindromic SNPs and indels strand inference using a reference VCF Check allele frequency discrepancy using a reference VCF Quality control, Value conversion & Filtering Statistics sanity check Equivalent statistics conversion BETA/SE , OR/OR_95L/OR_95U P, Z, CHISQ, MLOG10 Extract/exclude hapmap3 variants Extract/exclude MHC variants Filtering values. Visualization Mqq plot : Manhattan plot and QQ plot side by side Heatmap : ldsc-rg genetic correlation matrix Scatter Plot : variant effect size comparison with sumstats Scatter Plot : allele frequency comparison Other Utilities Read ldsc h2 or rg outputs directly as DataFrames Extract lead SNPs given a window size Logging : keep a complete record of manipulations from raw data to munged data Formating GWAS sumstats in certain formats LDSC / MAGMA / METAL / MR-MEGA / FUMA Install coming soon Requirements: Python3 pyVCF 0.6.8 Biopython 1.79 liftover 1.1.13 pandas 1.2.4 numpy 1.21.2 matplotlib>3.5 seaborn 0.11.1 scipy 1.6.2 Reference sources UCSC reference files: https://hgdownload.soe.ucsc.edu/downloads.html#human 1000 Genome Phase3 vcf files: http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/ gnomAD vcf files: https://gnomad.broadinstitute.org/downloads dbSNP vcf files: https://ftp.ncbi.nih.gov/snp/ Contacts https://github.com/Cloufield/gwaslab Update log v3.0.0 v2.0.0 added sumstats QC pipepline.","title":"Home"},{"location":"#gwaslab","text":"Gwaslab : a simple python package for handling GWAS sumstats. Each process is modularized and can be customized to your needs. Most manipulations are designed as methods of python object, gwaslab.Sumstats . import gwaslab as gl mysumstats = gl.Sumstats(path) mysumstats.plot_mqq() ...","title":"GWASLAB"},{"location":"#functions","text":"","title":"Functions"},{"location":"#standardization-normalization-harmonization","text":"CHR and POS notation standardization Variant POS and allele normalization Genome build : Liftover Reference allele alignment using a reference genome sequence rsID assignment based on CHR, POS, REF and ALT CHR POS assignment based on rsID using a reference VCF Palindromic SNPs and indels strand inference using a reference VCF Check allele frequency discrepancy using a reference VCF","title":"Standardization, Normalization &amp; Harmonization"},{"location":"#quality-control-value-conversion-filtering","text":"Statistics sanity check Equivalent statistics conversion BETA/SE , OR/OR_95L/OR_95U P, Z, CHISQ, MLOG10 Extract/exclude hapmap3 variants Extract/exclude MHC variants Filtering values.","title":"Quality control, Value conversion &amp; Filtering"},{"location":"#visualization","text":"Mqq plot : Manhattan plot and QQ plot side by side Heatmap : ldsc-rg genetic correlation matrix Scatter Plot : variant effect size comparison with sumstats Scatter Plot : allele frequency comparison","title":"Visualization"},{"location":"#other-utilities","text":"Read ldsc h2 or rg outputs directly as DataFrames Extract lead SNPs given a window size Logging : keep a complete record of manipulations from raw data to munged data Formating GWAS sumstats in certain formats LDSC / MAGMA / METAL / MR-MEGA / FUMA","title":"Other Utilities"},{"location":"#install","text":"coming soon","title":"Install"},{"location":"#requirements","text":"Python3 pyVCF 0.6.8 Biopython 1.79 liftover 1.1.13 pandas 1.2.4 numpy 1.21.2 matplotlib>3.5 seaborn 0.11.1 scipy 1.6.2","title":"Requirements:"},{"location":"#reference-sources","text":"UCSC reference files: https://hgdownload.soe.ucsc.edu/downloads.html#human 1000 Genome Phase3 vcf files: http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/ gnomAD vcf files: https://gnomad.broadinstitute.org/downloads dbSNP vcf files: https://ftp.ncbi.nih.gov/snp/","title":"Reference sources"},{"location":"#contacts","text":"https://github.com/Cloufield/gwaslab","title":"Contacts"},{"location":"#update-log","text":"v3.0.0 v2.0.0 added sumstats QC pipepline.","title":"Update log"},{"location":"AlleleFrequency/","text":"Scatter & Distribution plot : allele frequency comparison sumstats.plot_daf()","title":"Scatter: allele frequency comparison"},{"location":"Conversion/","text":"Statistic conversion: P <-> MLOG10P","title":"Conversion"},{"location":"EffectSize/","text":"Scatter plot : effect size comparison gl.compare_effect(path1, cols_name_list_1, effect_cols_list_1, path2, cols_name_list_2, effect_cols_list_2, eaf=[], maf_level=None, label=[\"Sumstats_1\",\"Sumstats_2\",\"Both\",\"None\"], snplist=None, mode=\"beta\", anno=False, null_beta=0, is_q=True, q_level=0.05, sig_level=5e-8, legend_title=r'$ P < 5 x 10^{-8}$ in:', legend_pos='upper left', reg_box=dict(boxstyle='round', facecolor='white', alpha=1,edgecolor=\"grey\"), is_reg=True, is_45_helper_line=True, scatterargs={\"s\":20}, plt_args={\"figsize\":(8,8),\"dpi\":300}, xylabel_prefix=\"Per-allele effect size in \", helper_line_args={\"color\":'black', \"linestyle\":'-',\"lw\":1}, fontargs={'family':'sans','fontname':'Arial','fontsize':12}, errargs={\"ecolor\":\"#cccccc\",\"elinewidth\":1}, verbose=False): Example: gl.compare()","title":"Scatter: effect size comparison"},{"location":"EffectSize/#scatter-plot-effect-size-comparison","text":"gl.compare_effect(path1, cols_name_list_1, effect_cols_list_1, path2, cols_name_list_2, effect_cols_list_2, eaf=[], maf_level=None, label=[\"Sumstats_1\",\"Sumstats_2\",\"Both\",\"None\"], snplist=None, mode=\"beta\", anno=False, null_beta=0, is_q=True, q_level=0.05, sig_level=5e-8, legend_title=r'$ P < 5 x 10^{-8}$ in:', legend_pos='upper left', reg_box=dict(boxstyle='round', facecolor='white', alpha=1,edgecolor=\"grey\"), is_reg=True, is_45_helper_line=True, scatterargs={\"s\":20}, plt_args={\"figsize\":(8,8),\"dpi\":300}, xylabel_prefix=\"Per-allele effect size in \", helper_line_args={\"color\":'black', \"linestyle\":'-',\"lw\":1}, fontargs={'family':'sans','fontname':'Arial','fontsize':12}, errargs={\"ecolor\":\"#cccccc\",\"elinewidth\":1}, verbose=False): Example: gl.compare()","title":"Scatter plot : effect size comparison"},{"location":"ExtractLead/","text":"Utilities Data conversion Extract lead variants Format sumstats for commonly used tools Load LDSC results into pd.DataFrame Observed-scale heritability to liability-scale heritablity conversion Extract lead variants sumstats.get_lead(windowsizekb=500, sig_level=5e-8) GWASLab will extract the lead variants from identified significant loci based on a sliding window (default window size: 500kb). (Details are described in ) windowsizekb :specify the sliding window size in kb (default: 500) sig_level :specify the P value threshold (default: 5e-8) Return a dataframe of the lead variants Formatting sumstats sumstats.format() Format the sumstats to the formats that were accepted by commonly used tools including LDSC, MAGMA, FUMA , METAL, (bed ,vcf,...) path : output file path format : Currently, GWASlab support ldsc, (fuma, metal,bed, vcf ...) extract : a list of SNPIDs. exclude : a list of SNPIDs. exclude_hla : True or False. If True, exclude HLA region when exporting sumstats. hapmap3 : True or False. If True,, only exporting Hapmap3 SNPs. to_csvargs : arguments for pandas.to_csv() function Batch load LDSC log file Simply batch load LDSc data into a pandas DataFrame for other manipulation. GWASLab uses regular expression to match the values and fill them into a dataframe. gl.read_ldsc() gl.read_ldsc(filelist, mode=\"h2\") `filelist` : a list of paths to ldsc log files `mode` : h2 or rg ```python #mode=h2 ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(ldsc_file_list, mode=h2) #mode=rg ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(mode=h2) For genetic correlation, after loading, you can use gl.plot_rg() to plot a heat map to visualize the results. No extra manipulation needed. gl.plot_rg(myldscrg) Heritabilty conversion (Observed-scale -> Liability-scale) gl.h2_obs_to_liab(h2_obs, P, K, se_obs=None) h2_obs : float. Heritability on the observed scale in an ascertained sample. P : float in (0,1). Prevalence of the phenotype in the sample. K : float in (0,1) . Prevalence of the phenotype in the population. se_obs : float. se of h2_obs. Adopted from LDSC. Reference: Estimating Missing Heritability for Disease from Genome-wide Association Studies https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059431/","title":"Extract Lead Variants"},{"location":"ExtractLead/#utilities","text":"Data conversion Extract lead variants Format sumstats for commonly used tools Load LDSC results into pd.DataFrame Observed-scale heritability to liability-scale heritablity conversion","title":"Utilities"},{"location":"ExtractLead/#extract-lead-variants","text":"sumstats.get_lead(windowsizekb=500, sig_level=5e-8) GWASLab will extract the lead variants from identified significant loci based on a sliding window (default window size: 500kb). (Details are described in ) windowsizekb :specify the sliding window size in kb (default: 500) sig_level :specify the P value threshold (default: 5e-8) Return a dataframe of the lead variants","title":"Extract lead variants"},{"location":"ExtractLead/#_1","text":"","title":""},{"location":"ExtractLead/#formatting-sumstats","text":"sumstats.format() Format the sumstats to the formats that were accepted by commonly used tools including LDSC, MAGMA, FUMA , METAL, (bed ,vcf,...) path : output file path format : Currently, GWASlab support ldsc, (fuma, metal,bed, vcf ...) extract : a list of SNPIDs. exclude : a list of SNPIDs. exclude_hla : True or False. If True, exclude HLA region when exporting sumstats. hapmap3 : True or False. If True,, only exporting Hapmap3 SNPs. to_csvargs : arguments for pandas.to_csv() function","title":"Formatting sumstats"},{"location":"ExtractLead/#_2","text":"","title":""},{"location":"ExtractLead/#batch-load-ldsc-log-file","text":"Simply batch load LDSc data into a pandas DataFrame for other manipulation. GWASLab uses regular expression to match the values and fill them into a dataframe. gl.read_ldsc() gl.read_ldsc(filelist, mode=\"h2\") `filelist` : a list of paths to ldsc log files `mode` : h2 or rg ```python #mode=h2 ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(ldsc_file_list, mode=h2) #mode=rg ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(mode=h2) For genetic correlation, after loading, you can use gl.plot_rg() to plot a heat map to visualize the results. No extra manipulation needed. gl.plot_rg(myldscrg)","title":"Batch load LDSC log file"},{"location":"ExtractLead/#heritabilty-conversion-observed-scale-liability-scale","text":"gl.h2_obs_to_liab(h2_obs, P, K, se_obs=None) h2_obs : float. Heritability on the observed scale in an ascertained sample. P : float in (0,1). Prevalence of the phenotype in the sample. K : float in (0,1) . Prevalence of the phenotype in the population. se_obs : float. se of h2_obs. Adopted from LDSC. Reference: Estimating Missing Heritability for Disease from Genome-wide Association Studies https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059431/","title":"Heritabilty conversion (Observed-scale -&gt; Liability-scale)"},{"location":"Format/","text":"Formatting sumstats sumstats.format() Format the sumstats to the formats that were accepted by commonly used tools including LDSC, MAGMA, FUMA , METAL, (bed ,vcf,...) path : output file path format : Currently, GWASlab support ldsc, (fuma, metal,bed, vcf ...) extract : a list of SNPIDs. exclude : a list of SNPIDs. exclude_hla : True or False. If True, exclude HLA region when exporting sumstats. hapmap3 : True or False. If True,, only exporting Hapmap3 SNPs. to_csvargs : arguments for pandas.to_csv() function","title":"Formatting"},{"location":"Format/#formatting-sumstats","text":"sumstats.format() Format the sumstats to the formats that were accepted by commonly used tools including LDSC, MAGMA, FUMA , METAL, (bed ,vcf,...) path : output file path format : Currently, GWASlab support ldsc, (fuma, metal,bed, vcf ...) extract : a list of SNPIDs. exclude : a list of SNPIDs. exclude_hla : True or False. If True, exclude HLA region when exporting sumstats. hapmap3 : True or False. If True,, only exporting Hapmap3 SNPs. to_csvargs : arguments for pandas.to_csv() function","title":"Formatting sumstats"},{"location":"Gallery/","text":"","title":"Gallery"},{"location":"GeneticCorrelation/","text":"load data plot","title":"Heatmap: genetic correlation"},{"location":"Harmonization/","text":"Harmonization Methods summary Sumstats Methods Options Description .check_ref() ref_path check alignment with a reference sequence .rsid_to_chrpos() path, n_cores use rsid to fill CHR and POS .rsid_to_chrpos2() path use rsid to fill CHR and POS (muilti-thread, need hd5 file) .assign_rsid() path annotate rsid using a reference vcf file .infer_strand() ref_infer=\"\" , ref_alt_freq=None, maf_threshold=0.43 infer the strand of a variant using reference vcf file with EAF in INFO .check_daf() ref_infer=\"\" , ref_alt_freq=None, calculate difference in allele frequencies .flip_allele_stats() After alignment and inferring, flip the alleles to harmonise the variants. .liftover() n_cores=1,from_build=\"19\", to_build=\"38\" perform liftover Align NEA with REF in reference genome mysumstats.check_ref(ref_path=\"ref_genome.fa\") (! Only changing the status code) Check if NEA is aligned with the reference sequence. After checking, the tracking status code will be changed accordingly. Assign CHR and POS according to rsID and reference data mysumstats.rsid_to_chrpos() #single thread mysumstats.rsid_to_chrpos2() #multithread (to be tested) Assign rsID according to CHR, POS, REF/ALT mysumstats.assign_rsid(path=\"reference.vcf.gz\") Annotated variants with rsID using a reference vcf file (tabix indexd). Gwaslab will first extract all variants in reference file with matching CHR and POS. And then comapre EA/NEA in sumstats with REF/ALT in reference vcf. When matching, it will annotate the vairant in sumstats with the matching rsID in reference vcf. Check panlidromic SNPs or undistingushable Indels mysumstats.infer_strand() (! Only changing the status code) Infer the strand for palindromic SNPs (AT, or CG), the default threshlod is 0.43. make sure specify the right allele frequency for you target ancestry in INFO field. Checking the alignment status of indels with the REF allele in reference vcf file. Check difference in allele frequency mysumstats.check_daf() You may want to check the allele frequency discrepancy with a reference vcf. Just specify the path and the right allele frequency for you target ancestry in INFO field. GWASlab will simply calculate DAF = AF-EAF - AF-ALT , and store the results in DAF column. DAF can then be used to plot or filter variants. mysumstats.plot_daf() Flipping based on status code mysumstats.flip_allele_stats() Flip allele-specific statistics to harmonise the variants based on the tracking status code Liftover mysumstats.liftover(n_cores=1,from_build=\"19\", to_build=\"38\") Perform liftover for POS (based on liftover GitHub - jeremymcrae/liftover: liftover for python, made fast with cython )","title":"Harmonization"},{"location":"Harmonization/#harmonization","text":"","title":"Harmonization"},{"location":"Harmonization/#methods-summary","text":"Sumstats Methods Options Description .check_ref() ref_path check alignment with a reference sequence .rsid_to_chrpos() path, n_cores use rsid to fill CHR and POS .rsid_to_chrpos2() path use rsid to fill CHR and POS (muilti-thread, need hd5 file) .assign_rsid() path annotate rsid using a reference vcf file .infer_strand() ref_infer=\"\" , ref_alt_freq=None, maf_threshold=0.43 infer the strand of a variant using reference vcf file with EAF in INFO .check_daf() ref_infer=\"\" , ref_alt_freq=None, calculate difference in allele frequencies .flip_allele_stats() After alignment and inferring, flip the alleles to harmonise the variants. .liftover() n_cores=1,from_build=\"19\", to_build=\"38\" perform liftover","title":"Methods summary"},{"location":"Harmonization/#align-nea-with-ref-in-reference-genome","text":"mysumstats.check_ref(ref_path=\"ref_genome.fa\") (! Only changing the status code) Check if NEA is aligned with the reference sequence. After checking, the tracking status code will be changed accordingly.","title":"Align NEA with REF in reference genome"},{"location":"Harmonization/#assign-chr-and-pos-according-to-rsid-and-reference-data","text":"mysumstats.rsid_to_chrpos() #single thread mysumstats.rsid_to_chrpos2() #multithread (to be tested)","title":"Assign CHR and POS according to rsID and reference data"},{"location":"Harmonization/#assign-rsid-according-to-chr-pos-refalt","text":"mysumstats.assign_rsid(path=\"reference.vcf.gz\") Annotated variants with rsID using a reference vcf file (tabix indexd). Gwaslab will first extract all variants in reference file with matching CHR and POS. And then comapre EA/NEA in sumstats with REF/ALT in reference vcf. When matching, it will annotate the vairant in sumstats with the matching rsID in reference vcf.","title":"Assign rsID according to CHR, POS, REF/ALT"},{"location":"Harmonization/#check-panlidromic-snps-or-undistingushable-indels","text":"mysumstats.infer_strand() (! Only changing the status code) Infer the strand for palindromic SNPs (AT, or CG), the default threshlod is 0.43. make sure specify the right allele frequency for you target ancestry in INFO field. Checking the alignment status of indels with the REF allele in reference vcf file.","title":"Check panlidromic SNPs or undistingushable Indels"},{"location":"Harmonization/#check-difference-in-allele-frequency","text":"mysumstats.check_daf() You may want to check the allele frequency discrepancy with a reference vcf. Just specify the path and the right allele frequency for you target ancestry in INFO field. GWASlab will simply calculate DAF = AF-EAF - AF-ALT , and store the results in DAF column. DAF can then be used to plot or filter variants. mysumstats.plot_daf()","title":"Check difference in allele frequency"},{"location":"Harmonization/#flipping-based-on-status-code","text":"mysumstats.flip_allele_stats() Flip allele-specific statistics to harmonise the variants based on the tracking status code","title":"Flipping based on status code"},{"location":"Harmonization/#liftover","text":"mysumstats.liftover(n_cores=1,from_build=\"19\", to_build=\"38\") Perform liftover for POS (based on liftover GitHub - jeremymcrae/liftover: liftover for python, made fast with cython )","title":"Liftover"},{"location":"HeritabilityConversion/","text":"Heritabilty conversion (Observed-scale -> Liability-scale) gl.h2_obs_to_liab(h2_obs, P, K, se_obs=None) h2_obs : float. Heritability on the observed scale in an ascertained sample. P : float in (0,1). Prevalence of the phenotype in the sample. K : float in (0,1) . Prevalence of the phenotype in the population. se_obs : float. se of h2_obs. Adopted from LDSC. Reference: Estimating Missing Heritability for Disease from Genome-wide Association Studies https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059431/","title":"Heritability conversion"},{"location":"HeritabilityConversion/#heritabilty-conversion-observed-scale-liability-scale","text":"gl.h2_obs_to_liab(h2_obs, P, K, se_obs=None) h2_obs : float. Heritability on the observed scale in an ascertained sample. P : float in (0,1). Prevalence of the phenotype in the sample. K : float in (0,1) . Prevalence of the phenotype in the population. se_obs : float. se of h2_obs. Adopted from LDSC. Reference: Estimating Missing Heritability for Disease from Genome-wide Association Studies https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059431/","title":"Heritabilty conversion (Observed-scale -&gt; Liability-scale)"},{"location":"LoadLDSC/","text":"Batch load LDSC log file Simply batch load LDSc data into a pandas DataFrame for other manipulation. GWASLab uses regular expression to match the values and fill them into a dataframe. gl.read_ldsc() gl.read_ldsc(filelist, mode=\"h2\") `filelist` : a list of paths to ldsc log files `mode` : h2 or rg ```python #mode=h2 ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(ldsc_file_list, mode=h2) #mode=rg ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(mode=h2) For genetic correlation, after loading, you can use gl.plot_rg() to plot a heat map to visualize the results. No extra manipulation needed. gl.plot_rg(myldscrg)","title":"Load LDSC log"},{"location":"LoadLDSC/#batch-load-ldsc-log-file","text":"Simply batch load LDSc data into a pandas DataFrame for other manipulation. GWASLab uses regular expression to match the values and fill them into a dataframe. gl.read_ldsc() gl.read_ldsc(filelist, mode=\"h2\") `filelist` : a list of paths to ldsc log files `mode` : h2 or rg ```python #mode=h2 ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(ldsc_file_list, mode=h2) #mode=rg ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(mode=h2) For genetic correlation, after loading, you can use gl.plot_rg() to plot a heat map to visualize the results. No extra manipulation needed. gl.plot_rg(myldscrg)","title":"Batch load LDSC log file"},{"location":"QC%26Filtering/","text":"QC and filtering Methods Summary Sumstats Methods Options Description .check_sanity() sanity check for statistics including BETA, SE, Z, CHISQ, EAF, OR, N... .remove_dup() mode=\"dm\",keep='first' remove duplicate or multi-allelic variants .filter_in() lt, gt, eq, inplace .filter_out() Statistics Sanity Check .check_sanity() : Basic sanity check will. be performed on statistics to check if there are any extreme values or values out of expected range . BETA/SE : float, -10<BETA<10, -10<log(OR)<10 OR/OR_95L/OR_95U : float, 0<OR<10, OR_95L>0, OR_95U>0 EAF : 0<= EAF <=1, if EAF of >95% of valid variants is less than 0.5, a warning will be sent. P : float, 0<P<5e-300 MLOG10 : float, MLOG10>0 Z : float CHISQ : float , CHISQ>0 N : interger, N>0 Direction : string, only contains \"+\",\"-\" ,\"0\"or \"?\" sumstats.check_sanity() Remove duplication or multiallelic variants after standardize the sumstats, you can also remove duplicated or multiallelic variants using : .remove_dup() mode: d ,remove duplicate. If SNPID exists, remove duplicate . If rsID exists, remove deuplicate rsID. m ,removed multiallelic. remove based on SNPID, CHR and POS sumstats.remove_dup(mode=\"dm\",keep='first') FIltering .filter_in(gt={},lt={},eq={},inplace=True) .filter_out(gt={},lt={},eq={},inplace=True) gt : greater than lt : less than eq : equal to inplace : True or False. If False, return a dataframe. If true, the Sumstats object will be filtered.","title":"QC&Filtering"},{"location":"QC%26Filtering/#qc-and-filtering","text":"","title":"QC and filtering"},{"location":"QC%26Filtering/#methods-summary","text":"Sumstats Methods Options Description .check_sanity() sanity check for statistics including BETA, SE, Z, CHISQ, EAF, OR, N... .remove_dup() mode=\"dm\",keep='first' remove duplicate or multi-allelic variants .filter_in() lt, gt, eq, inplace .filter_out()","title":"Methods Summary"},{"location":"QC%26Filtering/#statistics-sanity-check","text":".check_sanity() : Basic sanity check will. be performed on statistics to check if there are any extreme values or values out of expected range . BETA/SE : float, -10<BETA<10, -10<log(OR)<10 OR/OR_95L/OR_95U : float, 0<OR<10, OR_95L>0, OR_95U>0 EAF : 0<= EAF <=1, if EAF of >95% of valid variants is less than 0.5, a warning will be sent. P : float, 0<P<5e-300 MLOG10 : float, MLOG10>0 Z : float CHISQ : float , CHISQ>0 N : interger, N>0 Direction : string, only contains \"+\",\"-\" ,\"0\"or \"?\" sumstats.check_sanity()","title":"Statistics Sanity Check"},{"location":"QC%26Filtering/#remove-duplication-or-multiallelic-variants","text":"after standardize the sumstats, you can also remove duplicated or multiallelic variants using : .remove_dup() mode: d ,remove duplicate. If SNPID exists, remove duplicate . If rsID exists, remove deuplicate rsID. m ,removed multiallelic. remove based on SNPID, CHR and POS sumstats.remove_dup(mode=\"dm\",keep='first')","title":"Remove duplication or multiallelic variants"},{"location":"QC%26Filtering/#filtering","text":".filter_in(gt={},lt={},eq={},inplace=True) .filter_out(gt={},lt={},eq={},inplace=True) gt : greater than lt : less than eq : equal to inplace : True or False. If False, return a dataframe. If true, the Sumstats object will be filtered.","title":"FIltering"},{"location":"Reference/","text":"Process Reference file 1000 Genome Download: Index of /vol1/ftp/release/20130502/ After downloading the raw vcf, we need to normalize the variants, split multiallelic variants, rename the variant and remove duplicates. Also, we need to extract out target ancestry and recalculate the allele frequency. Create a sample list for EAS samples awk '$3==\"EAS\"{print $1}' integrated_call_samples_v3.20130502.ALL.panel >EAS.sample 1000 genome: #!/bin/bash for chr in {1..2} do bcftools view -S EAS.sample ALL.chr\"${chr}\".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz | \\ bcftools norm -m-any --check-ref w -f human_g1k_v37.fasta | \\ bcftools annotate -x ID,INFO -I +'%CHROM:%POS:%REF:%ALT' | \\ bcftools norm --rm-dup both | \\ bcftools +fill-tags -Oz -- -t AF \\ > EAS.chr\"${chr}\".split_norm_af.vcf.gz tabix -p vcf EAS.chr\"${chr}\".split_norm_af.vcf.gz done dbsnp rsID database. dbsnp v151 (hg19): https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz latest release: Index of /snp/latest_release/VCF gnomad Allele frequency for major ancestries and rsID gnomAD v2 & gnomAD v2 liftover & gnomAD v3: gnomAD","title":"References"},{"location":"Reference/#process-reference-file","text":"","title":"Process Reference file"},{"location":"Reference/#1000-genome","text":"Download: Index of /vol1/ftp/release/20130502/ After downloading the raw vcf, we need to normalize the variants, split multiallelic variants, rename the variant and remove duplicates. Also, we need to extract out target ancestry and recalculate the allele frequency. Create a sample list for EAS samples awk '$3==\"EAS\"{print $1}' integrated_call_samples_v3.20130502.ALL.panel >EAS.sample 1000 genome: #!/bin/bash for chr in {1..2} do bcftools view -S EAS.sample ALL.chr\"${chr}\".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz | \\ bcftools norm -m-any --check-ref w -f human_g1k_v37.fasta | \\ bcftools annotate -x ID,INFO -I +'%CHROM:%POS:%REF:%ALT' | \\ bcftools norm --rm-dup both | \\ bcftools +fill-tags -Oz -- -t AF \\ > EAS.chr\"${chr}\".split_norm_af.vcf.gz tabix -p vcf EAS.chr\"${chr}\".split_norm_af.vcf.gz done","title":"1000 Genome"},{"location":"Reference/#dbsnp","text":"rsID database. dbsnp v151 (hg19): https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz latest release: Index of /snp/latest_release/VCF","title":"dbsnp"},{"location":"Reference/#gnomad","text":"Allele frequency for major ancestries and rsID gnomAD v2 & gnomAD v2 liftover & gnomAD v3: gnomAD","title":"gnomad"},{"location":"Standardization/","text":"Standardization and normalization import gwaslab as gl sumstats = gl.Sumstats(...) After loading raw sumstats into gwaslab Sumstats Object, the first thing we probably want to do is to standardize the variant-related notations and check if there are any unexpected errors in the statistics. When checking is finished, the status code will be automatically changed. Methods Summary Sumstats Methods Options Description .fix_ID() fixchrpos=False , fixid=False , overwrite=False check and fix rsID or SNPID(chr:pos:ref:alt), or use snpid to fix CHR and POS .fix_CHR() remove=False standardize chromsome notation .fix_POS() remove=False standardize basepair posituion notation and filter out bad values .fix_allele() remove=False standardize base notation to ATCG .normalize_allele() n_cores=1 normalize indels (only support ATA:AA -> AT:A but not -:T) .sort_coordinate() sort the variant coordinates 1. IDs Gwaslab requires at least one ID columns for sumstats, either in the form of SNPID or rsID, (or both). Gwaslab will automatically check if SNPID is mixed in rsID. SNPID : it could be user provided IDs, or in CHR:POS:REF:ALT format, delimiter can be\":\",\"_\" or \"-\" rsID : dbSNP rsIDs gwaslab checks if the IDs you provided is valid SNPID or rsID. It can also extract CHR and POS information from the CHR:POS:REF:ALT formatted IDs using .fix_ID() method. SNPID will be fixed by CHR:POS:NEA:EA only when the variants is already aligned with reference genome. Otherwise, a temporary SNPID in the format of CHR:POS will be given. .fix_ID() : check or fix SNPID and rsID. sumstats.fixID(fixchrpos=False, fixid=False, overwrite=False) 2. CHR .fix_CHR() CHR will be standardized to 1-22,X,Y,MT Leading \"chr\" and leading 0s will be stripped. sumstats.fix_CHR(remove=False) 3. POS .fix_POS() Values in POS must be positive integer numbers. Basepair position will be force converted to integers. Invalid pos will be converted to NA. (not implemented yet) After conversion, gwaslab will also sanity check if POS is in the range of 1 to 300,000,000. (the longest chromosome, CHR1, is around 250,000,000bp long) sumstats.fix_POS(remove=False) 4. Allele 4.1 Standardization .fix_allele() Currently, gwaslab only support processing SNPs and INDELs. All alleles will be checked if containing letters other than ATCG . Copy number variant (CNV) like <CN0> won't be recognized. Lower cases will converted to UPPERCASES. sumstats.fix_allele(remove=False) 4.2 Normalization .normalize_allele() Alleles will be normalized accroding to left alignment and parsimony principal. (For details: add link here ) For example, chr1:123456:ATG:AT will be normalized to chr1:123455:TG:T. Note: Currently, the normalizeation is implemented without checking reference, which means it can not normalize variants like chr1:123456:G:- if the missing information need to be obtained from a reference genome. sumstats.normalize_allele(n_cores=1) 5. Coordinate sorting Sort genomic coordinates\uff0c 1-22 X Y MT sumstats.sort_coordinate() 6. Column sorting The default column order is \"SNPID\",\"rsID\", \"CHR\", \"POS\", \"EA\", \"NEA\", \"EAF\", \"BETA\", \"SE\", \"Z\", \"CHISQ\", \"P\", \"MLOG10P\", \"OR\", \"OR_SE\", \"OR_95L\", \"OR_95U\", \"INFO\", \"N\",\"DIRECTION\",\"STATUS\" and other additional columns. sumstats.sort_columns()","title":"Standardization&normalization"},{"location":"Standardization/#standardization-and-normalization","text":"import gwaslab as gl sumstats = gl.Sumstats(...) After loading raw sumstats into gwaslab Sumstats Object, the first thing we probably want to do is to standardize the variant-related notations and check if there are any unexpected errors in the statistics. When checking is finished, the status code will be automatically changed.","title":"Standardization and normalization"},{"location":"Standardization/#methods-summary","text":"Sumstats Methods Options Description .fix_ID() fixchrpos=False , fixid=False , overwrite=False check and fix rsID or SNPID(chr:pos:ref:alt), or use snpid to fix CHR and POS .fix_CHR() remove=False standardize chromsome notation .fix_POS() remove=False standardize basepair posituion notation and filter out bad values .fix_allele() remove=False standardize base notation to ATCG .normalize_allele() n_cores=1 normalize indels (only support ATA:AA -> AT:A but not -:T) .sort_coordinate() sort the variant coordinates","title":"Methods Summary"},{"location":"Standardization/#1-ids","text":"Gwaslab requires at least one ID columns for sumstats, either in the form of SNPID or rsID, (or both). Gwaslab will automatically check if SNPID is mixed in rsID. SNPID : it could be user provided IDs, or in CHR:POS:REF:ALT format, delimiter can be\":\",\"_\" or \"-\" rsID : dbSNP rsIDs gwaslab checks if the IDs you provided is valid SNPID or rsID. It can also extract CHR and POS information from the CHR:POS:REF:ALT formatted IDs using .fix_ID() method. SNPID will be fixed by CHR:POS:NEA:EA only when the variants is already aligned with reference genome. Otherwise, a temporary SNPID in the format of CHR:POS will be given. .fix_ID() : check or fix SNPID and rsID. sumstats.fixID(fixchrpos=False, fixid=False, overwrite=False)","title":"1. IDs"},{"location":"Standardization/#2-chr","text":".fix_CHR() CHR will be standardized to 1-22,X,Y,MT Leading \"chr\" and leading 0s will be stripped. sumstats.fix_CHR(remove=False)","title":"2. CHR"},{"location":"Standardization/#3-pos","text":".fix_POS() Values in POS must be positive integer numbers. Basepair position will be force converted to integers. Invalid pos will be converted to NA. (not implemented yet) After conversion, gwaslab will also sanity check if POS is in the range of 1 to 300,000,000. (the longest chromosome, CHR1, is around 250,000,000bp long) sumstats.fix_POS(remove=False)","title":"3. POS"},{"location":"Standardization/#4-allele","text":"","title":"4. Allele"},{"location":"Standardization/#41-standardization","text":".fix_allele() Currently, gwaslab only support processing SNPs and INDELs. All alleles will be checked if containing letters other than ATCG . Copy number variant (CNV) like <CN0> won't be recognized. Lower cases will converted to UPPERCASES. sumstats.fix_allele(remove=False)","title":"4.1 Standardization"},{"location":"Standardization/#42-normalization","text":".normalize_allele() Alleles will be normalized accroding to left alignment and parsimony principal. (For details: add link here ) For example, chr1:123456:ATG:AT will be normalized to chr1:123455:TG:T. Note: Currently, the normalizeation is implemented without checking reference, which means it can not normalize variants like chr1:123456:G:- if the missing information need to be obtained from a reference genome. sumstats.normalize_allele(n_cores=1)","title":"4.2 Normalization"},{"location":"Standardization/#5-coordinate-sorting","text":"Sort genomic coordinates\uff0c 1-22 X Y MT sumstats.sort_coordinate()","title":"5. Coordinate sorting"},{"location":"Standardization/#6-column-sorting","text":"The default column order is \"SNPID\",\"rsID\", \"CHR\", \"POS\", \"EA\", \"NEA\", \"EAF\", \"BETA\", \"SE\", \"Z\", \"CHISQ\", \"P\", \"MLOG10P\", \"OR\", \"OR_SE\", \"OR_95L\", \"OR_95U\", \"INFO\", \"N\",\"DIRECTION\",\"STATUS\" and other additional columns. sumstats.sort_columns()","title":"6. Column sorting"},{"location":"StatusCode/","text":"A 7-digit code: showing the status of a variants. Reflecting the reliability of the statistics. Design principals: Tracable Higher value ->higer uncertainty Digit Description 1,2 Genome_build 3 rsID & SNPID 4 CHR, POS 5 EA, NEA 6 REF-NEA Alignment 7 Palindromic SNPs + Indels","title":"StatusCode"},{"location":"SumstatsObject/","text":"Sumstats Object in gwaslab In gwaslab, sumstats were stored in a Sumstats Object \uff0cwhich is built on pandas Dataframe . All other function are designed as methods of this Sumstats Object. To load any sumstats into the object, simply specify the column name and load the raw GWAS summary statsitics from a pandas dataframe or specifying file path. All raw data will be loaded as \"string\" datatype. mysumstats = gl.Sumstats( sumstats, snpid=None, rsid=None, chrom=None, pos=None, ea=None, nea=None, eaf=None, n=None, beta=None, se=None, chisq=None, z=None, p=None, mlog10p=None, info=None, OR=None, OR_se=None, OR_95L=None, OR_95U=None, status=None, other=[], direction=None, verbose=True, build=\"00\", **args ) sumstats : either a file path or a pandas DataFrame Currently, gwaslab supports the following columns: snpid : variant ID column, preferably in chr:pos:ea:nea format. rsid : dbSNP rsID column The minimum required columns are just either rsid or snpid . All other columns are optional. chrom : chromosome column pos : basepair position column ea : effect allele column nea : non-effect allele column eaf : effect allele frequency n : sample size column or just input a single integer beta : effect size beta se : standard error chisq : chi square z : z score p : p value mlog10p : -log10(P) info : imputation info or rsq OR : odds ratio OR_SE : odds ratio se OR_95L :odds ratio lower 95% ci OR_95U :odds ratio upper 95% ci direction : direction column in METAL format (e.g. \"++--+?+\") other : a list of other column names you want to keep with the core columns, probably some annotations. status : gwaslab 5-digit vairants status code. For details, please check status code page. verbose : if true: output log build : str genome build (\"19\",\"38\",\"00\") **arg : additional parameters for pl.read_table function. After loading, the raw data columns will be renamed to new columns without ambiguity and the dataframe is store in .data : mysumstats.data All manipulation conducted to the sumstats will be logged for reproducibility and traceability. The log is stored in a gl.Log object . You can check it by .log.show() and save it using .log.save() mysumstats.log.show() mysumstats.log.save() You can check the meta information of this sumstats by: (to be implemented) mysumstats.summary() Other functions of gwaslab is implemented as the methods of Sumstats Object. mysumstats.basic_check() mysumstats.plot_mqq()","title":"SumstatsObject"},{"location":"SumstatsObject/#sumstats-object-in-gwaslab","text":"In gwaslab, sumstats were stored in a Sumstats Object \uff0cwhich is built on pandas Dataframe . All other function are designed as methods of this Sumstats Object. To load any sumstats into the object, simply specify the column name and load the raw GWAS summary statsitics from a pandas dataframe or specifying file path. All raw data will be loaded as \"string\" datatype. mysumstats = gl.Sumstats( sumstats, snpid=None, rsid=None, chrom=None, pos=None, ea=None, nea=None, eaf=None, n=None, beta=None, se=None, chisq=None, z=None, p=None, mlog10p=None, info=None, OR=None, OR_se=None, OR_95L=None, OR_95U=None, status=None, other=[], direction=None, verbose=True, build=\"00\", **args ) sumstats : either a file path or a pandas DataFrame Currently, gwaslab supports the following columns: snpid : variant ID column, preferably in chr:pos:ea:nea format. rsid : dbSNP rsID column The minimum required columns are just either rsid or snpid . All other columns are optional. chrom : chromosome column pos : basepair position column ea : effect allele column nea : non-effect allele column eaf : effect allele frequency n : sample size column or just input a single integer beta : effect size beta se : standard error chisq : chi square z : z score p : p value mlog10p : -log10(P) info : imputation info or rsq OR : odds ratio OR_SE : odds ratio se OR_95L :odds ratio lower 95% ci OR_95U :odds ratio upper 95% ci direction : direction column in METAL format (e.g. \"++--+?+\") other : a list of other column names you want to keep with the core columns, probably some annotations. status : gwaslab 5-digit vairants status code. For details, please check status code page. verbose : if true: output log build : str genome build (\"19\",\"38\",\"00\") **arg : additional parameters for pl.read_table function. After loading, the raw data columns will be renamed to new columns without ambiguity and the dataframe is store in .data : mysumstats.data All manipulation conducted to the sumstats will be logged for reproducibility and traceability. The log is stored in a gl.Log object . You can check it by .log.show() and save it using .log.save() mysumstats.log.show() mysumstats.log.save() You can check the meta information of this sumstats by: (to be implemented) mysumstats.summary() Other functions of gwaslab is implemented as the methods of Sumstats Object. mysumstats.basic_check() mysumstats.plot_mqq()","title":"Sumstats Object in gwaslab"},{"location":"Tutorial/","text":"Quick Start Using a jupyter notebook, we first import gwaslab package: import gwaslab as gl The sample sumstats we use in this study: !wget -O t2d_bbj.txt.gz http://jenger.riken.jp/14/ Let's import this raw sumstats into the gwaslab Sumstats Object by specifying the necessary columns, and all data are imported as strings. mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", snpid=\"SNP\", chrom=\"CHR\", pos=\"POS\", ea=\"ALT\", nea=\"REF\", eaf=\"Frq\", beta=\"BETA\", se=\"SE\", p=\"P\", direction=\"Dir\", n=\"N\", build=\"19\") See details in SumstatsObject . Maybe the first thing you want to check is the manhattan plot, you can do this with one line of code, gwaslab will perform a minimum QC for just the plotting. mysumstats.plot_mqq() Standardization & normalization & sanity check Looks good, but we need to perform QC to make sure there are no unexpected errors: simply run: mysumstats.basic_check() .basic_check() is a wrapper of all the following basic functions, you can use these separately. mysumstats.fix_ID() mysumstats.fix_chr() mysumstats.fix_pos() mysumstats.fix_allele() mysumstats.check_sanity() mysumstats.normalize_allele() See details in Standardization . Filtering There are more than 10 million variants in the original sumstats and it will take long to process the entrie dataset. So, let's just filter-in (include) variants with P<0.00005 and filter-out (exclude) variants on ChrX. This could also be used for filtering other columns like INFO,N and so forth if you need. mysumstats.filter_in(lt={\"P\":0.00005}) mysumstats.filter_out(eq={\"CHR\":\"X\"}) See details in QC&Filtering . Extract lead variants Let's extract the lead variants in each significant loci to check our data. The significant loci are detected based on a sliding window (default window size: 500kb) mysumstats.get_lead() See details in ExtractLead . Customized manhattan plot GWASlab can plot more complicated manhattan plot: (not finished yet) mysumstats.plot_mqq(cut=20, skip=2, anno=True, anno_set=[], highlight=[], pinpoint=[] ) See details in Visualization . Harmonise the sumstats All-in-one function After checking the basics of the sumstats, next we may need to harmonise the sumstats for downstream analysis. For harmonization, we need reference files fasta and vcf. sumstats.harmonise( basic_check=False, ref_seq=\u201c./human_g1k_v37.fasta.gz\u201d, ref_rsid=\u201c./00-All.vcf.gz\u201d, ref_infer=\u201c./EAS.all.split_norm_af.vcf.gz\u201d, ref_alt_freq=\u201cAF\u201d, ) ref_seq : reference genome sequence in fasta format for alignment ref_rsid : reference vcf for rsID annotation ref_infer : reference vcf for strand inferring (require allele frequency in INFO filed.) ref_alt_freq : key word for alternative allele frequency in the reference vcf file. Some available and reliable reference files we can use: reference genome sequence fasta file. (For example, in the tutorial, hg19 reference sequence human_g1k_v37.fasta.gz from http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/ will be used) reference vcf file for rsID annotation (For example: https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz ) reference vcf for allele frequency (can be the same as 2, for example from 1KG Index of /vol1/ftp/release/20130502/ (manipulation of the vcf is needed) or gnomad). See details in Reference . .harmonise() is basically a wrapper of the following functions. mysumstats.basic_check() mysumstats.check_ref() mysumstats.flip_allele_stats() mysumstats.infer_strand() See details in Harmonization . Align with reference genome let's then align the NEA (non-effect allele) with reference sequence from a fasta file. mysumstats.check_ref(ref_path = \"./human_g1k_v37.fasta.gz\") In this case, the hg19 reference genome was downloaded from 1KG. Filp allele-specific statistics Gwaslab will check the status code and flip only those needed. mysumstats.flip_allele_stats() Annotate rsID Gwaslab can annotate the vairant with rsID using a reference vcf. For this purpose, we use the vcf file provided by dbsnp. (In this tutorial, b151/hg19 version was used) mmysumstats.flip_allele_stats(path=\"./00-All.vcf.gz\") Infer strand for palindromic SNPs and check ref allele for indels After the alignment with reference genome sequence, next we try to infer the strand of palindromic SNPs and also check the ref allele for indels. Note: GWASLab will only infer the strand for those that are already aligned with reference genome. mysumstats.infer_strand(ref_infer=\"./EAS.all.split_norm_af.vcf.gz\", ref_alt_freq=\"AF\") See details in Reference on how to process the 1000 genome raw vcf. Filp allele-specific statistics again for palindromic SNPs and indels Gwaslab will check the status code and flip only those needed. mysumstats.flip_allele_stats() Check difference in allele frequency After aligment and correct strands for panlindromic SNPs, you may want to double check the differences in allele frequency between the EAF from sumstats and ALT allele frequency in a reference vcf (For example ,1000 genome) See details in Reference on how to process the 1000 genome raw vcf. You can simply use .check_daf() to check the difference in allele frequencies: mysumstats.check_daf() After checking, use plot_daf() to visualize the results. It will generate two figures: 1. a scatter plot 2. a distribution plot. Plot DAF mysumstats.plot_daf() Liftover mysumstats.liftover(n_cores=1,from_build=\"19\", to_build=\"38\") Gwaslab only liftover CHR and POS, and when lifted, the last two digits status code will be rolled back to 99. Since for difference reference genome, the reference allele or strand might be reverse, so it is need to align and check agin. See details in Harmonization .","title":"Tutorial"},{"location":"Tutorial/#quick-start","text":"Using a jupyter notebook, we first import gwaslab package: import gwaslab as gl The sample sumstats we use in this study: !wget -O t2d_bbj.txt.gz http://jenger.riken.jp/14/ Let's import this raw sumstats into the gwaslab Sumstats Object by specifying the necessary columns, and all data are imported as strings. mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", snpid=\"SNP\", chrom=\"CHR\", pos=\"POS\", ea=\"ALT\", nea=\"REF\", eaf=\"Frq\", beta=\"BETA\", se=\"SE\", p=\"P\", direction=\"Dir\", n=\"N\", build=\"19\") See details in SumstatsObject . Maybe the first thing you want to check is the manhattan plot, you can do this with one line of code, gwaslab will perform a minimum QC for just the plotting. mysumstats.plot_mqq()","title":"Quick Start"},{"location":"Tutorial/#standardization-normalization-sanity-check","text":"Looks good, but we need to perform QC to make sure there are no unexpected errors: simply run: mysumstats.basic_check() .basic_check() is a wrapper of all the following basic functions, you can use these separately. mysumstats.fix_ID() mysumstats.fix_chr() mysumstats.fix_pos() mysumstats.fix_allele() mysumstats.check_sanity() mysumstats.normalize_allele() See details in Standardization .","title":"Standardization &amp; normalization &amp; sanity check"},{"location":"Tutorial/#_1","text":"","title":""},{"location":"Tutorial/#filtering","text":"There are more than 10 million variants in the original sumstats and it will take long to process the entrie dataset. So, let's just filter-in (include) variants with P<0.00005 and filter-out (exclude) variants on ChrX. This could also be used for filtering other columns like INFO,N and so forth if you need. mysumstats.filter_in(lt={\"P\":0.00005}) mysumstats.filter_out(eq={\"CHR\":\"X\"}) See details in QC&Filtering .","title":"Filtering"},{"location":"Tutorial/#extract-lead-variants","text":"Let's extract the lead variants in each significant loci to check our data. The significant loci are detected based on a sliding window (default window size: 500kb) mysumstats.get_lead() See details in ExtractLead .","title":"Extract lead variants"},{"location":"Tutorial/#customized-manhattan-plot","text":"GWASlab can plot more complicated manhattan plot: (not finished yet) mysumstats.plot_mqq(cut=20, skip=2, anno=True, anno_set=[], highlight=[], pinpoint=[] ) See details in Visualization .","title":"Customized manhattan plot"},{"location":"Tutorial/#_2","text":"","title":""},{"location":"Tutorial/#harmonise-the-sumstats","text":"","title":"Harmonise the sumstats"},{"location":"Tutorial/#all-in-one-function","text":"After checking the basics of the sumstats, next we may need to harmonise the sumstats for downstream analysis. For harmonization, we need reference files fasta and vcf. sumstats.harmonise( basic_check=False, ref_seq=\u201c./human_g1k_v37.fasta.gz\u201d, ref_rsid=\u201c./00-All.vcf.gz\u201d, ref_infer=\u201c./EAS.all.split_norm_af.vcf.gz\u201d, ref_alt_freq=\u201cAF\u201d, ) ref_seq : reference genome sequence in fasta format for alignment ref_rsid : reference vcf for rsID annotation ref_infer : reference vcf for strand inferring (require allele frequency in INFO filed.) ref_alt_freq : key word for alternative allele frequency in the reference vcf file. Some available and reliable reference files we can use: reference genome sequence fasta file. (For example, in the tutorial, hg19 reference sequence human_g1k_v37.fasta.gz from http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/ will be used) reference vcf file for rsID annotation (For example: https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz ) reference vcf for allele frequency (can be the same as 2, for example from 1KG Index of /vol1/ftp/release/20130502/ (manipulation of the vcf is needed) or gnomad). See details in Reference . .harmonise() is basically a wrapper of the following functions. mysumstats.basic_check() mysumstats.check_ref() mysumstats.flip_allele_stats() mysumstats.infer_strand() See details in Harmonization .","title":"All-in-one function"},{"location":"Tutorial/#align-with-reference-genome","text":"let's then align the NEA (non-effect allele) with reference sequence from a fasta file. mysumstats.check_ref(ref_path = \"./human_g1k_v37.fasta.gz\") In this case, the hg19 reference genome was downloaded from 1KG.","title":"Align with reference genome"},{"location":"Tutorial/#filp-allele-specific-statistics","text":"Gwaslab will check the status code and flip only those needed. mysumstats.flip_allele_stats()","title":"Filp allele-specific statistics"},{"location":"Tutorial/#annotate-rsid","text":"Gwaslab can annotate the vairant with rsID using a reference vcf. For this purpose, we use the vcf file provided by dbsnp. (In this tutorial, b151/hg19 version was used) mmysumstats.flip_allele_stats(path=\"./00-All.vcf.gz\")","title":"Annotate rsID"},{"location":"Tutorial/#infer-strand-for-palindromic-snps-and-check-ref-allele-for-indels","text":"After the alignment with reference genome sequence, next we try to infer the strand of palindromic SNPs and also check the ref allele for indels. Note: GWASLab will only infer the strand for those that are already aligned with reference genome. mysumstats.infer_strand(ref_infer=\"./EAS.all.split_norm_af.vcf.gz\", ref_alt_freq=\"AF\") See details in Reference on how to process the 1000 genome raw vcf.","title":"Infer strand for palindromic SNPs and check ref allele for indels"},{"location":"Tutorial/#filp-allele-specific-statistics-again-for-palindromic-snps-and-indels","text":"Gwaslab will check the status code and flip only those needed. mysumstats.flip_allele_stats()","title":"Filp allele-specific statistics again for palindromic SNPs and indels"},{"location":"Tutorial/#check-difference-in-allele-frequency","text":"After aligment and correct strands for panlindromic SNPs, you may want to double check the differences in allele frequency between the EAF from sumstats and ALT allele frequency in a reference vcf (For example ,1000 genome) See details in Reference on how to process the 1000 genome raw vcf. You can simply use .check_daf() to check the difference in allele frequencies: mysumstats.check_daf() After checking, use plot_daf() to visualize the results. It will generate two figures: 1. a scatter plot 2. a distribution plot.","title":"Check difference in allele frequency"},{"location":"Tutorial/#plot-daf","text":"mysumstats.plot_daf()","title":"Plot DAF"},{"location":"Tutorial/#liftover","text":"mysumstats.liftover(n_cores=1,from_build=\"19\", to_build=\"38\") Gwaslab only liftover CHR and POS, and when lifted, the last two digits status code will be rolled back to 99. Since for difference reference genome, the reference allele or strand might be reverse, so it is need to align and check agin. See details in Harmonization .","title":"Liftover"},{"location":"Visualization/","text":"Visualization Manhattan and QQ plot (MQQ plot) Scatter plot: Effect size comparison Heatmap: Genetic correlation matrix Scatter & Distribution plot : allele frequency comparison Manhattan plot and QQ plot import gwaslab as gl mydata = gl.Sumstats(....) mydata.plot_mqq( snpid=None, scaled=False, eaf=None, cut=0, cutfactor=10, mode=\"mqq\", mqqratio=3, cut_line_color=\"#ebebeb\", windowsizekb=500, anno=None, sig_level=5e-8, sig_line_color=\"grey\", suggestive_sig_level=5e-6, stratified=False, maf_bins=[(0, 0.01), (0.01, 0.05), (0.05, 0.25),(0.25,0.5)], maf_bin_colors = [\"#f0ad4e\",\"#5cb85c\", \"#5bc0de\",\"#000042\"], highlight = [], highlight_color =\"#33FFA0\", highlight_windowkb = 500, pinpoint=[], pinpoint_color =\"#f55142\", title =None, mtitle=None, qtitle=None, figargs= {\"figsize\":(15,5)}, fontsize = 10, colors = [\"#000042\", \"#7878BA\"], use_rank=False, verbose=True, repel_force=0.03, title_pad=1.08, gc=True, save=None, saveargs={\"dpi\":400,\"facecolor\":\"white\"}, log=gl.Log() ) Manhattan and QQ plot layout mode : determine the layout of manhattan plot and qq plot. \"mqq\" or \"qqm\" : side-by-side manhattan and QQ plt. mqq : left manhatan, right QQ qqm : left QQ , right manhatan \"m\" : only manhattan plot \"qq\" : only qq plot mqqratio : width ratio Skip \"low\" and shrink \"high\" skip : sometimes it is not necessary to plot all variants, we can skip the insignicant variants . For example, we can exclude varints with -log10p lower than 3 from the plot by specifying skip=3 cut : loci with extremly large -log10(P) value are very likely to dwarf other significant loci , so we want to scale down the extrame loci from a certain threshold. cutfactor : shrinkage factor, default is 10 cut_line_color : the color of the line above which y axis is rescaled Annotation with chr:pos or a given column anno : True or a list if anno == True: the variants to annotate will be selected atomatically using a sliding window with windowsize=500 (kb). if anno=\"col_name\": if a list is provided: repel_force : when the annotation overlaps with other, try increasing the repel_force to increase the padding between annotations. anno_set : if you want to annoatte only a few specific variants, you can simply provide a list of SNPIDs. Highlight specified loci Highlight specified loci. highlight : specify the lead variants of loci for highlighting. highlight_color : specify the color ussed for highlighting. highlight_windowkb : specify the span of highlighted region ( in kp) Pinpoint specified variants Pinpoint certain variants in the manhattan plot. pinpint : a list of SNPIDs pinpoint_color : color for pinpoint Maf-stratified QQ plot stratified : If True, plot MAF straitified QQ plot. maf_bins : maf bins for straitification. maf_bin_colors : colors used for each bin. Use rank or POS use_rank : if True, use the rank instead of real base pair position. use simply rank and basepair position to draw the x axis. Colors Quick plot Customized plot","title":"Manhattan&QQ"},{"location":"Visualization/#visualization","text":"Manhattan and QQ plot (MQQ plot) Scatter plot: Effect size comparison Heatmap: Genetic correlation matrix Scatter & Distribution plot : allele frequency comparison","title":"Visualization"},{"location":"Visualization/#manhattan-plot-and-qq-plot","text":"import gwaslab as gl mydata = gl.Sumstats(....) mydata.plot_mqq( snpid=None, scaled=False, eaf=None, cut=0, cutfactor=10, mode=\"mqq\", mqqratio=3, cut_line_color=\"#ebebeb\", windowsizekb=500, anno=None, sig_level=5e-8, sig_line_color=\"grey\", suggestive_sig_level=5e-6, stratified=False, maf_bins=[(0, 0.01), (0.01, 0.05), (0.05, 0.25),(0.25,0.5)], maf_bin_colors = [\"#f0ad4e\",\"#5cb85c\", \"#5bc0de\",\"#000042\"], highlight = [], highlight_color =\"#33FFA0\", highlight_windowkb = 500, pinpoint=[], pinpoint_color =\"#f55142\", title =None, mtitle=None, qtitle=None, figargs= {\"figsize\":(15,5)}, fontsize = 10, colors = [\"#000042\", \"#7878BA\"], use_rank=False, verbose=True, repel_force=0.03, title_pad=1.08, gc=True, save=None, saveargs={\"dpi\":400,\"facecolor\":\"white\"}, log=gl.Log() )","title":"Manhattan plot and QQ plot"},{"location":"Visualization/#_1","text":"","title":""},{"location":"Visualization/#manhattan-and-qq-plot-layout","text":"mode : determine the layout of manhattan plot and qq plot. \"mqq\" or \"qqm\" : side-by-side manhattan and QQ plt. mqq : left manhatan, right QQ qqm : left QQ , right manhatan \"m\" : only manhattan plot \"qq\" : only qq plot mqqratio : width ratio","title":"Manhattan and QQ plot layout"},{"location":"Visualization/#skip-low-and-shrink-high","text":"skip : sometimes it is not necessary to plot all variants, we can skip the insignicant variants . For example, we can exclude varints with -log10p lower than 3 from the plot by specifying skip=3 cut : loci with extremly large -log10(P) value are very likely to dwarf other significant loci , so we want to scale down the extrame loci from a certain threshold. cutfactor : shrinkage factor, default is 10 cut_line_color : the color of the line above which y axis is rescaled","title":"Skip \"low\" and shrink \"high\""},{"location":"Visualization/#annotation-with-chrpos-or-a-given-column","text":"anno : True or a list if anno == True: the variants to annotate will be selected atomatically using a sliding window with windowsize=500 (kb). if anno=\"col_name\": if a list is provided: repel_force : when the annotation overlaps with other, try increasing the repel_force to increase the padding between annotations. anno_set : if you want to annoatte only a few specific variants, you can simply provide a list of SNPIDs.","title":"Annotation with chr:pos or a given column"},{"location":"Visualization/#highlight-specified-loci","text":"Highlight specified loci. highlight : specify the lead variants of loci for highlighting. highlight_color : specify the color ussed for highlighting. highlight_windowkb : specify the span of highlighted region ( in kp)","title":"Highlight specified loci"},{"location":"Visualization/#pinpoint-specified-variants","text":"Pinpoint certain variants in the manhattan plot. pinpint : a list of SNPIDs pinpoint_color : color for pinpoint","title":"Pinpoint specified variants"},{"location":"Visualization/#maf-stratified-qq-plot","text":"stratified : If True, plot MAF straitified QQ plot. maf_bins : maf bins for straitification. maf_bin_colors : colors used for each bin.","title":"Maf-stratified QQ plot"},{"location":"Visualization/#use-rank-or-pos","text":"use_rank : if True, use the rank instead of real base pair position. use simply rank and basepair position to draw the x axis.","title":"Use rank or POS"},{"location":"Visualization/#colors","text":"","title":"Colors"},{"location":"Visualization/#quick-plot","text":"","title":"Quick plot"},{"location":"Visualization/#customized-plot","text":"","title":"Customized plot"}]}