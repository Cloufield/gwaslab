{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"gwaslab (v3.3.0) Gwaslab : * A simple python package for handling GWAS sumstats. * Each process is modularized and can be customized to your needs. * Most manipulations are designed as methods of python object, gwaslab.Sumstats . import gwaslab as gl # load plink2 output mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", fmt=\"plink2\", build=\"19\") # or you can specify the columns: mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", snpid=\"SNP\", chrom=\"CHR\", pos=\"POS\", ea=\"ALT\", nea=\"REF\", neaf=\"Frq\", beta=\"BETA\", se=\"SE\", p=\"P\", direction=\"Dir\", n=\"N\", build=\"19\") # manhattan and qq plot mysumstats.plot_mqq() ... Functions Standardization, Normalization & Harmonization CHR and POS notation standardization Variant POS and allele normalization Genome build : Liftover Reference allele alignment using a reference genome sequence rsID assignment based on CHR, POS, REF and ALT CHR POS assignment based on rsID using a reference VCF Palindromic SNPs and indels strand inference using a reference VCF Check allele frequency discrepancy using a reference VCF Quality control, Value conversion & Filtering Statistics sanity check Equivalent statistics conversion BETA/SE , OR/OR_95L/OR_95U P, Z, CHISQ, MLOG10 Extract/exclude hapmap3 variants Extract/exclude MHC variants Filtering values. Visualization Mqq plot : Manhattan plot and QQ plot side by side (with a bunch of customizable features including auto-annotate nearest gene names) Heatmap : ldsc-rg genetic correlation matrix Scatter Plot : variant effect size comparison with sumstats Scatter Plot : allele frequency comparison Forest Plot : forest plots for meta-analysis of SNPs Other Utilities Read ldsc h2 or rg outputs directly as DataFrames (auto-parsing). Extract lead variants given a sliding window size. Extract novel loci given a list of known lead variants. Logging : keep a complete record of manipulations from raw data to munged data. Sumstats summary function: know your data better. Formating GWAS sumstats in certain formats LDSC / MAGMA / METAL / MR-MEGA / FUMA / VCF / BED... check available formats Install pip install gwaslab==3.3.0 Requirements: Python >= 3.6 pySAM pyensembl scikit-allel Biopython >= 1.79 liftover >= 1.1.13 pandas >= 1.2.4 numpy >= 1.21.2 matplotlib >=3.5 seaborn >=0.11.1 scipy >=1.6.2 statsmodels > =0.13 adjustText Contacts Github: https://github.com/Cloufield/gwaslab Blog (in Chinese): https://gwaslab.com/ Email: gwaslab@gmail.com","title":"Home"},{"location":"#gwaslab-v330","text":"Gwaslab : * A simple python package for handling GWAS sumstats. * Each process is modularized and can be customized to your needs. * Most manipulations are designed as methods of python object, gwaslab.Sumstats . import gwaslab as gl # load plink2 output mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", fmt=\"plink2\", build=\"19\") # or you can specify the columns: mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", snpid=\"SNP\", chrom=\"CHR\", pos=\"POS\", ea=\"ALT\", nea=\"REF\", neaf=\"Frq\", beta=\"BETA\", se=\"SE\", p=\"P\", direction=\"Dir\", n=\"N\", build=\"19\") # manhattan and qq plot mysumstats.plot_mqq() ...","title":"gwaslab (v3.3.0)"},{"location":"#functions","text":"","title":"Functions"},{"location":"#standardization-normalization-harmonization","text":"CHR and POS notation standardization Variant POS and allele normalization Genome build : Liftover Reference allele alignment using a reference genome sequence rsID assignment based on CHR, POS, REF and ALT CHR POS assignment based on rsID using a reference VCF Palindromic SNPs and indels strand inference using a reference VCF Check allele frequency discrepancy using a reference VCF","title":"Standardization, Normalization &amp; Harmonization"},{"location":"#quality-control-value-conversion-filtering","text":"Statistics sanity check Equivalent statistics conversion BETA/SE , OR/OR_95L/OR_95U P, Z, CHISQ, MLOG10 Extract/exclude hapmap3 variants Extract/exclude MHC variants Filtering values.","title":"Quality control, Value conversion &amp; Filtering"},{"location":"#visualization","text":"Mqq plot : Manhattan plot and QQ plot side by side (with a bunch of customizable features including auto-annotate nearest gene names) Heatmap : ldsc-rg genetic correlation matrix Scatter Plot : variant effect size comparison with sumstats Scatter Plot : allele frequency comparison Forest Plot : forest plots for meta-analysis of SNPs","title":"Visualization"},{"location":"#other-utilities","text":"Read ldsc h2 or rg outputs directly as DataFrames (auto-parsing). Extract lead variants given a sliding window size. Extract novel loci given a list of known lead variants. Logging : keep a complete record of manipulations from raw data to munged data. Sumstats summary function: know your data better. Formating GWAS sumstats in certain formats LDSC / MAGMA / METAL / MR-MEGA / FUMA / VCF / BED... check available formats","title":"Other Utilities"},{"location":"#install","text":"pip install gwaslab==3.3.0","title":"Install"},{"location":"#requirements","text":"Python >= 3.6 pySAM pyensembl scikit-allel Biopython >= 1.79 liftover >= 1.1.13 pandas >= 1.2.4 numpy >= 1.21.2 matplotlib >=3.5 seaborn >=0.11.1 scipy >=1.6.2 statsmodels > =0.13 adjustText","title":"Requirements:"},{"location":"#contacts","text":"Github: https://github.com/Cloufield/gwaslab Blog (in Chinese): https://gwaslab.com/ Email: gwaslab@gmail.com","title":"Contacts"},{"location":"AlleleFrequency/","text":"Scatter & Distribution plot : allele frequency comparison sumstats.plot_daf()","title":"Scatter: allele frequency comparison"},{"location":"Conversion/","text":"Statistics conversion gwaslab can convert equvalent statistics, including: - P => MLOG10P - MLOG10P => P - Z => P - CHISQ => P - BETA/SE => OR/OR_95L/OR_95U - OR/OR_95L/OR_95U => BETA/SE - BETA/SE => Z - P => CHISQ - Z => CHISQ fill_data() mysumstats.fill_data( to_fill=[], df=None, overwrite=False, only_sig=False ) Options to_fill : the columns to fill. [\"OR\",\"OR_95L\",\"OR_95U\",\"BETA\",\"SE\",\"P\",\"MLOG10P\",\"Z\",\"CHISQ\"] df : columns name for degree of freedom overwrite : if overwrite when the specified column existed only_sig : fill the data only for significant variants Example # raw data #SNPID CHR POS EA NEA EAF BETA SE P STATUS #1:725932_G_A 1 725932 G A 0.9960 -0.0737 0.1394 0.5970 9999999 #1:725933_A_G 1 725933 G A 0.0040 0.0737 0.1394 0.5973 9999999 #1:737801_T_C 1 737801 C T 0.0051 0.0490 0.1231 0.6908 9999999 # let's fill \"MLOG10P\",\"Z\",\"OR\",\"OR_95L\",\"OR_95U\" # gwaslab will automatically search for equivalent statistics mysumstats.fill_data(to_fill=[\"MLOG10P\",\"Z\",\"OR\",\"OR_95L\",\"OR_95U\"]) Wed Oct 19 10:13:30 2022 Start filling data using existing columns... Wed Oct 19 10:13:30 2022 -Raw input columns: ['SNPID', 'CHR', 'POS', 'EA', 'NEA', 'EAF', 'BETA', 'SE', 'P', 'STATUS'] Wed Oct 19 10:13:30 2022 -Overwrite mode: False Wed Oct 19 10:13:30 2022 - Skipping columns: [] Wed Oct 19 10:13:30 2022 Filling columns: ['MLOG10P', 'OR', 'OR_95L', 'OR_95U'] Wed Oct 19 10:13:30 2022 - Filling OR using BETA column... Wed Oct 19 10:13:31 2022 - Filling OR_95L/OR_95U using BETA/SE columns... Wed Oct 19 10:13:32 2022 - Filling MLOG10P using P column... Wed Oct 19 10:13:38 2022 Finished filling data using existing columns.","title":"Statistics conversion"},{"location":"Conversion/#statistics-conversion","text":"gwaslab can convert equvalent statistics, including: - P => MLOG10P - MLOG10P => P - Z => P - CHISQ => P - BETA/SE => OR/OR_95L/OR_95U - OR/OR_95L/OR_95U => BETA/SE - BETA/SE => Z - P => CHISQ - Z => CHISQ","title":"Statistics conversion"},{"location":"Conversion/#fill_data","text":"mysumstats.fill_data( to_fill=[], df=None, overwrite=False, only_sig=False )","title":"fill_data()"},{"location":"Conversion/#options","text":"to_fill : the columns to fill. [\"OR\",\"OR_95L\",\"OR_95U\",\"BETA\",\"SE\",\"P\",\"MLOG10P\",\"Z\",\"CHISQ\"] df : columns name for degree of freedom overwrite : if overwrite when the specified column existed only_sig : fill the data only for significant variants","title":"Options"},{"location":"Conversion/#example","text":"# raw data #SNPID CHR POS EA NEA EAF BETA SE P STATUS #1:725932_G_A 1 725932 G A 0.9960 -0.0737 0.1394 0.5970 9999999 #1:725933_A_G 1 725933 G A 0.0040 0.0737 0.1394 0.5973 9999999 #1:737801_T_C 1 737801 C T 0.0051 0.0490 0.1231 0.6908 9999999 # let's fill \"MLOG10P\",\"Z\",\"OR\",\"OR_95L\",\"OR_95U\" # gwaslab will automatically search for equivalent statistics mysumstats.fill_data(to_fill=[\"MLOG10P\",\"Z\",\"OR\",\"OR_95L\",\"OR_95U\"]) Wed Oct 19 10:13:30 2022 Start filling data using existing columns... Wed Oct 19 10:13:30 2022 -Raw input columns: ['SNPID', 'CHR', 'POS', 'EA', 'NEA', 'EAF', 'BETA', 'SE', 'P', 'STATUS'] Wed Oct 19 10:13:30 2022 -Overwrite mode: False Wed Oct 19 10:13:30 2022 - Skipping columns: [] Wed Oct 19 10:13:30 2022 Filling columns: ['MLOG10P', 'OR', 'OR_95L', 'OR_95U'] Wed Oct 19 10:13:30 2022 - Filling OR using BETA column... Wed Oct 19 10:13:31 2022 - Filling OR_95L/OR_95U using BETA/SE columns... Wed Oct 19 10:13:32 2022 - Filling MLOG10P using P column... Wed Oct 19 10:13:38 2022 Finished filling data using existing columns.","title":"Example"},{"location":"EffectSize/","text":"Scatter plot : effect size comparison gl.compare_effect( path1, cols_name_list_1, effect_cols_list_1, path2, cols_name_list_2, effect_cols_list_2, eaf=[], maf_level=None, label=[\"Sumstats_1\",\"Sumstats_2\",\"Both\",\"None\"], snplist=None, mode=\"beta\", anno=False, null_beta=0, is_q=True, q_level=0.05, sig_level=5e-8, legend_title=r'$ P < 5 x 10^{-8}$ in:', legend_pos='upper left', reg_box=dict(boxstyle='round', facecolor='white', alpha=1,edgecolor=\"grey\"), is_reg=True, is_45_helper_line=True, scatterargs={\"s\":20}, plt_args={\"figsize\":(8,8),\"dpi\":300}, xylabel_prefix=\"Per-allele effect size in \", helper_line_args={\"color\":'black', \"linestyle\":'-',\"lw\":1}, fontargs={'family':'sans','fontname':'Arial','fontsize':12}, errargs={\"ecolor\":\"#cccccc\",\"elinewidth\":1}, sep=[\"\\t\",\"\\t\"], log = Log(), verbose=False) path1 and path2 : the paths to the sumstats. cols_name_list_1 and cols_name_list_2 : list of column names for variants basic information, in the order of [snpid,p,ea,nea,chr,pos] effect_cols_list_1 and effect_cols_list_1 : list of column names for effect size-related columns, in the order of [effect,se] or [OR,OR_95L,OR_95H] eaf : optional, a list column names for effect allele frequency, in the order of [sumstats1_eaf, sumstats2_eaf]. It is needed when you need to filter by maf using maf_level . maf_level : the maf filter for variants. Vairants with maf < maf_level will be removed from comparison. label : a list of labels for the legend , in the order of [\"Sumstats_1\",\"Sumstats_2\",\"Both\",\"None\"]. snplist : optional, specify the variants you want to compare. If None, gwaslab will automatically extract lead variants from both sumstats. anno : if annotate the variants is_q : if apply the heterogeneity tests by Cochran's Q test. q_level : the significance threshold for Cochran's Q test. sig_level : the significance level for auto-extracting lead variants. Example: gl.compare()","title":"Scatter: effect size comparison"},{"location":"EffectSize/#scatter-plot-effect-size-comparison","text":"gl.compare_effect( path1, cols_name_list_1, effect_cols_list_1, path2, cols_name_list_2, effect_cols_list_2, eaf=[], maf_level=None, label=[\"Sumstats_1\",\"Sumstats_2\",\"Both\",\"None\"], snplist=None, mode=\"beta\", anno=False, null_beta=0, is_q=True, q_level=0.05, sig_level=5e-8, legend_title=r'$ P < 5 x 10^{-8}$ in:', legend_pos='upper left', reg_box=dict(boxstyle='round', facecolor='white', alpha=1,edgecolor=\"grey\"), is_reg=True, is_45_helper_line=True, scatterargs={\"s\":20}, plt_args={\"figsize\":(8,8),\"dpi\":300}, xylabel_prefix=\"Per-allele effect size in \", helper_line_args={\"color\":'black', \"linestyle\":'-',\"lw\":1}, fontargs={'family':'sans','fontname':'Arial','fontsize':12}, errargs={\"ecolor\":\"#cccccc\",\"elinewidth\":1}, sep=[\"\\t\",\"\\t\"], log = Log(), verbose=False) path1 and path2 : the paths to the sumstats. cols_name_list_1 and cols_name_list_2 : list of column names for variants basic information, in the order of [snpid,p,ea,nea,chr,pos] effect_cols_list_1 and effect_cols_list_1 : list of column names for effect size-related columns, in the order of [effect,se] or [OR,OR_95L,OR_95H] eaf : optional, a list column names for effect allele frequency, in the order of [sumstats1_eaf, sumstats2_eaf]. It is needed when you need to filter by maf using maf_level . maf_level : the maf filter for variants. Vairants with maf < maf_level will be removed from comparison. label : a list of labels for the legend , in the order of [\"Sumstats_1\",\"Sumstats_2\",\"Both\",\"None\"]. snplist : optional, specify the variants you want to compare. If None, gwaslab will automatically extract lead variants from both sumstats. anno : if annotate the variants is_q : if apply the heterogeneity tests by Cochran's Q test. q_level : the significance threshold for Cochran's Q test. sig_level : the significance level for auto-extracting lead variants. Example: gl.compare()","title":"Scatter plot : effect size comparison"},{"location":"ExtractLead/","text":"Extract lead variants mysumstats.get_lead( windowsizekb=500, sig_level=5e-8, xymt=[\"X\",\"Y\",\"MT\"], anno=False, build=\"19\", source=\"ensembl\", verbose=True) GWASLab will extract the lead variants from identified significant loci based on a sliding window (default window size: 500kb). (Details are described in ) Options: - windowsizekb :specify the sliding window size in kb (default: 500) - sig_level :specify the P value threshold (default: 5e-8). - xymt : list of notation for chrX, chrY and chrMT. - anno : boolean if annotate the lead variants with nearest gene names. - build : string genome build version \"19\" or \"38\". Return a dataframe of the lead variants Example Sample sumstats: IS from pheweb.jp https://pheweb.jp/pheno/IS mysumstats = gl.Sumstats(\"./hum0197.v3.BBJ.IS.v1/GWASsummary_IS_Japanese_SakaueKanai2020.auto.txt.gz\", fmt=\"saige\") mysumstats.get_lead()","title":"Extract Lead Variants"},{"location":"ExtractLead/#extract-lead-variants","text":"mysumstats.get_lead( windowsizekb=500, sig_level=5e-8, xymt=[\"X\",\"Y\",\"MT\"], anno=False, build=\"19\", source=\"ensembl\", verbose=True) GWASLab will extract the lead variants from identified significant loci based on a sliding window (default window size: 500kb). (Details are described in ) Options: - windowsizekb :specify the sliding window size in kb (default: 500) - sig_level :specify the P value threshold (default: 5e-8). - xymt : list of notation for chrX, chrY and chrMT. - anno : boolean if annotate the lead variants with nearest gene names. - build : string genome build version \"19\" or \"38\". Return a dataframe of the lead variants","title":"Extract lead variants"},{"location":"ExtractLead/#example","text":"Sample sumstats: IS from pheweb.jp https://pheweb.jp/pheno/IS mysumstats = gl.Sumstats(\"./hum0197.v3.BBJ.IS.v1/GWASsummary_IS_Japanese_SakaueKanai2020.auto.txt.gz\", fmt=\"saige\") mysumstats.get_lead()","title":"Example"},{"location":"ExtractNovel/","text":"Coming soon","title":"Extract Novel Variants"},{"location":"ExtractNovel/#coming-soon","text":"","title":"Coming soon"},{"location":"ForestPlot/","text":"Coming soon","title":"Forest Plot"},{"location":"ForestPlot/#coming-soon","text":"","title":"Coming soon"},{"location":"Format/","text":"Output sumstats in certain formats to_format( path=\"./sumstats\", fmt=\"ldsc\", extract=None, exclude=None, id_use=\"rsID\", hapmap3=False, exclude_hla=False, build=\"19\", verbose=True, output_log=True, to_csvargs={}, float_formats={}, xymt_number=False, xymt=[\"X\",\"Y\",\"MT\"], chr_prefix=None, bgzip=False, tabix=False ) path : string , the path for the output, only prefix is needed. fmt =\"ldsc\": output format for sumstats. Currently support plink , plink2 , ldsc , saige , fastgwa , regenie . For details , please check https://github.com/Cloufield/formatbook . extract : list , a list of variants to include. exclude : list , a list of variants to exclude. id_use : string , specify which ID to use when merging with Hapmap3 SNPs. hapmap3 : boolean , if True, only output Hapmap3 SNPs. exclude_hla : boolean , if True, exclude variants in MHC region from output. build : string , reference genome build. xymt_number : if True, output chrX/Y/MT as 23/24/25. xymt : list , descript how to convert chromosome 23,24,25. chr_prefix : string , add a prefix to chromosomes when output chr. 6 -> Chr6. bgzip : boolean , if True, bgzip the output file. Only works for bed format. tabix : boolean , if True, use tabix to index the bgzipped output file. Only works for bed format. to_csvargs : dict , extra parameters for pd.to_csv() float_formats : dict , a dictionary to specify the float format for each column. verbose : boolean , if True, print logs. output_log : boolean , if True, save log to a file. Example 1: import gwaslab as gl # load your raw sumstats mysumstats = gl.Sumstats(...) # basic QC mysumstats.basic_check() # output metal format mysumstats.to_format(\"./test\",fmt=\"metal\") log : Tue Sep 13 18:00:41 2022 Start to format the output sumstats in: metal format Tue Sep 13 18:00:41 2022 -Formatting statistics ... Tue Sep 13 18:00:41 2022 - Float statistics formats: Tue Sep 13 18:00:41 2022 - Columns: ['EAF', 'BETA', 'SE', 'P'] Tue Sep 13 18:00:41 2022 - Output formats: ['{:.4g}', '{:.4f}', '{:.4f}', '{:.4e}'] Tue Sep 13 18:00:41 2022 - Start outputting sumstats in metal format... Tue Sep 13 18:00:41 2022 -metal format will be loaded... Tue Sep 13 18:00:41 2022 -metal format meta info: Tue Sep 13 18:00:41 2022 - format_name : metal Tue Sep 13 18:00:41 2022 - format_source : https://genome.sph.umich.edu/wiki/METAL_Documentation Tue Sep 13 18:00:41 2022 - format_version : 20220726 Tue Sep 13 18:00:41 2022 -gwaslab to metal format dictionary: Tue Sep 13 18:00:41 2022 - gwaslab keys: ['SNPID', 'EA', 'NEA', 'EAF', 'BETA', 'SE', 'P', 'DIRECTION'] Tue Sep 13 18:00:41 2022 - metal values: ['MarkerName', 'Allele1', 'Allele2', 'Freq1', 'Effect', 'StdErr', 'P-value', 'Direction'] Tue Sep 13 18:00:41 2022 -Output columns: Index(['MarkerName', 'Allele1', 'Allele2', 'Freq1', 'Effect', 'StdErr', 'P-value'], dtype='object') Tue Sep 13 18:00:41 2022 -Output path: ./test.metal.tsv.gz Tue Sep 13 18:00:41 2022 -Saving log file: ./test.metal.log Tue Sep 13 18:00:41 2022 Finished outputting successfully! Example 2: LDSC format, extract hapmap3 SNPs and exclude SNPs in HLA region ## format the sumstats to ldsc format ## extract only hapmap3 SNPs ## exclude SNPs in HLA region mysumstats.to_format(\"./test\",fmt=\"ldsc\", hapmap3=True, exclude_hla=False, build=\"19\") Example 3: bed-like format # output 1-based bed-like files for vep mysumstats.to_format(\"./test\",fmt=\"vep\",xymt_number=True,chr_prefix=\"Chr\") # output 0-based bed-like file, and then bgzip and index the file. mysumstats.to_format(\"./test\",fmt=\"bed\",bgzip=True,tabix=True) Example 4: vcf format # output vcf file, and then bgzip and index the file. mysumstats.to_format(\"./test\",fmt=\"vcf\",bgzip=True,tabix=True) Example 5: GWAS-ssf # output GWAS-ssf format mysumstats.to_format(\"./test\",fmt=\"ssf\") For sample codes, please check https://github.com/Cloufield/gwaslab/blob/main/examples/IO_format.ipynb","title":"Format & Save"},{"location":"Format/#output-sumstats-in-certain-formats","text":"to_format( path=\"./sumstats\", fmt=\"ldsc\", extract=None, exclude=None, id_use=\"rsID\", hapmap3=False, exclude_hla=False, build=\"19\", verbose=True, output_log=True, to_csvargs={}, float_formats={}, xymt_number=False, xymt=[\"X\",\"Y\",\"MT\"], chr_prefix=None, bgzip=False, tabix=False ) path : string , the path for the output, only prefix is needed. fmt =\"ldsc\": output format for sumstats. Currently support plink , plink2 , ldsc , saige , fastgwa , regenie . For details , please check https://github.com/Cloufield/formatbook . extract : list , a list of variants to include. exclude : list , a list of variants to exclude. id_use : string , specify which ID to use when merging with Hapmap3 SNPs. hapmap3 : boolean , if True, only output Hapmap3 SNPs. exclude_hla : boolean , if True, exclude variants in MHC region from output. build : string , reference genome build. xymt_number : if True, output chrX/Y/MT as 23/24/25. xymt : list , descript how to convert chromosome 23,24,25. chr_prefix : string , add a prefix to chromosomes when output chr. 6 -> Chr6. bgzip : boolean , if True, bgzip the output file. Only works for bed format. tabix : boolean , if True, use tabix to index the bgzipped output file. Only works for bed format. to_csvargs : dict , extra parameters for pd.to_csv() float_formats : dict , a dictionary to specify the float format for each column. verbose : boolean , if True, print logs. output_log : boolean , if True, save log to a file.","title":"Output sumstats in certain formats"},{"location":"Format/#example-1","text":"import gwaslab as gl # load your raw sumstats mysumstats = gl.Sumstats(...) # basic QC mysumstats.basic_check() # output metal format mysumstats.to_format(\"./test\",fmt=\"metal\") log : Tue Sep 13 18:00:41 2022 Start to format the output sumstats in: metal format Tue Sep 13 18:00:41 2022 -Formatting statistics ... Tue Sep 13 18:00:41 2022 - Float statistics formats: Tue Sep 13 18:00:41 2022 - Columns: ['EAF', 'BETA', 'SE', 'P'] Tue Sep 13 18:00:41 2022 - Output formats: ['{:.4g}', '{:.4f}', '{:.4f}', '{:.4e}'] Tue Sep 13 18:00:41 2022 - Start outputting sumstats in metal format... Tue Sep 13 18:00:41 2022 -metal format will be loaded... Tue Sep 13 18:00:41 2022 -metal format meta info: Tue Sep 13 18:00:41 2022 - format_name : metal Tue Sep 13 18:00:41 2022 - format_source : https://genome.sph.umich.edu/wiki/METAL_Documentation Tue Sep 13 18:00:41 2022 - format_version : 20220726 Tue Sep 13 18:00:41 2022 -gwaslab to metal format dictionary: Tue Sep 13 18:00:41 2022 - gwaslab keys: ['SNPID', 'EA', 'NEA', 'EAF', 'BETA', 'SE', 'P', 'DIRECTION'] Tue Sep 13 18:00:41 2022 - metal values: ['MarkerName', 'Allele1', 'Allele2', 'Freq1', 'Effect', 'StdErr', 'P-value', 'Direction'] Tue Sep 13 18:00:41 2022 -Output columns: Index(['MarkerName', 'Allele1', 'Allele2', 'Freq1', 'Effect', 'StdErr', 'P-value'], dtype='object') Tue Sep 13 18:00:41 2022 -Output path: ./test.metal.tsv.gz Tue Sep 13 18:00:41 2022 -Saving log file: ./test.metal.log Tue Sep 13 18:00:41 2022 Finished outputting successfully!","title":"Example 1:"},{"location":"Format/#example-2-ldsc-format-extract-hapmap3-snps-and-exclude-snps-in-hla-region","text":"## format the sumstats to ldsc format ## extract only hapmap3 SNPs ## exclude SNPs in HLA region mysumstats.to_format(\"./test\",fmt=\"ldsc\", hapmap3=True, exclude_hla=False, build=\"19\")","title":"Example 2: LDSC format, extract hapmap3 SNPs and exclude SNPs in HLA region"},{"location":"Format/#example-3-bed-like-format","text":"# output 1-based bed-like files for vep mysumstats.to_format(\"./test\",fmt=\"vep\",xymt_number=True,chr_prefix=\"Chr\") # output 0-based bed-like file, and then bgzip and index the file. mysumstats.to_format(\"./test\",fmt=\"bed\",bgzip=True,tabix=True)","title":"Example 3: bed-like format"},{"location":"Format/#example-4-vcf-format","text":"# output vcf file, and then bgzip and index the file. mysumstats.to_format(\"./test\",fmt=\"vcf\",bgzip=True,tabix=True)","title":"Example 4: vcf format"},{"location":"Format/#example-5-gwas-ssf","text":"# output GWAS-ssf format mysumstats.to_format(\"./test\",fmt=\"ssf\") For sample codes, please check https://github.com/Cloufield/gwaslab/blob/main/examples/IO_format.ipynb","title":"Example 5: GWAS-ssf"},{"location":"Gallery/","text":"","title":"Gallery"},{"location":"GeneticCorrelation/","text":"load data plot","title":"Heatmap: genetic correlation"},{"location":"Harmonization/","text":"Harmonization Methods summary Sumstats Methods Options Description .check_ref() ref_path check alignment with a reference sequence .rsid_to_chrpos() path, n_cores use rsid to fill CHR and POS .rsid_to_chrpos2() path use rsid to fill CHR and POS (muilti-thread, need hd5 file) .assign_rsid() path annotate rsid using a reference vcf file .infer_strand() ref_infer=\"\" , ref_alt_freq=None, maf_threshold=0.43 infer the strand of a variant using reference vcf file with EAF in INFO .check_daf() ref_infer=\"\" , ref_alt_freq=None, calculate difference in allele frequencies .flip_allele_stats() After alignment and inferring, flip the alleles to harmonise the variants. .liftover() n_cores=1,from_build=\"19\", to_build=\"38\" perform liftover Align NEA with REF in reference genome mysumstats.check_ref(ref_path=\"ref_genome.fa\") (! Only changing the status code) Check if NEA is aligned with the reference sequence. After checking, the tracking status code will be changed accordingly. Assign CHR and POS according to rsID and reference data mysumstats.rsid_to_chrpos() #single thread mysumstats.rsid_to_chrpos2() #multithread (to be tested) Assign rsID according to CHR, POS, REF/ALT mysumstats.assign_rsid(path=\"reference.vcf.gz\") Annotated variants with rsID using a reference vcf file (tabix indexd). Gwaslab will first extract all variants in reference file with matching CHR and POS. And then comapre EA/NEA in sumstats with REF/ALT in reference vcf. When matching, it will annotate the vairant in sumstats with the matching rsID in reference vcf. Check panlidromic SNPs or undistingushable Indels mysumstats.infer_strand() (! Only changing the status code) Infer the strand for palindromic SNPs (AT, or CG), the default threshlod is 0.43. make sure specify the right allele frequency for you target ancestry in INFO field. Checking the alignment status of indels with the REF allele in reference vcf file. Check difference in allele frequency mysumstats.check_daf() You may want to check the allele frequency discrepancy with a reference vcf. Just specify the path and the right allele frequency for you target ancestry in INFO field. GWASlab will simply calculate DAF = AF-EAF - AF-ALT , and store the results in DAF column. DAF can then be used to plot or filter variants. mysumstats.plot_daf() Flipping based on status code mysumstats.flip_allele_stats() Flip allele-specific statistics to harmonise the variants based on the tracking status code Liftover mysumstats.liftover(n_cores=1,from_build=\"19\", to_build=\"38\") Perform liftover for POS (based on liftover GitHub - jeremymcrae/liftover: liftover for python, made fast with cython )","title":"Harmonization"},{"location":"Harmonization/#harmonization","text":"","title":"Harmonization"},{"location":"Harmonization/#methods-summary","text":"Sumstats Methods Options Description .check_ref() ref_path check alignment with a reference sequence .rsid_to_chrpos() path, n_cores use rsid to fill CHR and POS .rsid_to_chrpos2() path use rsid to fill CHR and POS (muilti-thread, need hd5 file) .assign_rsid() path annotate rsid using a reference vcf file .infer_strand() ref_infer=\"\" , ref_alt_freq=None, maf_threshold=0.43 infer the strand of a variant using reference vcf file with EAF in INFO .check_daf() ref_infer=\"\" , ref_alt_freq=None, calculate difference in allele frequencies .flip_allele_stats() After alignment and inferring, flip the alleles to harmonise the variants. .liftover() n_cores=1,from_build=\"19\", to_build=\"38\" perform liftover","title":"Methods summary"},{"location":"Harmonization/#align-nea-with-ref-in-reference-genome","text":"mysumstats.check_ref(ref_path=\"ref_genome.fa\") (! Only changing the status code) Check if NEA is aligned with the reference sequence. After checking, the tracking status code will be changed accordingly.","title":"Align NEA with REF in reference genome"},{"location":"Harmonization/#assign-chr-and-pos-according-to-rsid-and-reference-data","text":"mysumstats.rsid_to_chrpos() #single thread mysumstats.rsid_to_chrpos2() #multithread (to be tested)","title":"Assign CHR and POS according to rsID and reference data"},{"location":"Harmonization/#assign-rsid-according-to-chr-pos-refalt","text":"mysumstats.assign_rsid(path=\"reference.vcf.gz\") Annotated variants with rsID using a reference vcf file (tabix indexd). Gwaslab will first extract all variants in reference file with matching CHR and POS. And then comapre EA/NEA in sumstats with REF/ALT in reference vcf. When matching, it will annotate the vairant in sumstats with the matching rsID in reference vcf.","title":"Assign rsID according to CHR, POS, REF/ALT"},{"location":"Harmonization/#check-panlidromic-snps-or-undistingushable-indels","text":"mysumstats.infer_strand() (! Only changing the status code) Infer the strand for palindromic SNPs (AT, or CG), the default threshlod is 0.43. make sure specify the right allele frequency for you target ancestry in INFO field. Checking the alignment status of indels with the REF allele in reference vcf file.","title":"Check panlidromic SNPs or undistingushable Indels"},{"location":"Harmonization/#check-difference-in-allele-frequency","text":"mysumstats.check_daf() You may want to check the allele frequency discrepancy with a reference vcf. Just specify the path and the right allele frequency for you target ancestry in INFO field. GWASlab will simply calculate DAF = AF-EAF - AF-ALT , and store the results in DAF column. DAF can then be used to plot or filter variants. mysumstats.plot_daf()","title":"Check difference in allele frequency"},{"location":"Harmonization/#flipping-based-on-status-code","text":"mysumstats.flip_allele_stats() Flip allele-specific statistics to harmonise the variants based on the tracking status code","title":"Flipping based on status code"},{"location":"Harmonization/#liftover","text":"mysumstats.liftover(n_cores=1,from_build=\"19\", to_build=\"38\") Perform liftover for POS (based on liftover GitHub - jeremymcrae/liftover: liftover for python, made fast with cython )","title":"Liftover"},{"location":"HeritabilityConversion/","text":"Heritabilty conversion (Observed-scale -> Liability-scale) gl.h2_obs_to_liab(h2_obs, P, K, se_obs=None) h2_obs : float. Heritability on the observed scale in an ascertained sample. P : float in (0,1). Prevalence of the phenotype in the sample. K : float in (0,1) . Prevalence of the phenotype in the population. se_obs : float. se of h2_obs. Adopted from LDSC. Reference: Estimating Missing Heritability for Disease from Genome-wide Association Studies https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059431/","title":"Convert Heritability"},{"location":"HeritabilityConversion/#heritabilty-conversion-observed-scale-liability-scale","text":"gl.h2_obs_to_liab(h2_obs, P, K, se_obs=None) h2_obs : float. Heritability on the observed scale in an ascertained sample. P : float in (0,1). Prevalence of the phenotype in the sample. K : float in (0,1) . Prevalence of the phenotype in the population. se_obs : float. se of h2_obs. Adopted from LDSC. Reference: Estimating Missing Heritability for Disease from Genome-wide Association Studies https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059431/","title":"Heritabilty conversion (Observed-scale -&gt; Liability-scale)"},{"location":"InferBuild/","text":"Infer Genome Build Version gwaslab use hapmaps chromosome and basepair position information to infer the reference genome build for sumstats. Status codes (first two digits) will be changed based on the results Example: mysumstats.infer_build() Wed Oct 19 11:01:01 2022 -Start to infer genome build version using hapmap3 SNPs... Wed Oct 19 11:01:01 2022 -Loading Hapmap3 variants data... Wed Oct 19 11:01:04 2022 -chr:pos will be used for matching... Wed Oct 19 11:01:33 2022 -Matching variants for hg19: num_hg19= 1092441 Wed Oct 19 11:01:33 2022 -Matching variants for hg38: num_hg38= 15997 Wed Oct 19 11:01:33 2022 -Since num_hg19>num_hg38, assigning genome build hg19...","title":"Infer Genome Build"},{"location":"InferBuild/#infer-genome-build-version","text":"gwaslab use hapmaps chromosome and basepair position information to infer the reference genome build for sumstats. Status codes (first two digits) will be changed based on the results Example: mysumstats.infer_build() Wed Oct 19 11:01:01 2022 -Start to infer genome build version using hapmap3 SNPs... Wed Oct 19 11:01:01 2022 -Loading Hapmap3 variants data... Wed Oct 19 11:01:04 2022 -chr:pos will be used for matching... Wed Oct 19 11:01:33 2022 -Matching variants for hg19: num_hg19= 1092441 Wed Oct 19 11:01:33 2022 -Matching variants for hg38: num_hg38= 15997 Wed Oct 19 11:01:33 2022 -Since num_hg19>num_hg38, assigning genome build hg19...","title":"Infer Genome Build Version"},{"location":"LoadLDSC/","text":"Batch load LDSC log file Simply batch load LDSc data into a pandas DataFrame for other manipulation. GWASLab uses regular expression to match the values and fill them into a dataframe. gl.read_ldsc() gl.read_ldsc(filelist, mode=\"h2\") `filelist` : a list of paths to ldsc log files `mode` : h2 or rg ```python #mode=h2 ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(ldsc_file_list, mode=h2) #mode=rg ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(mode=h2) pathlist=[\"./test.results.log\",\"./test2.results.log\"] ldsc_h2 = gl.read_ldsc(pathlist, mode=\"h2\") ldsc_rg = gl.read_ldsc(pathlist, mode=\"rg\") ldsc_h2 Filename h2_obs h2_se Lambda_gc Mean_chi2 Intercept Intercept_se Ratio Ratio_se test.results.log 42.9954 8.657 1.2899 1.3226 0.0098 0.0098 0.6538 0.0304 test2.results.log NA NA 1.2899 1.3226 0.0098 0.0098 Ratio < 0 NA ldsc_rg p1 p2 rg se z p h2_obs h2_obs_se h2_int h2_int_se gcov_int gcov_int_se ./test.results.log ./test.results.log 0.2317 0.0897 2.5824 0.0098 0.3305 0.0571 0.9612 0.009 -0.0001 0.0062 ./test.results.log ./test2.results.log 0.2317 0.0897 2.5824 0.0098 0.3305 0.0571 0.9612 0.009 -0.0001 0.0062 For genetic correlation, after loading, you can use gl.plot_rg() to plot a heat map to visualize the results. No extra manipulation needed. gl.plot_rg(myldscrg)","title":"Load LDSC log"},{"location":"LoadLDSC/#batch-load-ldsc-log-file","text":"Simply batch load LDSc data into a pandas DataFrame for other manipulation. GWASLab uses regular expression to match the values and fill them into a dataframe. gl.read_ldsc() gl.read_ldsc(filelist, mode=\"h2\") `filelist` : a list of paths to ldsc log files `mode` : h2 or rg ```python #mode=h2 ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(ldsc_file_list, mode=h2) #mode=rg ldsc_file_list=[\"file1.\"] myldscrg = gl.read_ldsc(mode=h2) pathlist=[\"./test.results.log\",\"./test2.results.log\"] ldsc_h2 = gl.read_ldsc(pathlist, mode=\"h2\") ldsc_rg = gl.read_ldsc(pathlist, mode=\"rg\") ldsc_h2 Filename h2_obs h2_se Lambda_gc Mean_chi2 Intercept Intercept_se Ratio Ratio_se test.results.log 42.9954 8.657 1.2899 1.3226 0.0098 0.0098 0.6538 0.0304 test2.results.log NA NA 1.2899 1.3226 0.0098 0.0098 Ratio < 0 NA ldsc_rg p1 p2 rg se z p h2_obs h2_obs_se h2_int h2_int_se gcov_int gcov_int_se ./test.results.log ./test.results.log 0.2317 0.0897 2.5824 0.0098 0.3305 0.0571 0.9612 0.009 -0.0001 0.0062 ./test.results.log ./test2.results.log 0.2317 0.0897 2.5824 0.0098 0.3305 0.0571 0.9612 0.009 -0.0001 0.0062 For genetic correlation, after loading, you can use gl.plot_rg() to plot a heat map to visualize the results. No extra manipulation needed. gl.plot_rg(myldscrg)","title":"Batch load LDSC log file"},{"location":"QC%26Filtering/","text":"QC and filtering Methods Summary Sumstats Methods Options Description .check_sanity() sanity check for statistics including BETA, SE, Z, CHISQ, EAF, OR, N... .remove_dup() mode=\"dm\",keep='first' remove duplicate or multi-allelic variants .filter_in() lt, gt, eq, inplace .filter_out() .filter_region_in() path , inplace=True ,high_ld=False, build=\"19\" .filter_region_out() path , inplace=True ,high_ld=False, build=\"19\" Statistics Sanity Check .check_sanity() : Basic sanity check will. be performed on statistics to check if there are any extreme values or values out of expected range . BETA/SE : float, -10<BETA<10, -10<log(OR)<10 OR/OR_95L/OR_95U : float, 0<OR<10, OR_95L>0, OR_95U>0 EAF : 0<= EAF <=1, if EAF of >95% of valid variants is less than 0.5, a warning will be sent. P : float, 0<P<5e-300 MLOG10 : float, MLOG10>0 Z : float CHISQ : float , CHISQ>0 N : interger, N>0 Direction : string, only contains \"+\",\"-\" ,\"0\"or \"?\" sumstats.check_sanity() Remove duplication or multiallelic variants after standardize the sumstats, you can also remove duplicated or multiallelic variants using : .remove_dup() mode: d ,remove duplicate. If SNPID exists, remove duplicate . If rsID exists, remove deuplicate rsID. m ,removed multiallelic. remove based on SNPID, CHR and POS sumstats.remove_dup(mode=\"dm\",keep='first') FIltering .filter_in(gt={},lt={},eq={},inplace=True) .filter_out(gt={},lt={},eq={},inplace=True) gt : greater than lt : less than eq : equal to inplace : True or False. If False, return a dataframe. If true, the Sumstats object will be filtered. Filtering region .filter_region_in(path=\"./abc.bed\") .filter_region_out(high_ld=True)","title":"QC&Filtering"},{"location":"QC%26Filtering/#qc-and-filtering","text":"","title":"QC and filtering"},{"location":"QC%26Filtering/#methods-summary","text":"Sumstats Methods Options Description .check_sanity() sanity check for statistics including BETA, SE, Z, CHISQ, EAF, OR, N... .remove_dup() mode=\"dm\",keep='first' remove duplicate or multi-allelic variants .filter_in() lt, gt, eq, inplace .filter_out() .filter_region_in() path , inplace=True ,high_ld=False, build=\"19\" .filter_region_out() path , inplace=True ,high_ld=False, build=\"19\"","title":"Methods Summary"},{"location":"QC%26Filtering/#statistics-sanity-check","text":".check_sanity() : Basic sanity check will. be performed on statistics to check if there are any extreme values or values out of expected range . BETA/SE : float, -10<BETA<10, -10<log(OR)<10 OR/OR_95L/OR_95U : float, 0<OR<10, OR_95L>0, OR_95U>0 EAF : 0<= EAF <=1, if EAF of >95% of valid variants is less than 0.5, a warning will be sent. P : float, 0<P<5e-300 MLOG10 : float, MLOG10>0 Z : float CHISQ : float , CHISQ>0 N : interger, N>0 Direction : string, only contains \"+\",\"-\" ,\"0\"or \"?\" sumstats.check_sanity()","title":"Statistics Sanity Check"},{"location":"QC%26Filtering/#remove-duplication-or-multiallelic-variants","text":"after standardize the sumstats, you can also remove duplicated or multiallelic variants using : .remove_dup() mode: d ,remove duplicate. If SNPID exists, remove duplicate . If rsID exists, remove deuplicate rsID. m ,removed multiallelic. remove based on SNPID, CHR and POS sumstats.remove_dup(mode=\"dm\",keep='first')","title":"Remove duplication or multiallelic variants"},{"location":"QC%26Filtering/#filtering","text":".filter_in(gt={},lt={},eq={},inplace=True) .filter_out(gt={},lt={},eq={},inplace=True) gt : greater than lt : less than eq : equal to inplace : True or False. If False, return a dataframe. If true, the Sumstats object will be filtered.","title":"FIltering"},{"location":"QC%26Filtering/#filtering-region","text":".filter_region_in(path=\"./abc.bed\") .filter_region_out(high_ld=True)","title":"Filtering region"},{"location":"Reference/","text":"pyensembl Reference file https://github.com/openvax/pyensembl Install pyensembl and download reference: # install pyensembl if not pip install pyensembl # syntax for download reference for pyensembl pyensembl install --release <list of Ensembl release numbers> --species <species-name> For gwaslab, please run the following commands: ensembl release 75 : hg19 ensembl release 76 : hg38 pyensembl install --release 75 76 --species human gwaslab could use ensembl reference data to annotate lead SNPs with the nearest gene name. Process Reference file 1000 Genome Download: Index of /vol1/ftp/release/20130502/ After downloading the raw vcf, we need to normalize the variants, split multiallelic variants, rename the variant and remove duplicates. Also, we need to extract out target ancestry and recalculate the allele frequency. Create a sample list for EAS samples awk '$3==\"EAS\"{print $1}' integrated_call_samples_v3.20130502.ALL.panel >EAS.sample 1000 genome: #!/bin/bash for chr in {1..22} do bcftools view -S EAS.sample ALL.chr\"${chr}\".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz | \\ bcftools norm -m-any --check-ref w -f human_g1k_v37.fasta | \\ bcftools annotate -x ID,INFO -I +'%CHROM:%POS:%REF:%ALT' | \\ bcftools norm --rm-dup both | \\ bcftools +fill-tags -Oz -- -t AF \\ > EAS.chr\"${chr}\".split_norm_af.vcf.gz tabix -p vcf EAS.chr\"${chr}\".split_norm_af.vcf.gz done dbsnp rsID database. dbsnp v151 (hg19): https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz latest release: Index of /snp/latest_release/VCF gnomad Allele frequency for major ancestries and rsID gnomAD v2 & gnomAD v2 liftover & gnomAD v3: gnomAD","title":"Reference data"},{"location":"Reference/#pyensembl-reference-file","text":"https://github.com/openvax/pyensembl Install pyensembl and download reference: # install pyensembl if not pip install pyensembl # syntax for download reference for pyensembl pyensembl install --release <list of Ensembl release numbers> --species <species-name> For gwaslab, please run the following commands: ensembl release 75 : hg19 ensembl release 76 : hg38 pyensembl install --release 75 76 --species human gwaslab could use ensembl reference data to annotate lead SNPs with the nearest gene name.","title":"pyensembl Reference file"},{"location":"Reference/#process-reference-file","text":"","title":"Process Reference file"},{"location":"Reference/#1000-genome","text":"Download: Index of /vol1/ftp/release/20130502/ After downloading the raw vcf, we need to normalize the variants, split multiallelic variants, rename the variant and remove duplicates. Also, we need to extract out target ancestry and recalculate the allele frequency. Create a sample list for EAS samples awk '$3==\"EAS\"{print $1}' integrated_call_samples_v3.20130502.ALL.panel >EAS.sample 1000 genome: #!/bin/bash for chr in {1..22} do bcftools view -S EAS.sample ALL.chr\"${chr}\".phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz | \\ bcftools norm -m-any --check-ref w -f human_g1k_v37.fasta | \\ bcftools annotate -x ID,INFO -I +'%CHROM:%POS:%REF:%ALT' | \\ bcftools norm --rm-dup both | \\ bcftools +fill-tags -Oz -- -t AF \\ > EAS.chr\"${chr}\".split_norm_af.vcf.gz tabix -p vcf EAS.chr\"${chr}\".split_norm_af.vcf.gz done","title":"1000 Genome"},{"location":"Reference/#dbsnp","text":"rsID database. dbsnp v151 (hg19): https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz latest release: Index of /snp/latest_release/VCF","title":"dbsnp"},{"location":"Reference/#gnomad","text":"Allele frequency for major ancestries and rsID gnomAD v2 & gnomAD v2 liftover & gnomAD v3: gnomAD","title":"gnomad"},{"location":"RegionalPlot/","text":"Coming Soon","title":"Regional Plot"},{"location":"RegionalPlot/#coming-soon","text":"","title":"Coming Soon"},{"location":"Standardization/","text":"Standardization and normalization import gwaslab as gl sumstats = gl.Sumstats(...) After loading raw sumstats into gwaslab Sumstats Object, the first thing we probably want to do is to standardize the variant-related notations and check if there are any unexpected errors in the statistics. When checking is finished, the status code will be automatically changed. Methods Summary Sumstats Methods Options Description .fix_ID() fixchrpos=False , fixid=False , overwrite=False check and fix rsID or SNPID(chr:pos:ref:alt), or use snpid to fix CHR and POS .fix_CHR() remove=False standardize chromsome notation .fix_POS() remove=False standardize basepair posituion notation and filter out bad values .fix_allele() remove=False standardize base notation to ATCG .normalize_allele() n_cores=1 normalize indels (only support ATA:AA -> AT:A but not -:T) .sort_coordinate() sort the variant coordinates 1. IDs Gwaslab requires at least one ID columns for sumstats, either in the form of SNPID or rsID, (or both). Gwaslab will automatically check if SNPID is mixed in rsID. SNPID : it could be user provided IDs, or in CHR:POS:REF:ALT format, delimiter can be\":\",\"_\" or \"-\" rsID : dbSNP rsIDs gwaslab checks if the IDs you provided is valid SNPID or rsID. It can also extract CHR and POS information from the CHR:POS:REF:ALT formatted IDs using .fix_ID() method. SNPID will be fixed by CHR:POS:NEA:EA only when the variants is already aligned with reference genome. Otherwise, a temporary SNPID in the format of CHR:POS will be given. .fix_ID() : check or fix SNPID and rsID. sumstats.fixID(fixchrpos=False, fixid=False, overwrite=False) 2. CHR .fix_CHR() CHR will be standardized to 1-22,X,Y,MT Leading \"chr\" and leading 0s will be stripped. sumstats.fix_CHR(remove=False) 3. POS .fix_POS() Values in POS must be positive integer numbers. Basepair position will be force converted to integers. Invalid pos will be converted to NA. (not implemented yet) After conversion, gwaslab will also sanity check if POS is in the range of 1 to 300,000,000. (the longest chromosome, CHR1, is around 250,000,000bp long) sumstats.fix_POS(remove=False) 4. Allele 4.1 Standardization .fix_allele() Currently, gwaslab only support processing SNPs and INDELs. All alleles will be checked if containing letters other than ATCG . Copy number variant (CNV) like <CN0> won't be recognized. Lower cases will converted to UPPERCASES. sumstats.fix_allele(remove=False) 4.2 Normalization .normalize_allele() Alleles will be normalized accroding to left alignment and parsimony principal. (For details: add link here ) For example, chr1:123456:ATG:AT will be normalized to chr1:123455:TG:T. Note: Currently, the normalizeation is implemented without checking reference, which means it can not normalize variants like chr1:123456:G:- if the missing information need to be obtained from a reference genome. sumstats.normalize_allele(n_cores=1) 5. Coordinate sorting Sort genomic coordinates\uff0c 1-22 X Y MT sumstats.sort_coordinate() 6. Column sorting The default column order is \"SNPID\",\"rsID\", \"CHR\", \"POS\", \"EA\", \"NEA\", \"EAF\", \"BETA\", \"SE\", \"Z\", \"CHISQ\", \"P\", \"MLOG10P\", \"OR\", \"OR_SE\", \"OR_95L\", \"OR_95U\", \"INFO\", \"N\",\"DIRECTION\",\"STATUS\" and other additional columns. sumstats.sort_columns()","title":"Standardization&normalization"},{"location":"Standardization/#standardization-and-normalization","text":"import gwaslab as gl sumstats = gl.Sumstats(...) After loading raw sumstats into gwaslab Sumstats Object, the first thing we probably want to do is to standardize the variant-related notations and check if there are any unexpected errors in the statistics. When checking is finished, the status code will be automatically changed.","title":"Standardization and normalization"},{"location":"Standardization/#methods-summary","text":"Sumstats Methods Options Description .fix_ID() fixchrpos=False , fixid=False , overwrite=False check and fix rsID or SNPID(chr:pos:ref:alt), or use snpid to fix CHR and POS .fix_CHR() remove=False standardize chromsome notation .fix_POS() remove=False standardize basepair posituion notation and filter out bad values .fix_allele() remove=False standardize base notation to ATCG .normalize_allele() n_cores=1 normalize indels (only support ATA:AA -> AT:A but not -:T) .sort_coordinate() sort the variant coordinates","title":"Methods Summary"},{"location":"Standardization/#1-ids","text":"Gwaslab requires at least one ID columns for sumstats, either in the form of SNPID or rsID, (or both). Gwaslab will automatically check if SNPID is mixed in rsID. SNPID : it could be user provided IDs, or in CHR:POS:REF:ALT format, delimiter can be\":\",\"_\" or \"-\" rsID : dbSNP rsIDs gwaslab checks if the IDs you provided is valid SNPID or rsID. It can also extract CHR and POS information from the CHR:POS:REF:ALT formatted IDs using .fix_ID() method. SNPID will be fixed by CHR:POS:NEA:EA only when the variants is already aligned with reference genome. Otherwise, a temporary SNPID in the format of CHR:POS will be given. .fix_ID() : check or fix SNPID and rsID. sumstats.fixID(fixchrpos=False, fixid=False, overwrite=False)","title":"1. IDs"},{"location":"Standardization/#2-chr","text":".fix_CHR() CHR will be standardized to 1-22,X,Y,MT Leading \"chr\" and leading 0s will be stripped. sumstats.fix_CHR(remove=False)","title":"2. CHR"},{"location":"Standardization/#3-pos","text":".fix_POS() Values in POS must be positive integer numbers. Basepair position will be force converted to integers. Invalid pos will be converted to NA. (not implemented yet) After conversion, gwaslab will also sanity check if POS is in the range of 1 to 300,000,000. (the longest chromosome, CHR1, is around 250,000,000bp long) sumstats.fix_POS(remove=False)","title":"3. POS"},{"location":"Standardization/#4-allele","text":"","title":"4. Allele"},{"location":"Standardization/#41-standardization","text":".fix_allele() Currently, gwaslab only support processing SNPs and INDELs. All alleles will be checked if containing letters other than ATCG . Copy number variant (CNV) like <CN0> won't be recognized. Lower cases will converted to UPPERCASES. sumstats.fix_allele(remove=False)","title":"4.1 Standardization"},{"location":"Standardization/#42-normalization","text":".normalize_allele() Alleles will be normalized accroding to left alignment and parsimony principal. (For details: add link here ) For example, chr1:123456:ATG:AT will be normalized to chr1:123455:TG:T. Note: Currently, the normalizeation is implemented without checking reference, which means it can not normalize variants like chr1:123456:G:- if the missing information need to be obtained from a reference genome. sumstats.normalize_allele(n_cores=1)","title":"4.2 Normalization"},{"location":"Standardization/#5-coordinate-sorting","text":"Sort genomic coordinates\uff0c 1-22 X Y MT sumstats.sort_coordinate()","title":"5. Coordinate sorting"},{"location":"Standardization/#6-column-sorting","text":"The default column order is \"SNPID\",\"rsID\", \"CHR\", \"POS\", \"EA\", \"NEA\", \"EAF\", \"BETA\", \"SE\", \"Z\", \"CHISQ\", \"P\", \"MLOG10P\", \"OR\", \"OR_SE\", \"OR_95L\", \"OR_95U\", \"INFO\", \"N\",\"DIRECTION\",\"STATUS\" and other additional columns. sumstats.sort_columns()","title":"6. Column sorting"},{"location":"StatusCode/","text":"A 7-digit code: showing the status of a variants. Reflecting the reliability of the statistics. Design principals: Tracable Higher value ->higer uncertainty Digit Description 1,2 Genome_build 3 rsID & SNPID 4 CHR, POS 5 EA, NEA 6 REF-NEA Alignment 7 Palindromic SNPs + Indels","title":"StatusCode"},{"location":"SumstatsObject/","text":"Sumstats Object in gwaslab In gwaslab, sumstats were stored in a Sumstats Object \uff0cwhich is built on pandas Dataframe . All other function are designed as methods of this Sumstats Object. To load any sumstats into the object, simply specify the column name and load the raw GWAS summary statsitics from a pandas dataframe or specifying file path. All raw data will be loaded as \"string\" datatype. mysumstats = gl.Sumstats( sumstats, fmt=None, snpid=None, rsid=None, chrom=None, pos=None, ea=None, nea=None, eaf=None, n=None, beta=None, se=None, chisq=None, z=None, p=None, mlog10p=None, info=None, OR=None, OR_95L=None, OR_95U=None, status=None, other=[], direction=None, verbose=True, build=\"00\", **args ) sumstats : either a file path or a pandas DataFrame Currently, gwaslab supports the following columns: snpid : variant ID column name, preferably in chr:pos:ea:nea format. rsid : dbSNP rsID column name The minimum required columns are just either rsid or snpid . All other columns are optional. fmt : input sumstats format : For formats supported by gwaslab, please check https://github.com/Cloufield/formatbook chrom : chromosome column name pos : basepair position column name ea : effect allele column name nea : non-effect allele column name eaf : effect allele frequency n : sample size column name or just input a single integer beta : effect size beta column name se : standard error column name chisq : chi square column name z : z score column name p : p value column name mlog10p : -log10(P) column name info : imputation info or rsq column name OR : odds ratio column name OR_95L :odds ratio lower 95% ci column name OR_95U :odds ratio upper 95% ci column name direction : direction column name in METAL format (e.g. \"++--+?+\") other : a list of other column names you want to keep with the core columns, probably some annotations. status : gwaslab 5-digit vairants status code. For details, please check status code page. verbose : if true: output log build : str genome build (\"19\",\"38\") **arg : additional parameters for pl.read_table function. Loading sumstats you can load the path by specifying the columns like: mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", snpid=\"SNPID\", chrom=\"CHR\", pos=\"POS\", ea=\"Allele2\", nea=\"Allele1\", eaf=\"AF_Allele2\", beta=\"BETA\", se=\"SE\", p=\"p.value\", n=\"N\") or just specify the format: mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", format=\"saige\") gwaslab uses manully curated format conversion dictionary in https://github.com/Cloufield/formatbook Check DataFrame After loading, the raw data columns will be renamed to new columns without ambiguity and the dataframe is store in .data : mysumstats.data You can simply save the processed data using pandas saving functions, for example mysumstats.data.to_csv(\"./mysumstats.csv\") or convert the sumstats to other sumstats: please check https://cloufield.github.io/gwaslab/Format/ Logging All manipulation conducted to the sumstats will be logged for reproducibility and traceability. The log is stored in a gl.Log object . You can check it by .log.show() and save it using .log.save() mysumstats.log.show() mysumstats.log.save() Sumstats summary You can check the meta information of this sumstats by: mysumstats.summary() Other functions Other functions of gwaslab is implemented as the methods of Sumstats Object. mysumstats.basic_check() mysumstats.plot_mqq()","title":"SumstatsObject"},{"location":"SumstatsObject/#sumstats-object-in-gwaslab","text":"In gwaslab, sumstats were stored in a Sumstats Object \uff0cwhich is built on pandas Dataframe . All other function are designed as methods of this Sumstats Object. To load any sumstats into the object, simply specify the column name and load the raw GWAS summary statsitics from a pandas dataframe or specifying file path. All raw data will be loaded as \"string\" datatype. mysumstats = gl.Sumstats( sumstats, fmt=None, snpid=None, rsid=None, chrom=None, pos=None, ea=None, nea=None, eaf=None, n=None, beta=None, se=None, chisq=None, z=None, p=None, mlog10p=None, info=None, OR=None, OR_95L=None, OR_95U=None, status=None, other=[], direction=None, verbose=True, build=\"00\", **args ) sumstats : either a file path or a pandas DataFrame Currently, gwaslab supports the following columns: snpid : variant ID column name, preferably in chr:pos:ea:nea format. rsid : dbSNP rsID column name The minimum required columns are just either rsid or snpid . All other columns are optional. fmt : input sumstats format : For formats supported by gwaslab, please check https://github.com/Cloufield/formatbook chrom : chromosome column name pos : basepair position column name ea : effect allele column name nea : non-effect allele column name eaf : effect allele frequency n : sample size column name or just input a single integer beta : effect size beta column name se : standard error column name chisq : chi square column name z : z score column name p : p value column name mlog10p : -log10(P) column name info : imputation info or rsq column name OR : odds ratio column name OR_95L :odds ratio lower 95% ci column name OR_95U :odds ratio upper 95% ci column name direction : direction column name in METAL format (e.g. \"++--+?+\") other : a list of other column names you want to keep with the core columns, probably some annotations. status : gwaslab 5-digit vairants status code. For details, please check status code page. verbose : if true: output log build : str genome build (\"19\",\"38\") **arg : additional parameters for pl.read_table function.","title":"Sumstats Object in gwaslab"},{"location":"SumstatsObject/#loading-sumstats","text":"you can load the path by specifying the columns like: mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", snpid=\"SNPID\", chrom=\"CHR\", pos=\"POS\", ea=\"Allele2\", nea=\"Allele1\", eaf=\"AF_Allele2\", beta=\"BETA\", se=\"SE\", p=\"p.value\", n=\"N\") or just specify the format: mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", format=\"saige\") gwaslab uses manully curated format conversion dictionary in https://github.com/Cloufield/formatbook","title":"Loading sumstats"},{"location":"SumstatsObject/#check-dataframe","text":"After loading, the raw data columns will be renamed to new columns without ambiguity and the dataframe is store in .data : mysumstats.data You can simply save the processed data using pandas saving functions, for example mysumstats.data.to_csv(\"./mysumstats.csv\") or convert the sumstats to other sumstats: please check https://cloufield.github.io/gwaslab/Format/","title":"Check DataFrame"},{"location":"SumstatsObject/#logging","text":"All manipulation conducted to the sumstats will be logged for reproducibility and traceability. The log is stored in a gl.Log object . You can check it by .log.show() and save it using .log.save() mysumstats.log.show() mysumstats.log.save()","title":"Logging"},{"location":"SumstatsObject/#sumstats-summary","text":"You can check the meta information of this sumstats by: mysumstats.summary()","title":"Sumstats summary"},{"location":"SumstatsObject/#other-functions","text":"Other functions of gwaslab is implemented as the methods of Sumstats Object. mysumstats.basic_check() mysumstats.plot_mqq()","title":"Other functions"},{"location":"Tutorial/","text":"Quick Start Using a jupyter notebook, we first import gwaslab package: import gwaslab as gl The sample sumstats we use in this study: !wget -O t2d_bbj.txt.gz http://jenger.riken.jp/14/ Let's import this raw sumstats into the gwaslab Sumstats Object by specifying the necessary columns, and all data are imported as strings. Note: you can either specify eaf (effect allele frequency) or neaf(non-effect allele frequency), if neaf is specified, it will be converted to eaf when loading sumstats. mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", snpid=\"SNP\", chrom=\"CHR\", pos=\"POS\", ea=\"ALT\", nea=\"REF\", neaf=\"Frq\", beta=\"BETA\", se=\"SE\", p=\"P\", direction=\"Dir\", n=\"N\", build=\"19\") See details in SumstatsObject . Maybe the first thing you want to check is the manhattan plot, you can do this with one line of code, gwaslab will perform a minimum QC for just the plotting. mysumstats.plot_mqq() Sanity check Looks good, but we need to perform QC to make sure there are no unexpected errors, let's check the statitsics first. mysumstats.check_sanity() Filtering There are more than 10 million variants in the original sumstats and it will take long to process the entrie dataset. So, let's just filter-in (include) variants with P<0.00005 and filter-out (exclude) variants on ChrX. This could also be used for filtering other columns like INFO,N and so forth if you need. mysumstats.filter_out(gt={\"P\":0.005},eq={\"CHR\":\"X\"}) See details in QC&Filtering . Standardization & normalization It is also needed to check ID,CHR,POS and alleles: simply run: mysumstats.basic_check() .basic_check() is a wrapper of all the following basic functions, you can use these separately. mysumstats.fix_ID() mysumstats.fix_chr() mysumstats.fix_pos() mysumstats.fix_allele() mysumstats.check_sanity() mysumstats.normalize_allele() See details in Standardization . Extract lead variants Let's extract the lead variants in each significant loci to check our data. The significant loci are detected based on a sliding window (default window size: 500kb) mysumstats.get_lead() See details in ExtractLead . Customized manhattan plot GWASlab can plot more complicated manhattan plot: (not finished yet) mysumstats.plot_mqq(snpid=\"SNPID\",mode=\"mqq\", cut=20,skip=3, eaf=\"EAF\", anno=True,anno_set=[\"9:22132729_A_G\",\"6:20688121_T_A\",\"9:22132729_A_G\",\"15:62394264_G_C\"] , pinpoint=[\"9:22132729_A_G\",\"5:176513896_C_A\"], highlight=[\"7:127253550_C_T\",\"19:46166604_C_T\"], highlight_windowkb =1000, stratified=True, marker_size=(5,10), figargs={\"figsize\":(15,5),\"dpi\":300}) See details in Visualization . Harmonise the sumstats All-in-one function After checking the basics of the sumstats, next we may need to harmonise the sumstats for downstream analysis. For harmonization, we need reference files fasta and vcf. We will just check chr3 to save time. mysumstats.filter_in(eq={\"CHR\":\"3\"}) mysumstats.clean( basic_check=False, ref_seq=\"./human_g1k_v37.fasta\", ref_rsid=\"./00-All.vcf.gz\", ref_infer=\"./EAS.chr3.split_norm_af.vcf.gz\", ref_alt_freq=\"AF\") ref_seq : reference genome sequence in fasta format for alignment ref_rsid : reference vcf for rsID annotation ref_infer : reference vcf for strand inferring (require allele frequency in INFO filed.) ref_alt_freq : key word for alternative allele frequency in the reference vcf file. Some available and reliable reference files: reference genome sequence fasta file. (For example, in the tutorial, hg19 reference sequence human_g1k_v37.fasta.gz from http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/ will be used) reference vcf file for rsID annotation (For example: https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz ) reference vcf for allele frequency (can be the same as 2, for example from 1KG Index of /vol1/ftp/release/20130502/ (manipulation of the vcf is needed, see Reference ) or gnomad). See details in Reference . .harmonise() is basically a wrapper of the following functions. mysumstats.basic_check() mysumstats.check_ref() mysumstats.flip_allele_stats() mysumstats.infer_strand() See details in Harmonization . Align with reference genome let's then align the NEA (non-effect allele) with reference sequence from a fasta file. mysumstats.check_ref(ref_path = \"./human_g1k_v37.fasta.gz\") In this case, the hg19 reference genome was downloaded from 1KG. Filp allele-specific statistics Gwaslab will check the status code and flip only those needed. mysumstats.flip_allele_stats() Annotate rsID Gwaslab can annotate the vairant with rsID using a reference vcf. For this purpose, we use the vcf file provided by dbsnp. (In this tutorial, b151/hg19 version was used) mmysumstats.flip_allele_stats(path=\"./00-All.vcf.gz\") Infer strand for palindromic SNPs and check ref allele for indels After the alignment with reference genome sequence, next we try to infer the strand of palindromic SNPs and also check the ref allele for indels. Note: GWASLab will only infer the strand for those that are already aligned with reference genome. mysumstats.infer_strand(ref_infer=\"./EAS.chr3.split_norm_af.vcf.gz\", ref_alt_freq=\"AF\") See details in Reference on how to process the 1000 genome raw vcf. Filp allele-specific statistics again for palindromic SNPs and indels Gwaslab will check the status code and flip only those needed. mysumstats.flip_allele_stats() Check difference in allele frequency After aligment and correct strands for panlindromic SNPs, you may want to double check the differences in allele frequency between the EAF from sumstats and ALT allele frequency in a reference vcf (For example ,1000 genome) See details in Reference on how to process the 1000 genome raw vcf. You can simply use .check_af() to check the difference in allele frequencies: eaf - aaf = daf mysumstats.check_af(ref_infer=\"./EAS.chr3.split_norm_af.vcf.gz\",ref_alt_freq=\"AF\") After checking, use plot_daf() to visualize the results. It will generate two figures: 1. a scatter plot 2. a distribution plot. Plot DAF mysumstats.plot_daf() Liftover mysumstats.liftover(n_cores=1,from_build=\"19\", to_build=\"38\") Gwaslab only liftover CHR and POS, and when lifted, the last two digits status code will be rolled back to 99. Since for difference reference genome, the reference allele or strand might be reverse, so it is need to align and check agin. See details in Harmonization .","title":"Tutorial"},{"location":"Tutorial/#quick-start","text":"Using a jupyter notebook, we first import gwaslab package: import gwaslab as gl The sample sumstats we use in this study: !wget -O t2d_bbj.txt.gz http://jenger.riken.jp/14/ Let's import this raw sumstats into the gwaslab Sumstats Object by specifying the necessary columns, and all data are imported as strings. Note: you can either specify eaf (effect allele frequency) or neaf(non-effect allele frequency), if neaf is specified, it will be converted to eaf when loading sumstats. mysumstats = gl.Sumstats(\"t2d_bbj.txt.gz\", snpid=\"SNP\", chrom=\"CHR\", pos=\"POS\", ea=\"ALT\", nea=\"REF\", neaf=\"Frq\", beta=\"BETA\", se=\"SE\", p=\"P\", direction=\"Dir\", n=\"N\", build=\"19\") See details in SumstatsObject . Maybe the first thing you want to check is the manhattan plot, you can do this with one line of code, gwaslab will perform a minimum QC for just the plotting. mysumstats.plot_mqq()","title":"Quick Start"},{"location":"Tutorial/#sanity-check","text":"Looks good, but we need to perform QC to make sure there are no unexpected errors, let's check the statitsics first. mysumstats.check_sanity()","title":"Sanity check"},{"location":"Tutorial/#filtering","text":"There are more than 10 million variants in the original sumstats and it will take long to process the entrie dataset. So, let's just filter-in (include) variants with P<0.00005 and filter-out (exclude) variants on ChrX. This could also be used for filtering other columns like INFO,N and so forth if you need. mysumstats.filter_out(gt={\"P\":0.005},eq={\"CHR\":\"X\"}) See details in QC&Filtering .","title":"Filtering"},{"location":"Tutorial/#standardization-normalization","text":"It is also needed to check ID,CHR,POS and alleles: simply run: mysumstats.basic_check() .basic_check() is a wrapper of all the following basic functions, you can use these separately. mysumstats.fix_ID() mysumstats.fix_chr() mysumstats.fix_pos() mysumstats.fix_allele() mysumstats.check_sanity() mysumstats.normalize_allele() See details in Standardization .","title":"Standardization &amp; normalization"},{"location":"Tutorial/#_1","text":"","title":""},{"location":"Tutorial/#extract-lead-variants","text":"Let's extract the lead variants in each significant loci to check our data. The significant loci are detected based on a sliding window (default window size: 500kb) mysumstats.get_lead() See details in ExtractLead .","title":"Extract lead variants"},{"location":"Tutorial/#customized-manhattan-plot","text":"GWASlab can plot more complicated manhattan plot: (not finished yet) mysumstats.plot_mqq(snpid=\"SNPID\",mode=\"mqq\", cut=20,skip=3, eaf=\"EAF\", anno=True,anno_set=[\"9:22132729_A_G\",\"6:20688121_T_A\",\"9:22132729_A_G\",\"15:62394264_G_C\"] , pinpoint=[\"9:22132729_A_G\",\"5:176513896_C_A\"], highlight=[\"7:127253550_C_T\",\"19:46166604_C_T\"], highlight_windowkb =1000, stratified=True, marker_size=(5,10), figargs={\"figsize\":(15,5),\"dpi\":300}) See details in Visualization .","title":"Customized manhattan plot"},{"location":"Tutorial/#_2","text":"","title":""},{"location":"Tutorial/#harmonise-the-sumstats","text":"","title":"Harmonise the sumstats"},{"location":"Tutorial/#all-in-one-function","text":"After checking the basics of the sumstats, next we may need to harmonise the sumstats for downstream analysis. For harmonization, we need reference files fasta and vcf. We will just check chr3 to save time. mysumstats.filter_in(eq={\"CHR\":\"3\"}) mysumstats.clean( basic_check=False, ref_seq=\"./human_g1k_v37.fasta\", ref_rsid=\"./00-All.vcf.gz\", ref_infer=\"./EAS.chr3.split_norm_af.vcf.gz\", ref_alt_freq=\"AF\") ref_seq : reference genome sequence in fasta format for alignment ref_rsid : reference vcf for rsID annotation ref_infer : reference vcf for strand inferring (require allele frequency in INFO filed.) ref_alt_freq : key word for alternative allele frequency in the reference vcf file. Some available and reliable reference files: reference genome sequence fasta file. (For example, in the tutorial, hg19 reference sequence human_g1k_v37.fasta.gz from http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/ will be used) reference vcf file for rsID annotation (For example: https://ftp.ncbi.nih.gov/snp/organisms/human_9606_b151_GRCh37p13/VCF/00-All.vcf.gz ) reference vcf for allele frequency (can be the same as 2, for example from 1KG Index of /vol1/ftp/release/20130502/ (manipulation of the vcf is needed, see Reference ) or gnomad). See details in Reference . .harmonise() is basically a wrapper of the following functions. mysumstats.basic_check() mysumstats.check_ref() mysumstats.flip_allele_stats() mysumstats.infer_strand() See details in Harmonization .","title":"All-in-one function"},{"location":"Tutorial/#align-with-reference-genome","text":"let's then align the NEA (non-effect allele) with reference sequence from a fasta file. mysumstats.check_ref(ref_path = \"./human_g1k_v37.fasta.gz\") In this case, the hg19 reference genome was downloaded from 1KG.","title":"Align with reference genome"},{"location":"Tutorial/#filp-allele-specific-statistics","text":"Gwaslab will check the status code and flip only those needed. mysumstats.flip_allele_stats()","title":"Filp allele-specific statistics"},{"location":"Tutorial/#annotate-rsid","text":"Gwaslab can annotate the vairant with rsID using a reference vcf. For this purpose, we use the vcf file provided by dbsnp. (In this tutorial, b151/hg19 version was used) mmysumstats.flip_allele_stats(path=\"./00-All.vcf.gz\")","title":"Annotate rsID"},{"location":"Tutorial/#infer-strand-for-palindromic-snps-and-check-ref-allele-for-indels","text":"After the alignment with reference genome sequence, next we try to infer the strand of palindromic SNPs and also check the ref allele for indels. Note: GWASLab will only infer the strand for those that are already aligned with reference genome. mysumstats.infer_strand(ref_infer=\"./EAS.chr3.split_norm_af.vcf.gz\", ref_alt_freq=\"AF\") See details in Reference on how to process the 1000 genome raw vcf.","title":"Infer strand for palindromic SNPs and check ref allele for indels"},{"location":"Tutorial/#filp-allele-specific-statistics-again-for-palindromic-snps-and-indels","text":"Gwaslab will check the status code and flip only those needed. mysumstats.flip_allele_stats()","title":"Filp allele-specific statistics again for palindromic SNPs and indels"},{"location":"Tutorial/#check-difference-in-allele-frequency","text":"After aligment and correct strands for panlindromic SNPs, you may want to double check the differences in allele frequency between the EAF from sumstats and ALT allele frequency in a reference vcf (For example ,1000 genome) See details in Reference on how to process the 1000 genome raw vcf. You can simply use .check_af() to check the difference in allele frequencies: eaf - aaf = daf mysumstats.check_af(ref_infer=\"./EAS.chr3.split_norm_af.vcf.gz\",ref_alt_freq=\"AF\") After checking, use plot_daf() to visualize the results. It will generate two figures: 1. a scatter plot 2. a distribution plot.","title":"Check difference in allele frequency"},{"location":"Tutorial/#plot-daf","text":"mysumstats.plot_daf()","title":"Plot DAF"},{"location":"Tutorial/#liftover","text":"mysumstats.liftover(n_cores=1,from_build=\"19\", to_build=\"38\") Gwaslab only liftover CHR and POS, and when lifted, the last two digits status code will be rolled back to 99. Since for difference reference genome, the reference allele or strand might be reverse, so it is need to align and check agin. See details in Harmonization .","title":"Liftover"},{"location":"UpdateLogs/","text":"Update Logs v3.3.1 (coming soon) extract novel loci given a list of known lead variants fixed bugs in fill_data() fixed path for hapmap3 snps for infer_build() v3.3.0 2022/10/18 added forest plot fixed options for mqqplot supported vcf v3.2.0 incorporated pyensembl and scikit-allel. get_lead() : support automatic gene name annotation (using pyensembl) to_format(): support common sumstats formats support 1-based bed-like formats for VEP support 0-based bed-like formats manhattan plot: optimized plotting logic annotate gene names added regional plot feature using a user-provided reference panel comparison effect plot: fix using OR v3.1.0 implemented formatbook: easily import sumstats and output sumstats in certain formats (support for commonly used formats including ldsc, plink, plink2, gwas-ssf, saige, regenie, fastgwa, metal, mrmega, pgscatalog, pgscatalog_hm, gwascatalog, gwascatalog_hm and gwaslab) added .filter_region_in/out using bed files (or in-built regions like high-ld or hla) implemented .summay() methods. optimized rsID annotation pipeline. Support annotation using curated chr:pos:ref:alt - rsID tsv for quick annotation. changed some datatypes and optimized memory usage. replaced pyVCF with pySAM","title":"Update logs"},{"location":"UpdateLogs/#update-logs","text":"","title":"Update Logs"},{"location":"UpdateLogs/#v331-coming-soon","text":"extract novel loci given a list of known lead variants fixed bugs in fill_data() fixed path for hapmap3 snps for infer_build()","title":"v3.3.1 (coming soon)"},{"location":"UpdateLogs/#v330-20221018","text":"added forest plot fixed options for mqqplot supported vcf","title":"v3.3.0 2022/10/18"},{"location":"UpdateLogs/#v320","text":"incorporated pyensembl and scikit-allel. get_lead() : support automatic gene name annotation (using pyensembl) to_format(): support common sumstats formats support 1-based bed-like formats for VEP support 0-based bed-like formats manhattan plot: optimized plotting logic annotate gene names added regional plot feature using a user-provided reference panel comparison effect plot: fix using OR","title":"v3.2.0"},{"location":"UpdateLogs/#v310","text":"implemented formatbook: easily import sumstats and output sumstats in certain formats (support for commonly used formats including ldsc, plink, plink2, gwas-ssf, saige, regenie, fastgwa, metal, mrmega, pgscatalog, pgscatalog_hm, gwascatalog, gwascatalog_hm and gwaslab) added .filter_region_in/out using bed files (or in-built regions like high-ld or hla) implemented .summay() methods. optimized rsID annotation pipeline. Support annotation using curated chr:pos:ref:alt - rsID tsv for quick annotation. changed some datatypes and optimized memory usage. replaced pyVCF with pySAM","title":"v3.1.0"},{"location":"Visualization/","text":"Manhattan plot and QQ plot import gwaslab as gl mydata = gl.Sumstats(....) mydata.plot_mqq( snpid=None, scaled=False, eaf=None, cut=0, cutfactor=10, mode=\"mqq\", mqqratio=3, cut_line_color=\"#ebebeb\", windowsizekb=500, anno=None, sig_level=5e-8, sig_line_color=\"grey\", suggestive_sig_level=5e-6, stratified=False, maf_bins=[(0, 0.01), (0.01, 0.05), (0.05, 0.25),(0.25,0.5)], maf_bin_colors = [\"#f0ad4e\",\"#5cb85c\", \"#5bc0de\",\"#000042\"], highlight = [], highlight_color =\"#33FFA0\", highlight_windowkb = 500, pinpoint=[], pinpoint_color =\"#f55142\", title =None, mtitle=None, qtitle=None, figargs= {\"figsize\":(15,5)}, fontsize = 10, colors = [\"#000042\", \"#7878BA\"], use_rank=False, verbose=True, repel_force=0.03, title_pad=1.08, gc=True, save=None, saveargs={\"dpi\":400,\"facecolor\":\"white\"}, log=gl.Log() ) Manhattan and QQ plot layout mode : determine the layout of manhattan plot and qq plot. \"mqq\" or \"qqm\" : side-by-side manhattan and QQ plt. mqq : left manhatan, right QQ qqm : left QQ , right manhatan \"m\" : only manhattan plot \"qq\" : only qq plot mqqratio : width ratio Skip \"low\" and shrink \"high\" skip : sometimes it is not necessary to plot all variants, we can skip the insignicant variants . For example, we can exclude varints with -log10p lower than 3 from the plot by specifying skip=3 cut : loci with extremly large -log10(P) value are very likely to dwarf other significant loci , so we want to scale down the extrame loci from a certain threshold. cutfactor : shrinkage factor, default is 10 cut_line_color : the color of the line above which y axis is rescaled Annotation with chr:pos or a given column anno : True or a list if anno == True: the variants to annotate will be selected atomatically using a sliding window with windowsize=500 (kb). if anno=\"col_name\": if a list is provided: repel_force : when the annotation overlaps with other, try increasing the repel_force to increase the padding between annotations. anno_set : if you want to annoatte only a few specific variants, you can simply provide a list of SNPIDs. Highlight specified loci Highlight specified loci. highlight : specify the lead variants of loci for highlighting. highlight_color : specify the color ussed for highlighting. highlight_windowkb : specify the span of highlighted region ( in kp) Pinpoint specified variants Pinpoint certain variants in the manhattan plot. pinpint : a list of SNPIDs pinpoint_color : color for pinpoint Maf-stratified QQ plot stratified : If True, plot MAF straitified QQ plot. maf_bins : maf bins for straitification. maf_bin_colors : colors used for each bin. Use rank or POS use_rank : if True, use the rank instead of real base pair position. use simply rank and basepair position to draw the x axis. Colors and fonts Quick plot mysumstatsysumstats.plot_mqq() Customized plot mysumstats.plot_mqq(snpid=\"SNPID\",mode=\"mqq\", cut=20,skip=3, eaf=\"EAF\", anno=True,anno_set=[\"9:22132729_A_G\",\"6:20688121_T_A\",\"9:22132729_A_G\",\"15:62394264_G_C\"] , pinpoint=[\"9:22132729_A_G\",\"5:176513896_C_A\"], highlight=[\"7:127253550_C_T\",\"19:46166604_C_T\"], highlight_windowkb =1000, stratified=True, marker_size=(5,10), figargs={\"figsize\":(15,5),\"dpi\":300})","title":"Manhattan & QQ plot"},{"location":"Visualization/#manhattan-plot-and-qq-plot","text":"import gwaslab as gl mydata = gl.Sumstats(....) mydata.plot_mqq( snpid=None, scaled=False, eaf=None, cut=0, cutfactor=10, mode=\"mqq\", mqqratio=3, cut_line_color=\"#ebebeb\", windowsizekb=500, anno=None, sig_level=5e-8, sig_line_color=\"grey\", suggestive_sig_level=5e-6, stratified=False, maf_bins=[(0, 0.01), (0.01, 0.05), (0.05, 0.25),(0.25,0.5)], maf_bin_colors = [\"#f0ad4e\",\"#5cb85c\", \"#5bc0de\",\"#000042\"], highlight = [], highlight_color =\"#33FFA0\", highlight_windowkb = 500, pinpoint=[], pinpoint_color =\"#f55142\", title =None, mtitle=None, qtitle=None, figargs= {\"figsize\":(15,5)}, fontsize = 10, colors = [\"#000042\", \"#7878BA\"], use_rank=False, verbose=True, repel_force=0.03, title_pad=1.08, gc=True, save=None, saveargs={\"dpi\":400,\"facecolor\":\"white\"}, log=gl.Log() )","title":"Manhattan plot and QQ plot"},{"location":"Visualization/#_1","text":"","title":""},{"location":"Visualization/#manhattan-and-qq-plot-layout","text":"mode : determine the layout of manhattan plot and qq plot. \"mqq\" or \"qqm\" : side-by-side manhattan and QQ plt. mqq : left manhatan, right QQ qqm : left QQ , right manhatan \"m\" : only manhattan plot \"qq\" : only qq plot mqqratio : width ratio","title":"Manhattan and QQ plot layout"},{"location":"Visualization/#_2","text":"","title":""},{"location":"Visualization/#skip-low-and-shrink-high","text":"skip : sometimes it is not necessary to plot all variants, we can skip the insignicant variants . For example, we can exclude varints with -log10p lower than 3 from the plot by specifying skip=3 cut : loci with extremly large -log10(P) value are very likely to dwarf other significant loci , so we want to scale down the extrame loci from a certain threshold. cutfactor : shrinkage factor, default is 10 cut_line_color : the color of the line above which y axis is rescaled","title":"Skip \"low\" and shrink \"high\""},{"location":"Visualization/#annotation-with-chrpos-or-a-given-column","text":"anno : True or a list if anno == True: the variants to annotate will be selected atomatically using a sliding window with windowsize=500 (kb). if anno=\"col_name\": if a list is provided: repel_force : when the annotation overlaps with other, try increasing the repel_force to increase the padding between annotations. anno_set : if you want to annoatte only a few specific variants, you can simply provide a list of SNPIDs.","title":"Annotation with chr:pos or a given column"},{"location":"Visualization/#highlight-specified-loci","text":"Highlight specified loci. highlight : specify the lead variants of loci for highlighting. highlight_color : specify the color ussed for highlighting. highlight_windowkb : specify the span of highlighted region ( in kp)","title":"Highlight specified loci"},{"location":"Visualization/#pinpoint-specified-variants","text":"Pinpoint certain variants in the manhattan plot. pinpint : a list of SNPIDs","title":"Pinpoint specified variants"},{"location":"Visualization/#pinpoint_color-color-for-pinpoint","text":"","title":"pinpoint_color : color for pinpoint"},{"location":"Visualization/#maf-stratified-qq-plot","text":"stratified : If True, plot MAF straitified QQ plot. maf_bins : maf bins for straitification.","title":"Maf-stratified QQ plot"},{"location":"Visualization/#maf_bin_colors-colors-used-for-each-bin","text":"","title":"maf_bin_colors: colors used for each bin."},{"location":"Visualization/#use-rank-or-pos","text":"use_rank : if True, use the rank instead of real base pair position. use simply rank and basepair position to draw the x axis.","title":"Use rank or POS"},{"location":"Visualization/#colors-and-fonts","text":"","title":"Colors and fonts"},{"location":"Visualization/#quick-plot","text":"mysumstatsysumstats.plot_mqq()","title":"Quick plot"},{"location":"Visualization/#customized-plot","text":"mysumstats.plot_mqq(snpid=\"SNPID\",mode=\"mqq\", cut=20,skip=3, eaf=\"EAF\", anno=True,anno_set=[\"9:22132729_A_G\",\"6:20688121_T_A\",\"9:22132729_A_G\",\"15:62394264_G_C\"] , pinpoint=[\"9:22132729_A_G\",\"5:176513896_C_A\"], highlight=[\"7:127253550_C_T\",\"19:46166604_C_T\"], highlight_windowkb =1000, stratified=True, marker_size=(5,10), figargs={\"figsize\":(15,5),\"dpi\":300})","title":"Customized plot"}]}